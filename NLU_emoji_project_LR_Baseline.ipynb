{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_emoji_project_LR_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NNWwwg_V8BV6",
        "DtuXsHxF8hgO",
        "sLkaHBPAioHf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6omA1Kcjev_",
        "outputId": "082a6400-35bc-4e11-d6b2-18de70340bd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn_hEojLp9XH",
        "outputId": "69b535c9-9cbd-4588-e124-187f88063fc6"
      },
      "source": [
        "import gensim.models as gsm\n",
        "import gensim.downloader\n",
        "import pandas as pd\n",
        "import time\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfus74UCYZh5"
      },
      "source": [
        "**Emoji2Vec Download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzvLfnqOpN_Z"
      },
      "source": [
        "e2v = gsm.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/2021_NLU/emoji2vec.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72SXbLsK8Tyg",
        "outputId": "f2e0f0da-4a26-4869-ce86-53faf705b882"
      },
      "source": [
        "e2v.vector_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTxO6FnEpR_U",
        "outputId": "dfd0f6a2-3a40-4432-d6d0-ce042a8a739f"
      },
      "source": [
        "happy_vector = e2v['ğŸ˜‚']  \n",
        "happy_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SyeCbyypR2p",
        "outputId": "1a5b8920-0214-4883-cb7d-f1167d29097e"
      },
      "source": [
        "print(len(e2v.vocab))\n",
        "print(e2v.vocab.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1661\n",
            "dict_keys(['ğŸ‡¸ğŸ‡°', 'ğŸ‘”', 'ğŸŒ€', 'ğŸš¾', 'ğŸ‘¹', 'ğŸš»', 'ğŸ‘¬', 'ğŸ‡«ğŸ‡¯', 'ğŸ§', 'ğŸ½', 'ğŸšœ', 'â™‹', 'ğŸš­', 'ğŸš·', 'ğŸ“…', 'ğŸ’ˆ', 'âœ”ï¸', 'ğŸ™ğŸ¼', 'ğŸ¸', 'ğŸ¤·', 'ğŸŒ‚', 'ğŸš“', 'ğŸ¤', 'ğŸ’˜', 'ğŸš”', 'ğŸ‘š', 'ğŸ§', 'ğŸ¥', 'ğŸµ', 'âœ‚ï¸', 'ğŸ‘“', 'â›”', 'ğŸ’‚', 'ğŸ†”', 'ğŸ˜•', 'ğŸ', 'ğŸŠğŸ»', 'â—', 'ğŸ’­', 'ğŸ’¬', 'ğŸ´', 'â™‰', 'âš–', 'ğŸ‡®ğŸ‡©', 'ğŸ›µ', 'â¬…ï¸', 'ğŸ“’', 'ğŸ˜¡', 'ğŸ‡²ğŸ‡¦', 'ğŸ‡¨ğŸ‡­', 'ğŸ¦', 'â—ï¸', 'ğŸŒ', 'ğŸ¡', 'ğŸ‡¿ğŸ‡²', 'ğŸ¤’', 'ğŸ”“', 'ğŸ»', 'ğŸ˜¹', 'ğŸš®', 'ğŸ‘½', 'ğŸŒ', 'ğŸ‡­ğŸ‡º', 'ğŸ†', 'ğŸ‡°ğŸ‡µ', 'ğŸ’”', 'ğŸ…ğŸ»', 'ğŸ‘‡ğŸ½', 'ğŸ†', 'ğŸ‘ƒğŸ½', 'ğŸ–', 'ğŸ˜®', 'âœ´ï¸', 'â—', 'âŒš', 'ğŸ†', 'ğŸ‘»', 'ğŸ—»', 'ğŸ‡¨ğŸ‡º', 'ğŸ˜Ÿ', 'ğŸ’£', 'ğŸ’', 'ğŸ¦€', 'ğŸ‡¬ğŸ‡­', 'ğŸ©', 'ğŸ‡¼', 'ğŸ‘‰ğŸ¾', 'ğŸ™Š', 'ğŸš', 'ğŸ™', 'ğŸš¯', 'ğŸ‘©ğŸ¿', 'ğŸ‡«ğŸ‡·', 'ğŸ‘¸ğŸ¼', 'ğŸ˜¿', 'ğŸ˜²', 'ğŸ‡²ğŸ‡°', 'ğŸ”¢', 'ğŸš¬', 'ğŸ’…', 'ğŸ€', 'ğŸ·', 'ğŸ™ˆ', 'ğŸ‘­', 'ğŸ¯', 'ğŸ°', 'ğŸ–¨', 'ğŸ¨', 'ğŸ†—', 'ğŸ˜©', 'ğŸ‰', 'ğŸ¤', 'ğŸ¥¡', 'âš«ï¸', 'ğŸ£', 'ğŸŒ¹', 'ğŸŒ¯', 'ğŸ†', 'â–¶ï¸', 'ğŸ”®', 'ğŸ™Œ', 'ğŸ†š', 'ğŸ™†', 'ğŸ’', 'ğŸ’†', 'ğŸ”°', 'ğŸŒœ', 'ğŸŒ•', 'ğŸ‘', 'ğŸ˜³', 'âš“', 'ğŸ«', 'â™', 'ğŸ‘‚', '\\ue50a', 'ğŸ’ƒ', 'ğŸ¼', 'ğŸ£', 'ğŸ§', 'ğŸ ', 'ğŸŒ´', 'ğŸ˜', 'ğŸ›…', 'ğŸ’¶', 'âš½', 'â™', 'ğŸ«', 'ğŸ˜ƒ', 'ğŸ‡¸ğŸ‡®', 'ğŸ”’', 'â›º', 'ğŸš¥', 'ğŸ’µ', 'ğŸº', 'ğŸ’€', 'ğŸŒ…', 'ğŸœ', 'â™£ï¸', 'ğŸ””', 'ğŸ™†ğŸ¿', 'ğŸ’‰', 'ğŸ’¯', 'ğŸ•', 'ğŸ‘£', 'ğŸŒ', 'ğŸ¥”', 'ğŸ¸', 'ğŸ‘ƒğŸ»', 'ğŸ®', 'ğŸ’', 'ğŸ‘µğŸ½', 'ğŸ‡³ğŸ‡¬', 'ğŸš¦', 'ğŸš£', 'ğŸ’•', 'ğŸ¾', 'ğŸ‚', 'ğŸ‘', 'ğŸ€', 'ğŸš', 'ğŸ˜»', 'ğŸ›£', 'ğŸˆ', 'ğŸ…', 'ğŸ‡­ğŸ‡³', 'ğŸ¦ƒ', 'ğŸŒ', 'ğŸ‹', 'ğŸŒ', 'âœˆï¸', 'ğŸ‡¨ğŸ‡²', 'ğŸ˜‚', 'ğŸŒ¡', 'ğŸ”', 'ğŸ˜™', 'ğŸ‡¸ğŸ‡§', 'ğŸ‘…', 'ğŸ•¸', 'ğŸ‡©ğŸ‡ª', 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦', 'ğŸŒ’', 'ğŸ¹', 'ğŸ˜›', 'ğŸ', 'ğŸ’’', 'ğŸ‘¯', 'â„ï¸', 'ğŸ˜’', 'ğŸ”Œ', 'ğŸŒ‘', 'ğŸš¤', 'ğŸ“', 'ğŸ³', 'ğŸ”', 'ğŸ™‹ğŸ¿', 'ğŸ˜€', 'ğŸ™', 'ğŸŒµ', 'ğŸš', 'ğŸ‹', 'â˜˜', 'ğŸ€', 'âœŒï¸', 'ğŸ ', 'ğŸŒ—', 'ğŸ¬', 'ğŸš‰', 'ğŸ…ğŸ½', 'ğŸ—', 'ğŸ––ğŸ½', 'â›½', 'ğŸŒ±', 'ğŸ’´', 'ğŸ‘ğŸ¾', 'ğŸ­', 'ğŸˆ²', 'â›„', 'ğŸŒ„', 'ğŸ°', 'ğŸ––ğŸ¼', 'ğŸ¤', 'ğŸˆµ', 'ğŸšŒ', 'ğŸª', 'ğŸ…', 'ğŸ‘³', 'ğŸ´', 'ğŸ‘°', 'ğŸ‡ğŸ½', 'ğŸ’¿', 'ğŸ™‚', 'ğŸ“', 'ğŸ†–', 'ğŸšµ', 'ğŸ‡ªğŸ‡¬', 'ğŸ”Ÿ', 'ğŸ£', 'â™“ï¸', 'ğŸ‡¸ğŸ‡»', 'ğŸ™…ğŸ»', 'ğŸ¤°', 'ğŸ’', 'ğŸ‡µğŸ‡¬', 'ğŸ’ ', 'ğŸ¾', 'ğŸ³', 'ğŸ›¤', 'ğŸ‘º', 'ğŸ¤¦', 'ğŸ‡©ğŸ‡´', 'ğŸš‚', 'ğŸ’·', 'ğŸ', 'ğŸ”œ', 'âœ¡', 'ğŸ‘²', 'ğŸš˜', 'ğŸ“', 'Â®ï¸', 'ğŸŒ ', 'ğŸƒ', 'ğŸ©', 'ğŸ’³', 'ğŸ˜Š', 'ğŸŸ', 'â™Œï¸', 'â˜”', 'ğŸ‡¬ğŸ‡§', 'ğŸ‘Ÿ', 'ğŸŒ›', 'ğŸ·', 'ğŸ’®', 'ğŸ‘‹', 'ğŸ•‰', 'ğŸ‘ƒ', 'ğŸ±', 'ğŸ“', 'ğŸ—¨', 'ğŸš•', 'ğŸ‡±ğŸ‡º', 'ğŸŒ‡', 'ğŸ‘ğŸ¾', 'ğŸ‡¶', 'ğŸ«', 'ğŸ’§', 'ğŸ˜', 'ğŸ‘«', 'â™‹ï¸', 'ğŸ˜‹', 'ğŸ––', 'ğŸšº', 'ğŸ˜–', 'ğŸ‡¦ğŸ‡¼', 'ğŸŒ', 'ğŸ•', 'â™Š', 'ğŸŸ', 'ğŸ™ğŸ»', 'â™ˆ', 'ğŸ', 'ğŸ‡®ğŸ‡³', 'âœ‹', 'ğŸ‡', 'ğŸ™…', 'ğŸŒ»', '9ï¸âƒ£', 'â„¹ï¸', '5âƒ£ï¸', 'ğŸˆ', 'ğŸ‘', 'ğŸŒ‰', 'ğŸ‘¿', 'ğŸ', 'ğŸ‡ªğŸ‡¸', 'ğŸ', 'ğŸ‘ğŸ¿', 'ğŸš£ğŸ¿', 'ğŸ–‡', 'ğŸ°', 'ğŸ‡¸ğŸ‡©', 'ğŸš', 'ğŸš¡', 'ğŸ¯', 'ğŸ”¼', 'ğŸ‘¦ğŸ¿', 'ğŸ˜ª', 'â›µï¸', 'â–ªï¸', 'ğŸ‡±', 'ğŸ™‹', 'ğŸ˜´', 'ğŸ˜”', 'ğŸ‡¦ğŸ‡²', 'â›·', 'ğŸ˜±', 'ğŸ“¨', 'ğŸ†™', 'ğŸšŸ', 'ğŸ˜°', 'ğŸ’', 'ğŸš°', 'âœ³ï¸', 'ğŸŒš', 'ğŸ¬', 'ğŸ”‰', 'ğŸ’±', 'ğŸ', 'ğŸ©', 'â¤ï¸', 'ğŸ‘°ğŸ½', 'ğŸ„ğŸ¼', 'ğŸ‡¦ğŸ‡«', 'ğŸ’œ', 'âš ï¸', 'ğŸ›', 'ğŸ‚', 'ğŸ·', 'ğŸ„', 'â¸', 'ğŸ™€', 'ğŸ‡¨ğŸ‡©', 'â˜•ï¸', 'ğŸŒˆ', 'ğŸšª', 'ğŸ‡·ğŸ‡ª', 'ğŸ‘©', 'â™ï¸', 'ğŸ¤¢', 'ğŸ‡²ğŸ‡ª', 'ğŸ“¤', 'ğŸ‡·ğŸ‡¼', 'ğŸ‡µ', 'ğŸ¨', 'ğŸ’¤', 'âš°', 'ğŸ¡', 'âšªï¸', 'ğŸš´', 'ğŸ½', 'ğŸ˜µ', 'ğŸ‡³ğŸ‡ª', 'ğŸ˜¥', 'ğŸ‡¬ğŸ‡µ', 'ğŸ‘', 'ğŸº', 'ğŸš', 'ğŸš™', 'ğŸ', 'ğŸ‡¦ğŸ‡´', 'ğŸ¸', 'ğŸ”£', 'ğŸ­', 'ğŸŒŒ', 'ğŸ’', 'ğŸŒ¸', 'ğŸ‡§ğŸ‡²', 'ğŸ‘–', 'ğŸ‘ŠğŸ½', 'ğŸ‘†', 'ğŸ›‹', 'ğŸŒ¾', 'ğŸ†', 'ğŸŒ', 'ğŸŒ‹', 'ğŸ˜', 'ğŸ„', 'ğŸ‘´ğŸ¼', 'ğŸ‘©ğŸ¾', 'ğŸ™…ğŸ¼', 'ğŸ®', 'ğŸ˜„', '1âƒ£ï¸', 'ğŸ£', 'â™’ï¸', 'ğŸ›', 'ğŸ“', 'ğŸ‡¸ğŸ‡·', 'â›„ï¸', 'ğŸ‡±ğŸ‡¹', 'ğŸš›', 'ğŸš…', 'ğŸ–•', 'ğŸª', 'ğŸš', 'ğŸ‡°ğŸ‡ª', 'ğŸ›ƒ', 'ğŸ‡µğŸ‡·', 'ğŸ‡­ğŸ‡°', 'ğŸ‡µğŸ‡¼', 'ğŸ“›', 'ğŸ˜…', 'ğŸ…±ï¸', 'ğŸ­', 'ğŸ¢', 'â™ï¸', 'ğŸˆš', 'ğŸ‘´', 'ğŸ ', 'âš“ï¸', 'ğŸ—', 'ğŸ’½', 'ğŸ¹', 'ğŸ˜ˆ', 'ğŸ‡³ğŸ‡¨', 'ğŸ‡»ğŸ‡³', 'ğŸ“°', '7ï¸âƒ£', 'ğŸ»', 'ğŸ˜‰', 'ğŸ’', 'ğŸš¶', 'ğŸ™‡ğŸ½', 'ğŸ', 'ğŸ²', 'ğŸ‰', 'ğŸ²', 'ğŸ‡³ğŸ‡µ', 'ğŸ‘¤', 'ğŸ˜', 'ğŸ¶', 'ğŸ‡¦ğŸ‡®', 'ğŸ‘„', 'ğŸ—¿', 'ğŸŒ†', 'ğŸš€', 'ğŸ‘±ğŸ¿', 'ğŸ¼', 'ğŸ', 'ã€½ï¸', 'ğŸ', '4âƒ£ï¸', 'ğŸ“¦', 'â™Œ', 'â™¿ï¸', 'â™’', 'ğŸ‡µğŸ‡¸', 'ğŸ‡®ğŸ‡¶', 'ğŸŒƒ', 'ğŸ¬', 'ğŸ˜·', 'ğŸ‘’', 'ğŸ“²', 'ğŸ”¥', 'â™ï¸', 'ğŸ¡', 'ğŸ¢', 'ğŸ¨', 'ğŸ“†', 'â­•', 'ğŸš–', 'ğŸ‰', 'ğŸ˜“', 'ğŸœ', 'ğŸŒ¿', 'ğŸ¨', 'ğŸ', 'ğŸ‡¦ğŸ‡¹', 'ğŸ‡¬ğŸ‡¾', 'ğŸŒ–', 'ğŸ‡§ğŸ‡¼', 'ğŸš½', 'ğŸ‘', 'ğŸ‡', 'ğŸ‡²ğŸ‡¶', 'ğŸ²', 'ğŸ¢', 'ğŸ˜¸', 'ğŸ—ƒ', 'ğŸ•µ', 'ğŸ±', 'ğŸ‰', 'ğŸ˜º', 'ğŸ˜«', 'ğŸŒ­', 'ğŸ§', 'ğŸ', 'ğŸ™', 'ğŸ™‰', 'ğŸ‡µğŸ‡­', 'ğŸ•·', 'ğŸ–¼', 'âœï¸', 'ğŸ˜¨', 'ğŸ’»', 'ğŸ”ˆ', 'ğŸ‡©ğŸ‡¿', 'ğŸ’¸', 'ğŸŠ', 'ğŸ¶', 'ğŸ‡²ğŸ‡³', 'ğŸš¢', 'ğŸ', 'ğŸš¶ğŸ¿', 'â™‘ï¸', 'ğŸ™‡', 'ğŸ‡­ğŸ‡¹', 'ğŸ', 'ğŸ‘ŠğŸ¼', 'ğŸ˜¤', 'ğŸ‡®ğŸ‡±', 'ğŸ·', 'ğŸ’°', 'ğŸ‘†ğŸ¿', 'â†ªï¸', 'ğŸ‘•', 'ğŸ”', 'ğŸ', 'ğŸ¤µ', 'ğŸ’ƒğŸ½', 'â›ºï¸', 'ğŸ‘‰ğŸ¼', 'ğŸ’™', 'ğŸ˜—', 'ğŸ‡¬ğŸ‡º', 'ğŸš', 'â˜ï¸', 'ğŸ‡¨ğŸ‡°', 'ğŸ›', 'ğŸ‡»ğŸ‡¦', 'ğŸ‘Œ', 'ğŸš©', 'ğŸ¥„', 'ğŸ‹', 'âœŠ', 'âš¡', 'ğŸ“¿', 'ğŸŒ²', 'ğŸ‘€', 'ğŸš’', 'ğŸ˜Œ', 'ğŸ¤—', 'ğŸ‡»ğŸ‡ª', 'ğŸ„', 'ğŸ“©', 'ğŸ–', 'ğŸ‡»ğŸ‡º', 'ğŸ³', 'ğŸ¦‡', 'ğŸ‡¨ğŸ‡»', 'ğŸ’«', 'ğŸ”¡', 'ğŸ', 'ğŸ¤', 'ğŸ‘ƒğŸ¼', 'ğŸ¥™', 'ğŸšˆ', 'ğŸ”‹', 'ğŸ˜¬', 'â™¨ï¸', 'ğŸŒ¥', 'ğŸ', 'ğŸ•º', 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§', 'ğŸ”ª', 'âœŠğŸ½', 'ğŸ¿', 'ğŸš£ğŸ¾', 'ğŸ™ğŸ¿', 'ğŸŒ¼', 'ğŸ”™', 'âœ‹ğŸ¿', 'ğŸ®', 'âšª', 'ğŸ–¤', 'ğŸ¼', 'ğŸ‡¦ğŸ‡¿', 'ğŸ‡¿ğŸ‡¦', 'â™‘', 'â', 'ğŸ˜­', 'ğŸ“³', 'ğŸ‘‡ğŸ¾', 'ğŸµ', 'ğŸ˜˜', 'ğŸ™ğŸ¼', 'ğŸ‡¼ğŸ‡¸', 'ğŸ˜œ', 'ğŸ»', 'ğŸŒ˜', 'ğŸ‡ªğŸ‡º', 'ğŸ‡¹ğŸ‡¨', 'ğŸ‡¯', 'ğŸ®', 'ğŸ¥', 'ğŸ©', 'ğŸ‡§ğŸ‡³', 'ğŸš±', 'ğŸŒŸ', 'ğŸ’‡', 'ğŸ', 'ğŸ', 'ğŸ‘³ğŸ¾', 'ğŸš¨', 'ğŸŒ°', 'ğŸš', 'ğŸ‡¦ğŸ‡©', 'â™“', 'ğŸ“¹', 'ğŸ•', 'ğŸŒ', 'ğŸ‡§ğŸ‡§', 'ğŸš³', 'ğŸ“±', 'ğŸ™‡ğŸ»', 'ğŸ›', 'ğŸ‡¯ğŸ‡µ', 'âœ…', 'ğŸ”«', 'ğŸ‡²ğŸ‡´', 'ğŸ‡¸ğŸ‡¨', 'ğŸ•', 'ğŸš«', 'ğŸ’', 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦', 'ğŸ˜¼', 'ğŸ‡¹ğŸ‡³', 'âš™', 'ğŸ‡¦ğŸ‡¬', '3âƒ£ï¸', 'ğŸ‘¶ğŸ½', 'ğŸŒ”', 'âœ‰ï¸', 'ğŸ‡¸ğŸ‡½', 'ğŸ‘¨ğŸ¼', 'ğŸš£ğŸ½', 'ğŸ•¯', 'ğŸ˜', 'ğŸ‡°ğŸ‡¾', 'ğŸ‘¾', 'ğŸšƒ', 'ğŸ›', 'ğŸ¤³', 'ğŸŒ¦', 'ğŸ‡¬ğŸ‡¦', 'ğŸª', 'ğŸ“', 'ğŸ‡§ğŸ‡´', 'ğŸ‡µğŸ‡ª', 'ğŸš¹', 'â›¸', 'ğŸ’©', 'ğŸ¦…', 'ğŸ¤ ', 'ğŸ‡°ğŸ‡®', 'ğŸ—‚', 'ğŸ‘ˆğŸ¾', 'â™', 'ğŸ‘¦ğŸ½', 'ğŸ‘', 'ğŸŒ·', 'ğŸ•´', 'ğŸ‡¹ğŸ‡¼', 'ğŸ‘¨\\u200dâ¤ï¸\\u200dğŸ’‹\\u200dğŸ‘¨', 'ğŸ‡³ğŸ‡«', 'ğŸŠ', 'ğŸ”©', 'ğŸ‡¦ğŸ‡¸', 'ğŸ‡®ğŸ‡´', 'ğŸ', 'ğŸ™ŒğŸ½', 'ğŸš¶ğŸ¾', 'ğŸ›„', 'ğŸš§', 'ğŸ‡¹ğŸ‡¬', 'ğŸ’Ÿ', 'ğŸ‡¸ğŸ‡ª', 'ğŸ‡²ğŸ‡¼', 'ğŸ‘ˆğŸ»', 'ğŸ’¥', 'ğŸ–Œ', 'ğŸ‘ğŸ¾', 'ğŸ’…ğŸ»', 'ğŸ’—', 'ğŸ’¡', 'ğŸŸ', 'ğŸŒ«', 'ğŸŒ¬', 'â™¦ï¸', 'â°', 'â˜¯', 'ğŸ’ª', 'ğŸ”‘', 'ğŸ’Š', 'ğŸ‡¬ğŸ‡®', 'â˜ï¸', 'ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©', 'â™ï¸', 'ğŸ–', 'ğŸ—', 'ğŸƒ', 'ğŸ‡¨ğŸ‡³', 'ğŸ‘›', 'ğŸš¿', 'ğŸ”', 'ğŸ”', 'ğŸ°', 'ğŸ–²', 'ğŸ‘¨ğŸ¿', 'ğŸ¤', 'ğŸŒŠ', 'ğŸ”„', 'ğŸ‡¦ğŸ‡¶', 'ğŸº', 'ğŸ›Œ', 'ğŸ‡²ğŸ‡¿', 'ğŸ‘¼ğŸ¼', 'ğŸ„ğŸ¿', 'ğŸ‡´ğŸ‡²', 'ğŸ¤', 'â˜•', 'ğŸ™ğŸ¾', 'ğŸ™ŒğŸ¿', 'ğŸ”³', 'ğŸ±', 'ğŸ‡µğŸ‡¾', 'ğŸ’¢', 'ğŸ’†ğŸ¼', 'â¬†ï¸', 'ğŸ¦', 'ğŸ€', 'ğŸ¤º', 'ğŸ“š', 'ğŸ‡°ğŸ‡²', 'ğŸŒº', 'ğŸŠ', 'ğŸ’…ğŸ¼', 'ğŸ™', 'ğŸ‚', 'ğŸ˜¶', 'ğŸ˜', 'ğŸ', 'ğŸ…', 'ğŸ“ƒ', 'âŒ', 'ğŸ¤£', 'ğŸ‡§ğŸ‡¶', 'â–', 'ğŸ™ğŸ¿', 'ğŸ‘±ğŸ¾', 'ğŸ‘¢', 'ğŸµ', 'ğŸ—½', 'ğŸ„', 'ğŸ‘‡', 'ğŸ‡¸ğŸ‡¦', 'ğŸ”¬', 'ğŸ¿', 'ğŸ™', 'ğŸ‡¸ğŸ‡¬', 'ğŸ¥', 'ğŸ¤¡', 'â›°', 'ğŸ–±', 'ğŸŒ“', 'ğŸ‘', 'ğŸ¥', 'ğŸ¦', 'ğŸŒ™', 'ğŸ€„', 'ğŸ‘', 'ğŸ”¨', 'ğŸŒ', 'ğŸ‘ğŸ¼', 'ğŸ’ªğŸ¿', 'ğŸ‡²ğŸ‡¹', 'ğŸ›', 'ğŸ‡«ğŸ‡´', 'â›ª', 'ğŸ‡¸ğŸ‡´', 'ğŸ‡­ğŸ‡·', 'ğŸ‡¿ğŸ‡¼', 'ğŸ’ğŸ¾', 'ğŸ˜', 'â²', 'ğŸ‡¹ğŸ‡«', 'ğŸ‘ˆğŸ¼', 'ğŸ‘¸', 'ğŸ’‚ğŸ¼', 'â†–ï¸', 'ğŸ“¼', 'ğŸ‘°ğŸ¼', 'ğŸ‘ª', 'ğŸ¤˜', 'ğŸ', 'ğŸ‘™', 'â›²', 'ğŸš¸', 'ğŸ™†ğŸ»', 'ğŸ“‡', 'ğŸ—œ', 'ğŸ‡½ğŸ‡°', 'âœŠğŸ¾', 'ğŸ’š', 'ğŸŒ³', 'ğŸ“»', 'ğŸµ', 'ğŸ‘‰ğŸ½', 'ğŸ˜', 'ğŸ’›', 'ğŸ“§', 'ğŸ¥', 'ğŸ', 'ğŸ˜š', 'ğŸ“–', 'ğŸˆ', 'ğŸ˜¦', 'ğŸš‹', 'ğŸ¹', 'ğŸš¼', 'ğŸ‡¦ğŸ‡º', 'ğŸ‡³ğŸ‡±', 'ğŸ‘ŠğŸ¿', 'ğŸš„', 'â­ï¸', 'ğŸ›¥', 'ğŸ’‚ğŸ»', 'ğŸ¤¥', 'ğŸ‘ŒğŸ¿', 'ğŸ¦', 'ğŸ’²', 'ğŸ‡¾ğŸ‡¹', 'ğŸš¶ğŸ»', 'ğŸ¤¶', 'ğŸ‡°ğŸ‡·', 'â­', 'âœŠğŸ¿', 'ğŸ‡§ğŸ‡«', 'ğŸ‘®ğŸ½', 'â˜ºï¸', 'âœ‹ğŸ»', 'ğŸ¯', 'ğŸ‘·ğŸ¾', 'â›ªï¸', 'ğŸ’', 'ğŸ˜', 'ğŸŒª', 'ğŸ‘ˆ', 'ğŸšµğŸ¼', '2âƒ£ï¸', 'ğŸ‡¾ğŸ‡ª', 'ğŸ¤–', 'ğŸ“µ', 'ğŸ‡¨ğŸ‡±', 'ğŸš ', 'ğŸ‡¹ğŸ‡­', 'ğŸ’¨', 'ğŸ‡¹ğŸ‡·', 'ğŸª', 'ğŸ˜ ', 'ğŸ†‘', 'ğŸ‡·ğŸ‡´', 'ğŸ‘³ğŸ¼', 'ğŸ’ªğŸ½', 'ğŸ•”', 'ğŸ›€', 'ğŸ¿', '6âƒ£ï¸', 'ğŸ‘ğŸ»', 'ğŸ‡¨ğŸ‡¨', 'ğŸ‘', 'ğŸƒ', 'ğŸŒ½', 'ğŸ‡¹ğŸ‡¿', 'ğŸ‡¨ğŸ‡½', 'ğŸˆº', 'â›…', 'ğŸ«', 'â˜ ', 'ğŸš†', 'ğŸšš', 'ğŸ‘‰', 'ğŸ‡³ğŸ‡®', 'ğŸ¤•', 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦', 'ğŸ‘', 'ğŸ‡¬ğŸ‡¶', 'ğŸ‡¨ğŸ‡¾', 'ğŸš', 'ğŸ¥˜', 'ğŸˆ', 'ğŸ”', '8ï¸âƒ£', 'ğŸ‡§ğŸ‡»', 'ğŸ‡®ğŸ‡¨', 'ğŸ‡¸', 'ğŸ‘§ğŸ¿', 'ğŸ‘²ğŸ¿', 'â˜€ï¸', 'ğŸ™…ğŸ½', 'ğŸ•–', 'â“', 'ğŸ‡¨ğŸ‡µ', 'â›', 'ğŸ•', 'ğŸ‘˜', 'ğŸ™‡ğŸ¾', 'ğŸ‰', 'ğŸ‡®ğŸ‡¹', 'ğŸ“«', 'ğŸ‘', 'ğŸš', 'ğŸ‡ºğŸ‡¬', 'ğŸ”¦', 'ğŸ•³', 'ğŸ‡ªğŸ‡­', 'ğŸ‡¿', 'ğŸ‡«ğŸ‡®', 'ğŸ‘ğŸ¿', 'ğŸ‡ºğŸ‡¾', 'ğŸ‡®ğŸ‡ª', 'ğŸ˜½', 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§', 'ğŸ˜¾', 'ğŸ™‹ğŸ½', 'ğŸ‘†ğŸ½', 'ğŸ—¡', 'ğŸ€„ï¸', 'ğŸ‘¸ğŸ¾', 'â›ˆ', 'ğŸ¦†', 'ğŸ‘—', 'ğŸ“', 'ğŸ‘§ğŸ¾', 'ğŸ‘®ğŸ¿', 'ğŸ•°', 'â™', 'ğŸ–', 'ğŸ„ğŸ¾', 'ğŸ‡¹ğŸ‡¦', 'ğŸ—£', 'ğŸ‘¼ğŸ»', 'ğŸ”¸', 'ğŸƒ', 'ğŸ–Š', 'ğŸ›‚', 'ğŸŒ¶', 'ğŸ‘‚ğŸ¼', 'ğŸ‡¨ğŸ‡®', 'ğŸ¥’', 'ğŸ¤¾', 'ğŸ“¯', 'ğŸ˜¢', 'ğŸ”‡', 'ğŸ’¾', 'ğŸ¦', 'ğŸ‡ºğŸ‡¸', 'ğŸ‘\\u200dğŸ—¨', 'ğŸ˜¯', 'âš”', 'ğŸ‡²ğŸ‡­', 'ğŸ‡', 'ğŸ‘µğŸ¼', 'ğŸ¥ƒ', 'ğŸ’…ğŸ½', 'ğŸšŠ', 'ğŸ‡§ğŸ‡¦', 'ğŸ¤‘', 'ğŸ‡¹ğŸ‡¯', 'ğŸ’¹', 'ğŸ‘‘', '6ï¸âƒ£', 'â±', 'ğŸ‡²ğŸ‡½', 'â˜¢', 'ğŸ‡°ğŸ‡¿', 'ğŸ‡¬ğŸ‡«', 'ğŸ“¡', 'ğŸ‡²ğŸ‡¾', 'ğŸ“', 'ğŸ†’', 'ğŸ™…ğŸ¿', 'ğŸ‘´ğŸ¿', 'ğŸ…¿ï¸', 'ğŸ—¾', 'â‡ï¸', 'ğŸ‡±ğŸ‡§', 'ğŸ’‹', 'ğŸ‘¡', 'ğŸ‘ğŸ»', 'ğŸˆ¯', 'ğŸ‘ğŸ¾', 'ğŸ´', 'ğŸ‡¨ğŸ‡«', 'ğŸ’‡ğŸ¼', 'ğŸ™‹ğŸ»', 'ğŸ’¼', 'ğŸ‡¬ğŸ‡¹', 'ğŸ™„', 'ğŸ‘¥', 'ğŸ‡±ğŸ‡¦', 'ğŸ‘·ğŸ¿', 'ğŸ‡¯ğŸ‡²', 'ğŸ¥€', 'ğŸ’“', 'ğŸ›³', 'â™‰ï¸', 'ğŸ‡§ğŸ‡¹', 'ğŸ‡³ğŸ‡´', 'â‰ï¸', 'ğŸ”›', 'ğŸ–‹', 'ğŸ‘ŒğŸ¾', 'ğŸ“®', 'â™Šï¸', 'ğŸ‘¨', 'ğŸ˜‘', 'ğŸ“•', 'ğŸ“‚', 'ğŸ‘®', 'ğŸ˜§', 'ğŸ‡¦ğŸ‡·', 'ğŸ—º', 'ğŸº', 'ğŸ‘µğŸ¿', 'ğŸ––ğŸ¿', 'ğŸ‘Š', 'ğŸ†“', 'ğŸ‹', 'ğŸ–¥', 'â™¥ï¸', 'ğŸ‡·ğŸ‡¸', 'ğŸ‘·', 'ğŸ‰‘', 'âœ‹ğŸ½', 'ğŸ“', 'â˜®', 'ğŸ‘ˆğŸ¿', 'ğŸƒ', 'ğŸ‡¸ğŸ‡±', 'ğŸ¥•', 'ğŸ“ª', 'ğŸ¶', 'ğŸ‡¹ğŸ‡»', 'ğŸšµğŸ½', 'ğŸ‡¸ğŸ‡²', 'ğŸ¤§', 'ğŸ›', 'ğŸ‡§ğŸ‡©', 'ğŸ”š', 'â—¼ï¸', 'ğŸ”Š', 'ğŸš—', 'ğŸ‡§ğŸ‡®', 'ğŸ•š', 'ğŸ‡·ğŸ‡º', 'ğŸ‡µğŸ‡³', 'â›…ï¸', 'ğŸŠğŸ½', 'ğŸ“­', 'ãŠ™ï¸', 'ğŸ”†', 'âš›', 'ğŸ”', 'ğŸ‡°ğŸ‡³', 'â˜‚', 'ğŸ“Œ', 'â›³', 'ğŸ“€', 'ğŸ‡¹ğŸ‡©', 'ğŸ™ğŸ½', 'ğŸ‘¼ğŸ¿', 'ğŸ‡§ğŸ‡­', 'âœ', 'âš—', 'ğŸ‘¨\\u200dâ¤ï¸\\u200dğŸ‘¨', 'ğŸ‘‹ğŸ¼', 'ğŸ›€ğŸ½', 'ğŸ™ƒ', 'ğŸ˜‡', 'âš«', 'ğŸ““', 'ğŸ½', 'ğŸ‡©ğŸ‡²', 'ğŸ“¬', 'ğŸ” ', 'ğŸ“Ÿ', 'ğŸ‡®', 'ğŸˆ‚ï¸', 'ğŸ“´', 'â›“', 'ğŸ“º', 'ğŸ“¢', 'ğŸŸ', 'ğŸ•“', 'ğŸ”', 'ğŸˆ¹', 'ğŸ‘¼', 'ğŸ”', 'ğŸœ', 'âš¡ï¸', 'ğŸ‘ğŸ¼', 'ğŸ’‘', 'ğŸ™ğŸ½', 'ğŸ‡§ğŸ‡¯', 'ğŸ‘ ', 'ğŸ”—', 'ğŸ‡«ğŸ‡°', 'ğŸ‘·ğŸ½', 'ğŸ“¶', 'ğŸ’', 'ğŸ”•', 'ğŸ“‹', 'âœ¨', 'ğŸ¤¹', 'ğŸš´ğŸ¼', 'ğŸ•—', 'ğŸŠğŸ¿', 'ğŸ”¯', 'ğŸ‡°ğŸ‡¬', 'ğŸ¦ˆ', 'ğŸ‘±', 'â€¼ï¸', 'ğŸ”·', 'ğŸ•‘', 'ğŸ™ğŸ¾', 'ğŸ…ğŸ¿', 'ğŸˆ´', 'ğŸ ', 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦', 'ğŸˆ¶', 'âœ‹ğŸ¾', 'â—€ï¸', 'ğŸ‘§ğŸ»', 'ğŸƒğŸ¾', 'ğŸ¤š', 'ğŸ‡¸ğŸ‡¸', 'â—½ï¸', 'ğŸ‡¬ğŸ‡©', 'ğŸ‘°ğŸ»', 'ğŸƒğŸ¼', 'ğŸ™', 'ğŸ‡²ğŸ‡·', 'ğŸ‡¶ğŸ‡¦', 'ğŸ‘´ğŸ»', 'ğŸ‡¬ğŸ‡²', 'ğŸ‡¨ğŸ‡¦', 'ğŸ––ğŸ»', 'ğŸ’Œ', 'ğŸ…ğŸ¾', 'ğŸ‡±ğŸ‡°', 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘¦', 'ğŸ‘‡ğŸ¿', 'ğŸ’„', 'ğŸ‡¦ğŸ‡ª', 'â›”ï¸', 'ğŸ‡©ğŸ‡¯', 'ğŸ‡ğŸ¾', 'ğŸ’¦', 'ğŸ‡ªğŸ‡·', 'â˜”ï¸', 'ğŸ¤¤', 'ğŸ‡²ğŸ‡»', 'ğŸ¯', 'ğŸ‘¸ğŸ»', 'ğŸšµğŸ»', 'â›²ï¸', 'ğŸš¶ğŸ½', 'â™ˆï¸', 'ğŸ‡µğŸ‡°', 'ğŸ‘ğŸ½', 'ğŸ“‘', 'ğŸ‡±ğŸ‡·', 'â›½ï¸', 'ğŸ‘ğŸ½', 'ğŸŠğŸ¼', 'â›³ï¸', 'ğŸ“ ', 'ğŸ”‚', 'â™»ï¸', 'ğŸ›€ğŸ¿', 'ğŸ§€', 'ğŸ—¯', 'ğŸš´ğŸ¿', 'ğŸˆ', 'â¤´ï¸', '1ï¸âƒ£', 'ğŸ˜†', 'ğŸ†˜', 'ğŸ’º', 'ğŸ‡»ğŸ‡¬', 'ğŸ‡«ğŸ‡²', 'ğŸ‡³ğŸ‡¿', 'â˜¹', 'ğŸ’ªğŸ»', 'ğŸ‘´ğŸ¾', 'â˜„', 'ğŸ‘‡ğŸ»', 'ğŸ’ƒğŸ¿', 'ğŸ“„', 'ğŸ‘¶', 'ğŸ‡ºğŸ‡¿', 'ğŸ’…ğŸ¾', 'â¬œï¸', 'ğŸ¾', 'ğŸ”–', 'ğŸ‡¨ğŸ‡¿', 'ğŸ‡ªğŸ‡¨', 'ğŸ”±', 'ğŸ‡¦ğŸ‡½', 'ğŸ“·', 'â£', 'â“‚ï¸', 'ğŸ‡³ğŸ‡·', 'ğŸ‡²ğŸ‡º', 'ğŸ‘µ', 'ğŸ‡¬ğŸ‡·', 'â•', 'ğŸ¦Š', 'â–«ï¸', 'ğŸ•¶', 'ğŸ‡§ğŸ‡·', 'ğŸ‡µğŸ‡¹', 'ğŸ‡²ğŸ‡±', 'ğŸ•‹', 'ğŸ‘ğŸ¼', 'ğŸŠ', 'ğŸ›¬', 'ğŸ”¤', 'ğŸ¹', 'ğŸŒ®', 'ğŸ”½', 'â¿', 'ãŠ—ï¸', 'ğŸ—³', 'ğŸ‡ğŸ»', 'ğŸ‡¸ğŸ‡¿', 'ğŸ‡¸ğŸ‡³', 'ğŸ‘©ğŸ¼', 'ğŸ¤”', 'ğŸ’ƒğŸ»', 'ğŸ›°', 'ğŸ‘‚ğŸ¾', 'ğŸ‡µğŸ‡¦', 'ğŸ‘·ğŸ¼', 'ğŸ›€ğŸ¾', 'âš¾', 'ğŸ‡´', 'ğŸš‘', 'ğŸ¥—', 'ğŸ‡¬ğŸ‡±', 'ğŸ•’', 'ğŸš´ğŸ½', 'ğŸ› ', 'ğŸ’', 'ğŸ‘ŒğŸ½', 'ğŸ‘¦', 'ğŸ¥“', 'ğŸ‘¸ğŸ½', 'ğŸ™', 'ğŸ‘²ğŸ»', 'ğŸ‡ºğŸ‡¦', 'ğŸš£ğŸ»', 'â°', 'ğŸ‘ğŸ»', 'ğŸ‡ªğŸ‡¹', 'â—»ï¸', 'ğŸ…', 'ğŸ‡¨ğŸ‡·', 'ğŸ¦‚', '0ï¸âƒ£', 'â©', 'ğŸ‘‰ğŸ¿', 'ğŸ–', 'ğŸ‡¹ğŸ‡²', 'ğŸ‘°ğŸ¾', 'ğŸ’–', 'ğŸ…¾ï¸', 'ğŸ¦‰', 'ğŸ“˜', 'ğŸ‡§ğŸ‡¸', 'ğŸ‡¹ğŸ‡°', 'ğŸ’†ğŸ»', 'ğŸ“Š', 'âœ‹ğŸ¼', 'ğŸ‡§ğŸ‡ª', 'â›©', 'ğŸ‡ªğŸ‡ª', 'ğŸ‡¦ğŸ‡±', 'âŒšï¸', 'ğŸ‡°ğŸ‡­', 'ğŸŒ¤', 'ğŸ‡¯ğŸ‡´', 'ğŸš²', '#ï¸âƒ£', 'ğŸ‡³ğŸ‡º', 'â†™ï¸', 'ğŸŒ', 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§', 'âœ’ï¸', 'ğŸ”¹', 'ğŸ¡', 'â˜ï¸', 'ğŸ‡¦ğŸ‡¨', 'ğŸ‡¬', 'ğŸ‘‡ğŸ¼', 'ğŸ—“', 'ğŸ’ƒğŸ¾', 'ğŸ•¹', 'â—½', 'ğŸ‡ğŸ¼', 'ğŸ‡±ğŸ‡¾', 'ğŸ‘³ğŸ¿', 'ğŸ‘ŒğŸ»', 'ğŸ‡ğŸ¿', 'ğŸ‡µğŸ‡«', 'ğŸ›‘', 'ğŸ‘œ', 'â¬›ï¸', 'ğŸ‡³', 'ğŸ¤', 'ğŸ‡±ğŸ‡®', 'ğŸ”­', 'ğŸ˜£', 'ğŸƒğŸ»', 'ğŸ¤´', 'ğŸ‡¸ğŸ‡¾', 'ğŸ™‹ğŸ¼', 'ğŸ“£', 'âŒ›', 'ğŸ‡¬ğŸ‡¬', 'â¬‡ï¸', 'ğŸ‘ğŸ¼', 'ğŸ“', 'ğŸ‡²ğŸ‡©', 'â•', 'ğŸ‡§ğŸ‡¿', 'ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ’‹\\u200dğŸ‘©', 'ğŸ‡³ğŸ‡¦', 'ğŸ‡ª', 'ğŸ“œ', 'ğŸ‡±ğŸ‡¨', 'ğŸ‘ƒğŸ¿', 'ğŸ’ğŸ¼', 'ğŸ’ğŸ½', 'ğŸŒ', 'ğŸ™†ğŸ¼', 'ğŸ•™', 'ğŸ™ğŸ¼', 'ğŸ‘µğŸ»', 'ğŸˆ·ï¸', 'ğŸ‘¶ğŸ»', 'ğŸ‘²ğŸ¼', 'â¹', 'ğŸ—', 'â›¹', 'ğŸ”´', 'ğŸŒ¨', 'ğŸ“—', 'â˜ƒ', 'ğŸ’‡ğŸ»', 'ğŸ‡µğŸ‡±', 'âš±', 'ğŸ‡¬ğŸ‡¼', 'ğŸš´ğŸ¾', 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§', 'ğŸ•', 'ğŸ…ğŸ¼', 'ğŸ‡©ğŸ‡¬', 'ğŸ—’', 'ğŸ‡¨ğŸ‡¼', 'ğŸ‘±ğŸ»', 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘§', 'ğŸ“”', 'ğŸ™…ğŸ¾', 'â™¿', 'â™ ï¸', 'â˜ª', 'ğŸ›€ğŸ¼', 'ğŸ‘†ğŸ»', 'ğŸ‡¯ğŸ‡ª', 'ğŸ¢', 'ğŸ“ˆ', 'ğŸ¤“', 'â˜‘ï¸', 'ğŸ¥‚', 'ğŸš‡', '5ï¸âƒ£', 'ğŸ™ŒğŸ»', 'ğŸ', 'ğŸ‚', 'âš½ï¸', 'ğŸ„ğŸ½', 'ğŸ‡®ğŸ‡¸', 'ğŸ—', 'ğŸ‘‚ğŸ¿', 'ğŸ¦„', 'ğŸ‘¦ğŸ»', 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘¦', 'â¬›', 'ğŸ”€', 'ğŸ™†ğŸ¾', 'ğŸˆ¸', 'â—¾ï¸', 'ğŸ‘§', 'ğŸ‘ğŸ½', 'ğŸ‡²ğŸ‡¸', 'ğŸš¶ğŸ¼', 'â„¢ï¸', 'ğŸ†•', 'ğŸ”§', 'ğŸ—¼', 'ğŸ•›', '3ï¸âƒ£', 'ğŸ™ŒğŸ¼', 'ğŸ’‡ğŸ¿', 'ğŸ‡±ğŸ‡¸', 'ğŸ‡²ğŸ‡¬', 'ğŸ‘‹ğŸ¾', 'ğŸ‡®ğŸ‡·', 'â˜£', 'ğŸ”', 'ğŸ¸', 'ğŸˆ³', 'ğŸ‘µğŸ¾', 'ğŸ’ğŸ¿', 'ğŸ‡²ğŸ‡µ', 'ğŸ•Œ', 'ğŸ••', 'âœ', 'ğŸ”µ', 'ğŸ“', 'ğŸ‘¼ğŸ¾', 'â¤µï¸', 'Â©ï¸', 'ğŸ‘²ğŸ¾', 'ğŸ‡»', 'ğŸ‡¨ğŸ‡´', 'ğŸ‘ŠğŸ»', 'ğŸ•Š', 'ğŸ’ƒğŸ¼', 'ğŸ‘‹ğŸ¿', 'ğŸ‡§ğŸ‡¬', 'ğŸ“¥', 'ã€°ï¸', 'ğŸ', 'ğŸ––ğŸ¾', 'ğŸš', 'â”', 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§', 'â†—ï¸', 'ğŸš´ğŸ»', 'ğŸ‡¹ğŸ‡¹', 'ğŸ›¢', 'ğŸ‘±ğŸ½', 'ğŸ‘ğŸ¿', 'ğŸ‡¹ğŸ‡´', 'ğŸ‘‹ğŸ»', 'âš’', 'ğŸ“‰', 'ğŸ’‚ğŸ½', 'ğŸ˜', 'â', 'ğŸ‘¨ğŸ¾', 'ğŸ™ŒğŸ¾', 'ğŸ‡¬ğŸ‡ª', 'â†”ï¸', 'ğŸ‘ğŸ¿', 'ğŸ', 'ğŸ‡°ğŸ‡¼', 'ğŸ¦‹', 'ğŸ’ªğŸ¾', 'ğŸ‡®ğŸ‡²', 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦\\u200dğŸ‘¦', 'ğŸ‘¨ğŸ½', '4ï¸âƒ£', 'ğŸ‘§ğŸ½', 'ğŸ‘®ğŸ¼', 'ğŸ‘³ğŸ»', 'ğŸ‘¶ğŸ¾', 'ğŸ’‚ğŸ¾', 'ğŸ‘ŒğŸ¼', 'ğŸ‘§ğŸ¼', 'ğŸ™', 'ğŸ‡»ğŸ‡®', 'âœ–ï¸', 'ğŸŠğŸ¾', 'ğŸ›´', 'â†•ï¸', 'ğŸ¦', 'ğŸ‘¶ğŸ¿', 'ğŸ‡»ğŸ‡¨', 'ğŸ™ğŸ»', 'ğŸ‘¼ğŸ½', 'ğŸ‡§ğŸ‡¾', 'ğŸŒ§', 'âŒ›ï¸', 'ğŸ’…ğŸ¿', 'ğŸ‡¬ğŸ‡³', 'âŒ¨', 'ğŸ‘ğŸ»', 'âº', 'ğŸ›', 'ğŸ‡¨ğŸ‡¬', 'ğŸ¤›', 'ğŸ›©', 'ğŸ‘ŠğŸ¾', 'â­•ï¸', 'ğŸ‘‰ğŸ»', 'ğŸ™‡ğŸ¿', 'ğŸ’‡ğŸ¾', '*âƒ£', 'â—¾', 'ğŸ“½', 'ğŸ¥‘', 'ğŸ‘ƒğŸ¾', 'â›‘', 'ğŸ•˜', 'ğŸ™ğŸ½', 'â›´', 'ğŸ‡²ğŸ‡¨', '7âƒ£ï¸', 'ğŸ’†ğŸ¿', 'âœŠğŸ»', 'ğŸ‘®ğŸ¾', 'ğŸ‘‚ğŸ½', 'ğŸ”…', 'ğŸšµğŸ¾', 'ğŸ—„', 'ğŸ™‹ğŸ¾', 'ğŸ‘³ğŸ½', 'ğŸ—', '2ï¸âƒ£', 'ğŸ‘‹ğŸ½', 'ğŸ„ğŸ»', 'ğŸ’ğŸ»', 'ğŸ‡©ğŸ‡°', 'ğŸ‘ğŸ½', 'ğŸ”˜', 'ğŸ‘±ğŸ¼', 'ğŸŒ©', 'ğŸ‡±ğŸ‡»', 'ğŸ‡', '\\u200d', 'ğŸ‘¶ğŸ¼', 'â¡ï¸', 'ğŸ‡²ğŸ‡²', 'â›±', 'â†˜ï¸', 'ğŸš£ğŸ¼', 'ğŸƒğŸ½', 'ğŸ´', 'ğŸ›', 'ğŸ…°ï¸', 'ğŸ™ğŸ¾', 'ğŸ‘©ğŸ»', 'âœŠğŸ¼', 'ğŸ‘©ğŸ½', 'â›', '9âƒ£ï¸', 'ğŸ‘¨ğŸ»', 'ğŸ”ƒ', 'ğŸ’†ğŸ½', 'ğŸ‘†ğŸ¼', 'ğŸ’‚ğŸ¿', 'ğŸ›«', 'ğŸšµğŸ¿', 'ğŸ›¡', 'ğŸ‘‚ğŸ»', 'ğŸ¥–', 'ğŸ‡º', 'ğŸ‘®ğŸ»', 'âª', 'ğŸ“™', 'ğŸ­', 'ğŸ‘°ğŸ¿', 'ğŸ‘¦ğŸ¾', 'ğŸ‘†ğŸ¾', 'ğŸ’‡ğŸ½', 'ğŸ›€ğŸ»', 'ğŸ‘²ğŸ½', 'ğŸ™‡ğŸ¼', 'ğŸ¤™', 'ğŸ”²', 'ğŸ‡¹ğŸ‡±', 'â³', 'ğŸ‘¦ğŸ¼', 'ğŸ‡¸ğŸ‡¹', 'ğŸ‡½', 'ğŸ™ğŸ»', 'ğŸ³', 'ğŸ™†ğŸ½', 'ğŸ‘ˆğŸ½', 'ğŸƒğŸ¿', 'ğŸ’ªğŸ¼', 'ğŸ—‘', 'ğŸ‘´ğŸ½', 'ğŸ¤œ', 'ğŸ“¸', 'ğŸ¬', 'ğŸ’†ğŸ¾', 'ğŸ–', 'â¬œ', 'ğŸ‘·ğŸ»', 'ğŸ‘¸ğŸ¿', 'ğŸ”¶', 'âš¾ï¸', 'â˜¸', 'â†©ï¸', 'â˜¦', 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦', 'ğŸ™ğŸ¿'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COtWbV2QYjF3"
      },
      "source": [
        "**Word2Vec Download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M0DFXRrpkdq",
        "outputId": "c79592d9-9e19-4448-8776-1c6f4e906111"
      },
      "source": [
        "word2vec = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVcr51LL38lL"
      },
      "source": [
        "pickle.dump(word2vec, open('/content/drive/MyDrive/2021_NLU/data/full_data/word2vec.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yH7euci0mEU"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/word2vec.pkl', 'rb') as f:  \n",
        "    word2vec = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_owdfNn0ar6"
      },
      "source": [
        "## FULL DATA (SINGLE AND MULTI) - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjw34dNoqAQw"
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/full_data/emoji_nsp_dataset_train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39ly4uVw2anB"
      },
      "source": [
        "df_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/full_data/emoji_nsp_dataset_valid.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR8PpYFo99HG"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/full_data/emoji_nsp_dataset_test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1TAAIGd9rBi_",
        "outputId": "399f4e8f-6e22-4d93-8cad-9630fae59f5b"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50553</td>\n",
              "      <td>The dababy memes make no sense and thatâ€™s why ...</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>74541</td>\n",
              "      <td>a year ago today i would be holding my breath ...</td>\n",
              "      <td>ğŸ˜µ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50992</td>\n",
              "      <td>I told my mama about how the music industry is...</td>\n",
              "      <td>ğŸ’¯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95343</td>\n",
              "      <td>[USER] [USER] Thankyou guys</td>\n",
              "      <td>ğŸ’¯</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60555</td>\n",
              "      <td>You want new SUBS? Like ï¸ Retweet Follow me  R...</td>\n",
              "      <td>ğŸ˜‚ğŸ˜‚</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  50553  ...        1\n",
              "1  74541  ...        0\n",
              "2  50992  ...        1\n",
              "3  95343  ...        0\n",
              "4  60555  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCl9_bZvrsQm",
        "outputId": "b1a991b0-d9c2-4283-d61e-2b61993b3a92"
      },
      "source": [
        "df_train.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index             15540\n",
              "tweets            15540\n",
              "emoji_sentence    15540\n",
              "follows?          15540\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebl2VyhL44Kl",
        "outputId": "b1832780-0391-4269-f79a-e8593ac03cea"
      },
      "source": [
        "df_train[\"emoji_sentence\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         ğŸ˜\n",
              "1         ğŸ¤­\n",
              "2         ğŸ¥º\n",
              "3         ğŸ™\n",
              "4         ğŸ™ƒ\n",
              "         ..\n",
              "15535     ğŸ¤·\n",
              "15536     ğŸ¤£\n",
              "15537     ğŸ¥º\n",
              "15538    ğŸ™ŒğŸº\n",
              "15539    ğŸ™„ğŸ˜‹\n",
              "Name: emoji_sentence, Length: 15540, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaS2Ayhm6j6q",
        "outputId": "053d5ffc-60d2-4749-f42c-c9256fa753c0"
      },
      "source": [
        "df_train[\"emoji_sentence\"].isna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        False\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "14396    False\n",
              "14397    False\n",
              "14398    False\n",
              "14399    False\n",
              "14400    False\n",
              "Name: emoji_sentence, Length: 14401, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvzvJ2-nqm2",
        "outputId": "6a9b8f5c-b9d1-4ca6-adf5-80045d715ba9"
      },
      "source": [
        "print(len(df_train))\n",
        "print(len(df_val))\n",
        "print(len(df_test))\n",
        "\n",
        "df_train = df_train.dropna().drop_duplicates()\n",
        "df_val = df_val.dropna().drop_duplicates()\n",
        "df_test = df_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_val))\n",
        "print(len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "2199\n",
            "4438\n",
            "15540\n",
            "2199\n",
            "4438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNWwwg_V8BV6"
      },
      "source": [
        "###Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrP-V85go6Ez"
      },
      "source": [
        "def make_lowercase(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - list of documents\n",
        "\t- output: data - list of documents after lowercasing everything\n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\tstart = time.time()\n",
        "\tdata = [i.lower() for i in data]\n",
        "\n",
        "\tend = time.time()\n",
        "\tprint('\\n       ##### Lowercasing Done! Time Taken - ',end-start)\n",
        "\treturn data                                                                       \n",
        "\n",
        "\n",
        "def punctuation_removal(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - list of documents\n",
        "\t- output: data - list of documents after removing punctuation\n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\tstart = time.time()\n",
        "\tdata = [i.translate(str.maketrans(string.punctuation,' '*len(string.punctuation))) for i in data]\n",
        "\tend = time.time()\n",
        "\tprint('\\n       ##### Punctuation removed! Time Taken - ',end-start)\n",
        "\treturn data\n",
        "\n",
        "def whitespace_removal(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - \n",
        "\t- output: data - \n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\tstart = time.time()\n",
        "\tdata = [' '.join(mystring.split()) for mystring in data]\n",
        "\t# data = [i.strip() for i in data]\n",
        "\tend = time.time()\n",
        "\tprint('\\n       ##### Whitespace removed! Time Taken - ',end-start)\n",
        "\treturn data\n",
        "\n",
        "# TOKENIZATION with NLTK\n",
        "def tokenization_nltk(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - \n",
        "\t- output: data - \n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\t# Using NLTK\n",
        "\tstart = time.time()\n",
        "\tdata = [nltk.word_tokenize(i) for i in data]\n",
        "\tend = time.time()\n",
        "\t# Using Spacy - Spacy takes too much time\n",
        "\t#data = [[token.text for token in nlp_spacy(i)] for i in data]\n",
        "\tprint('\\n       ##### Tokenization Done using NLTK! Time Taken - ', end-start)\n",
        "\treturn data\n",
        "\n",
        "# #used to search in nltk stop_words\n",
        "# def BinarySearch(a, x): \n",
        "# \ti = bisect_left(a, x) \n",
        "# \tif i != len(a) and a[i] == x:\n",
        "# \t\treturn i \n",
        "# \telse: \n",
        "# \t\treturn -1\n",
        "\n",
        "# def stopwords_removal(data, stop_words_nltk, debug=False):\n",
        "# \t'''\n",
        "# \t- input: data - \n",
        "# \t- output: data - \n",
        "# \t'''\n",
        "# \tif(debug):\n",
        "# \t\tprint(\"stopwords_removal_nltk data_sample out of \",len(data))\n",
        "# \t\tprint(data[:sample_to_print])\n",
        "# \t#using NLTK\n",
        "# \tstart = time.time()\n",
        "# \tdata = [[j for j in doc if (BinarySearch(stop_words_nltk,j)<0)] for doc in data]\n",
        "# \tdata = [[x for x in word if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())] for word in data]\n",
        "# \tend = time.time()\n",
        "# \tprint('\\n       ##### Stopwords Removed using NLTK! Time Taken - ',end-start)\n",
        "# \treturn data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T0O29AYoGgT"
      },
      "source": [
        "def clean_text(sample, debug=False):\n",
        "  '''\n",
        "  sample should be a list of documents\n",
        "  '''\n",
        "\n",
        "\n",
        "  # sample = remove_string_with_nonASCII(sample)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  # sample = preprocess_tweet_text(sample)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "    \n",
        "  sample = make_lowercase(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  sample = punctuation_removal(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  sample = whitespace_removal(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  sample = tokenization_nltk(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  # sample = tokenization_spacy(sample)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  # sample = lemmatization_tokenization_spacy(sample)\n",
        "  # if debug:\n",
        "    # print(sample[:2])\n",
        "\n",
        "  # sample = stopwords_removal(sample, stop_words_nltk)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  # sample = make_bigrams_gensim(sample, bigrams_min_count=10, bigrams_threshold=10) #params from gensim\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  sample_normal = [' '.join(i) for i in sample]\n",
        "  # Sample tokenized is used for Word2Vec\n",
        "\n",
        "  return sample, sample_normal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iddyM7tMqGa0",
        "outputId": "275907a0-80fe-40be-fe3e-6f4defd3a8e1"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_tokenized, x_train_normal = clean_text(df_train['tweets'].values)\n",
        "x_val_tokenized, x_val_normal = clean_text(df_val['tweets'].values)\n",
        "x_test_tokenized, x_test_normal = clean_text(df_test['tweets'].values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.012780904769897461\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.09380507469177246\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.02262401580810547\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  2.0198376178741455\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.00092315673828125\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.013142824172973633\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.003053903579711914\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.2526061534881592\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0018680095672607422\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.02589106559753418\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.006514072418212891\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.5394716262817383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mFlX8HC8Nj2"
      },
      "source": [
        "y_train = df_train['follows?'].values\n",
        "y_val = df_val['follows?'].values\n",
        "y_test = df_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szipRmZv8Ntj"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_2 = []\n",
        "x_train_tokenized_2 = []\n",
        "x_train_normal_2 = []\n",
        "empty_indices_train = []\n",
        "\n",
        "for i in range(len(x_train_tokenized)):\n",
        "  if len(x_train_tokenized[i])==0:\n",
        "    empty_indices_train.append(i)\n",
        "  else:\n",
        "    x_train_tokenized_2.append(x_train_tokenized[i])\n",
        "    x_train_normal_2.append(x_train_normal[i])\n",
        "    y_train_2.append(y_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcTijrpg9A1Z"
      },
      "source": [
        "#remove empty values for val\n",
        "y_val_2 = []\n",
        "x_val_tokenized_2 = []\n",
        "x_val_normal_2 = []\n",
        "empty_indices_val = []\n",
        "\n",
        "for i in range(len(x_val_tokenized)):\n",
        "  if len(x_val_tokenized[i])==0:\n",
        "    empty_indices_val.append(i)\n",
        "  else:\n",
        "    x_val_tokenized_2.append(x_val_tokenized[i])\n",
        "    x_val_normal_2.append(x_val_normal[i])\n",
        "    y_val_2.append(y_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yqUX_iR9A5W"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_2 = []\n",
        "x_test_tokenized_2 = []\n",
        "x_test_normal_2 = []\n",
        "empty_indices_test = []\n",
        "\n",
        "for i in range(len(x_test_tokenized)):\n",
        "  if len(x_test_tokenized[i])==0:\n",
        "    empty_indices_test.append(i)\n",
        "  else:\n",
        "    x_test_tokenized_2.append(x_test_tokenized[i])\n",
        "    x_test_normal_2.append(x_test_normal[i])\n",
        "    y_test_2.append(y_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdSWeXeQ9BB6",
        "outputId": "cb9341e6-abe7-4e23-ab5f-76fe795e15cb"
      },
      "source": [
        "print(empty_indices_train)\n",
        "print(len(empty_indices_train))\n",
        "print(len(x_train_tokenized))\n",
        "print(len(x_train_tokenized_2))\n",
        "print(len(x_train_normal_2))\n",
        "print(len(y_train_2))\n",
        "\n",
        "print(empty_indices_val)\n",
        "print(len(empty_indices_val))\n",
        "print(len(x_val_tokenized))\n",
        "print(len(x_val_tokenized_2))\n",
        "print(len(x_val_normal_2))\n",
        "print(len(y_val_2))\n",
        "\n",
        "print(empty_indices_test)\n",
        "print(len(empty_indices_test))\n",
        "print(len(x_test_tokenized))\n",
        "print(len(x_test_tokenized_2))\n",
        "print(len(x_test_normal_2))\n",
        "print(len(y_test_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "15540\n",
            "15540\n",
            "15540\n",
            "15540\n",
            "[]\n",
            "0\n",
            "2199\n",
            "2199\n",
            "2199\n",
            "2199\n",
            "[]\n",
            "0\n",
            "4438\n",
            "4438\n",
            "4438\n",
            "4438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhFYPLWu8HNA"
      },
      "source": [
        "### Save tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyp_54CI9BF-"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_data.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_tokenized, x_train_normal, x_val_tokenized, x_val_normal, x_test_tokenized, x_test_normal, empty_indices_train, x_train_tokenized_2, \\\n",
        "                 x_train_normal_2, empty_indices_val, x_val_tokenized_2, x_val_normal_2, y_train, y_val, y_train_2, y_val_2, y_test, y_test_2,\\\n",
        "                 empty_indices_test, x_test_normal_2, x_test_tokenized_2 ], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lIVgsadxKLA"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_data.pkl', 'rb') as f:  \n",
        "    x_train_tokenized, x_train_normal, x_val_tokenized, x_val_normal, x_test_tokenized, x_test_normal, empty_indices_train, x_train_tokenized_2, \\\n",
        "                 x_train_normal_2, empty_indices_val, x_val_tokenized_2, x_val_normal_2, y_train, y_val, y_train_2, y_val_2, y_test, y_test_2,\\\n",
        "                 empty_indices_test, x_test_normal_2, x_test_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38nUJAfi9NXB"
      },
      "source": [
        "# def create_df(xdata, emojidata, ydata):\n",
        "#   temp=[\" \".join(i) for i in xdata]\n",
        "#   df_new = pd.DataFrame(temp)\n",
        "#   df_new[\"Emoji\"] = emojidata\n",
        "#   df_new[\"Target\"] = ydata\n",
        "\n",
        "#   df_new.columns = [\"Tweet\", \"Emoji\", \"Target\"]\n",
        "#   return df_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIS_kfnY9NbN"
      },
      "source": [
        "# df_new_val = create_df(x_val_tokenized_2,  y_val_2)\n",
        "# df_new_train = create_df(x_train_tokenized_2, y_train_2)\n",
        "# df_new_test = create_df(x_test_tokenized_2, df_test['emoji_sentence'], y_test_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj3WZZ_I4uK7"
      },
      "source": [
        "# df_new_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1JhRi9i1iF",
        "outputId": "27a45dff-24db-4c07-ba2e-e512484b7e84"
      },
      "source": [
        "df_test['tokenized_tweets'] = x_test_tokenized\n",
        "df_test['tokenized_len'] = df_test['tokenized_tweets'].apply(lambda x: len(x))\n",
        "print(df_test['tokenized_len'].mean())\n",
        "print(df_test['tokenized_len'].median())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.242000901306895\n",
            "10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Gvk_ol9UY5"
      },
      "source": [
        "# # Saving the objects:\n",
        "# with open('/content/drive/MyDrive/2021_NLU/data/full_data/df_new.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "#     pickle.dump([df_new_val, df_new_train, df_new_test], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKDpl79C9UcJ"
      },
      "source": [
        "# with open('/content/drive/MyDrive/2020 NLP/Project/df_new.pkl', 'rb') as f:  \n",
        "#     df_new_val, df_new_train, df_new_test = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtuXsHxF8hgO"
      },
      "source": [
        "### Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQmEFUlC9gU5"
      },
      "source": [
        "def convert_word2vec(model, corpus, strategy):\n",
        "  # return [[model[token] for token in sentence] for sentence in corpus]\n",
        "  output = []\n",
        "  for sentence in corpus:\n",
        "    vector_ = np.zeros(model.vector_size)\n",
        "    for token in sentence:\n",
        "      try:\n",
        "        token_vector = model[token]\n",
        "        vector_ = vector_ + token_vector\n",
        "      except:\n",
        "        vector_ = vector_ + np.zeros(model.vector_size)\n",
        "    if strategy=='mean':\n",
        "      vector_ = vector_/len(sentence)\n",
        "    elif strategy=='add':\n",
        "      pass\n",
        "    output.append(vector_)\n",
        "  # output is a list\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIHpx-MO9gZs"
      },
      "source": [
        "X_train_w2vec = convert_word2vec(word2vec, x_train_tokenized_2, strategy='mean')\n",
        "X_val_w2vec = convert_word2vec(word2vec, x_val_tokenized_2, strategy='mean')\n",
        "X_test_w2vec = convert_word2vec(word2vec, x_test_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNA44FrAzOER"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_train['emoji_sentence_list'] = df_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_train = df_train['emoji_sentence_list'].values\n",
        "\n",
        "df_val['emoji_sentence_list'] = df_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_val = df_val['emoji_sentence_list'].values\n",
        "\n",
        "df_test['emoji_sentence_list'] = df_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_test = df_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0wjcIlwDJMw"
      },
      "source": [
        "def convert_emoji2vec(model, corpus, strategy):\n",
        "  # return [[model[token] for token in sentence] for sentence in corpus]\n",
        "  output = []\n",
        "  for emojis in corpus:\n",
        "    vector_ = np.zeros(model.vector_size)\n",
        "    for emoji in emojis:\n",
        "      try:\n",
        "        token_vector = model[emoji]\n",
        "        vector_ = vector_ + token_vector\n",
        "      except:\n",
        "        vector_ = vector_ + np.zeros(model.vector_size)\n",
        "    if strategy=='mean':\n",
        "      vector_ = vector_/len(emojis)\n",
        "    elif strategy=='add':\n",
        "      pass\n",
        "    output.append(vector_)\n",
        "  # output is a list\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqWMsSTD9gnq"
      },
      "source": [
        "X_train_e2vec = convert_emoji2vec(e2v, emoji_corpus_train, strategy='mean')\n",
        "X_val_e2vec = convert_emoji2vec(e2v, emoji_corpus_val, strategy='mean')\n",
        "X_test_e2vec = convert_emoji2vec(e2v, emoji_corpus_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5xk3GbOACeb",
        "outputId": "376d85ea-ba16-4a6a-8f8c-1806176ef82e"
      },
      "source": [
        "print(len(X_train_w2vec))\n",
        "print(len(X_train_w2vec[4]))\n",
        "\n",
        "print(len(X_val_w2vec))\n",
        "print(len(X_val_w2vec[4]))\n",
        "\n",
        "print(len(X_test_w2vec))\n",
        "print(len(X_test_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "300\n",
            "2199\n",
            "300\n",
            "4438\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33EYEGrA_cti",
        "outputId": "77ed942c-3e85-4b56-c15d-73675b3ff88e"
      },
      "source": [
        "print(len(X_train_e2vec))\n",
        "print(len(X_train_e2vec[4]))\n",
        "\n",
        "print(len(X_val_e2vec))\n",
        "print(len(X_val_e2vec[4]))\n",
        "\n",
        "print(len(X_test_e2vec))\n",
        "print(len(X_test_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "300\n",
            "2199\n",
            "300\n",
            "4438\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmQCEf5Ig3ZB"
      },
      "source": [
        "#### Averaged Vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kRpTqbjAYxB"
      },
      "source": [
        "X_train_vec = (np.array(X_train_w2vec) + np.array(X_train_e2vec))/2\n",
        "X_val_vec = (np.array(X_val_w2vec) + np.array(X_val_e2vec))/2\n",
        "X_test_vec = (np.array(X_test_w2vec) + np.array(X_test_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXcy1curADf_",
        "outputId": "ce0614c7-9069-434c-959a-4d685572458c"
      },
      "source": [
        "X_train_w2vec[0][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04621582, -0.00656535,  0.04308268,  0.0743042 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf71tBhPA4Fw",
        "outputId": "a55e5076-ad81-48c6-82e3-b38c2c0cde06"
      },
      "source": [
        "X_train_e2vec[0][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03221022,  0.03802984, -0.00126745,  0.07279918])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhW5xZdmA4KQ",
        "outputId": "e1aa2d0f-0a59-4719-939b-0d5a294ca9ea"
      },
      "source": [
        "X_train_vec[0][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03921302, 0.01573225, 0.02090762, 0.07355169])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKrkAztPBO-t",
        "outputId": "6db4cacb-fa27-4fde-c832-ae0281058eda"
      },
      "source": [
        "len(X_train_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODMNoNOhEZt"
      },
      "source": [
        "#### Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1WbET1chHtn"
      },
      "source": [
        "X_train_vec_concat = np.concatenate((X_train_w2vec, X_train_e2vec), axis=1) \n",
        "X_val_vec_concat  = np.concatenate((X_val_w2vec, X_val_e2vec), axis=1) \n",
        "X_test_vec_concat  = np.concatenate((X_test_w2vec, X_test_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TurUa1-xaHlA",
        "outputId": "3523c11d-8231-4394-9390-2d7713c252a3"
      },
      "source": [
        "print(len(X_train_w2vec))\n",
        "print(len(X_train_e2vec))\n",
        "print(len(X_train_vec_concat))\n",
        "print(len(X_train_w2vec[4]))\n",
        "print(len(X_train_vec_concat[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "15540\n",
            "15540\n",
            "300\n",
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He-E1rm5Z6v6",
        "outputId": "9a8690ed-c7fc-49b0-e0a7-4ef12f135584"
      },
      "source": [
        "len(X_train_vec_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbr_jNujjRUQ",
        "outputId": "8c2143be-cbb7-440f-ad54-0ea0b764c64e"
      },
      "source": [
        "X_train_vec_concat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15540, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftrgTt0h8Z7R"
      },
      "source": [
        "### Save Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j16u5CJuzldt"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_vec, X_val_vec, X_test_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwUDi7-OzlhL"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec.pkl', 'rb') as f:  \n",
        "    X_train_vec, X_val_vec, X_test_vec = pickle.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlaP0o8huEP"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec_concat.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_vec_concat, X_val_vec_concat, X_test_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpYchOBhhuIX"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec.pkl', 'rb') as f:  \n",
        "    X_train_vec_concat, X_val_vec_concat, X_test_vec_concat = pickle.load(f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SehXB2kF0ljA"
      },
      "source": [
        "## (ONLY) SINGLE EMOJI - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBfMT8ND0ob2"
      },
      "source": [
        "df_sing_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/single_emoji/emoji_nsp_dataset_single_emoji_train.csv')\n",
        "df_sing_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/single_emoji/emoji_nsp_dataset_single_emoji_valid.csv')\n",
        "df_sing_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/single_emoji/emoji_nsp_dataset_single_emoji_test.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "b4vjIbWT0ofB",
        "outputId": "99e42f27-7cd2-46ff-d43d-25d0d7d95653"
      },
      "source": [
        "df_sing_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67113</td>\n",
              "      <td>Craving Black Cake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35900</td>\n",
              "      <td>yâ€™all i was kidding, pls donâ€™t attack me</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1045</td>\n",
              "      <td>omg bye so true</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11764</td>\n",
              "      <td>Nooo Iâ€™m at the end of the og Futurama eps</td>\n",
              "      <td>ğŸ˜¢</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1642</td>\n",
              "      <td>[USER] [USER] [USER] [USER] Not worth wasting ...</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  67113  ...        0\n",
              "1  35900  ...        1\n",
              "2   1045  ...        1\n",
              "3  11764  ...        1\n",
              "4   1642  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4I6fFWe0oj6",
        "outputId": "8f5480ae-21c3-409a-ec33-a64d5b563cdf"
      },
      "source": [
        "print(len(df_sing_train))\n",
        "print(len(df_sing_val))\n",
        "print(len(df_sing_test))\n",
        "\n",
        "df_sing_train = df_sing_train.dropna().drop_duplicates()\n",
        "df_sing_val = df_sing_val.dropna().drop_duplicates()\n",
        "df_sing_test = df_sing_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_sing_train))\n",
        "print(len(df_sing_val))\n",
        "print(len(df_sing_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15015\n",
            "2153\n",
            "4341\n",
            "15015\n",
            "2153\n",
            "4341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGCW8hdc0omx",
        "outputId": "25aea3cd-7cb8-4608-da32-978f40d28a3b"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_sing_tokenized, x_train_sing_normal = clean_text(df_sing_train['tweets'].values)\n",
        "x_val_sing_tokenized, x_val_sing_normal = clean_text(df_sing_val['tweets'].values)\n",
        "x_test_sing_tokenized, x_test_sing_normal = clean_text(df_sing_test['tweets'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.011325836181640625\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.07462406158447266\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.020409584045410156\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  1.7219054698944092\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0008127689361572266\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.009940624237060547\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.0026712417602539062\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.24480819702148438\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0017445087432861328\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.023852109909057617\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.006357908248901367\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.4971282482147217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVdQHYmk0orG"
      },
      "source": [
        "y_sing_train = df_sing_train['follows?'].values\n",
        "y_sing_val = df_sing_val['follows?'].values\n",
        "y_sing_test = df_sing_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_tTjjSL3nGe"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_sing_2 = []\n",
        "x_train_sing_tokenized_2 = []\n",
        "x_train_sing_normal_2 = []\n",
        "empty_indices_sing_train = []\n",
        "\n",
        "for i in range(len(x_train_sing_tokenized)):\n",
        "  if len(x_train_sing_tokenized[i])==0:\n",
        "    empty_indices_sing_train.append(i)\n",
        "  else:\n",
        "    x_train_sing_tokenized_2.append(x_train_sing_tokenized[i])\n",
        "    x_train_sing_normal_2.append(x_train_sing_normal[i])\n",
        "    y_train_sing_2.append(y_sing_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blwEBMvm4Cry"
      },
      "source": [
        "#remove empty values for val\n",
        "y_val_sing_2 = []\n",
        "x_val_sing_tokenized_2 = []\n",
        "x_val_sing_normal_2 = []\n",
        "empty_indices_sing_val = []\n",
        "\n",
        "for i in range(len(x_val_sing_tokenized)):\n",
        "  if len(x_val_sing_tokenized[i])==0:\n",
        "    empty_indices_sing_val.append(i)\n",
        "  else:\n",
        "    x_val_sing_tokenized_2.append(x_val_sing_tokenized[i])\n",
        "    x_val_sing_normal_2.append(x_val_sing_normal[i])\n",
        "    y_val_sing_2.append(y_sing_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etNPNC7G4Cu6"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_sing_2 = []\n",
        "x_test_sing_tokenized_2 = []\n",
        "x_test_sing_normal_2 = []\n",
        "empty_indices_sing_test = []\n",
        "\n",
        "for i in range(len(x_test_sing_tokenized)):\n",
        "  if len(x_test_sing_tokenized[i])==0:\n",
        "    empty_indices_sing_test.append(i)\n",
        "  else:\n",
        "    x_test_sing_tokenized_2.append(x_test_sing_tokenized[i])\n",
        "    x_test_sing_normal_2.append(x_test_sing_normal[i])\n",
        "    y_test_sing_2.append(y_sing_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daxAEWZN3nJ9",
        "outputId": "aa25807f-3e2b-4df1-a560-5ffa4b1f52d8"
      },
      "source": [
        "print(empty_indices_sing_train)\n",
        "print(len(empty_indices_sing_train))\n",
        "print(len(x_train_sing_tokenized))\n",
        "print(len(x_train_sing_tokenized_2))\n",
        "print(len(x_train_sing_normal_2))\n",
        "print(len(y_train_sing_2))\n",
        "\n",
        "print(empty_indices_sing_val)\n",
        "print(len(empty_indices_sing_val))\n",
        "print(len(x_val_sing_tokenized))\n",
        "print(len(x_val_sing_tokenized_2))\n",
        "print(len(x_val_sing_normal_2))\n",
        "print(len(y_val_sing_2))\n",
        "\n",
        "print(empty_indices_sing_test)\n",
        "print(len(empty_indices_sing_test))\n",
        "print(len(x_test_sing_tokenized))\n",
        "print(len(x_test_sing_tokenized_2))\n",
        "print(len(x_test_sing_normal_2))\n",
        "print(len(y_test_sing_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "15015\n",
            "15015\n",
            "15015\n",
            "15015\n",
            "[]\n",
            "0\n",
            "2153\n",
            "2153\n",
            "2153\n",
            "2153\n",
            "[]\n",
            "0\n",
            "4341\n",
            "4341\n",
            "4341\n",
            "4341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZZMjTd3nNi"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_sing_tokenized, x_train_sing_normal, x_val_sing_tokenized, x_val_sing_normal, x_test_sing_tokenized, x_test_sing_normal, empty_indices_sing_train, x_train_sing_tokenized_2, \\\n",
        "                 x_train_sing_normal_2, empty_indices_sing_val, x_val_sing_tokenized_2, x_val_sing_normal_2, y_sing_train, y_sing_val, y_train_sing_2, y_val_sing_2, y_sing_test, y_test_sing_2,\\\n",
        "                 empty_indices_sing_test, x_test_sing_normal_2, x_test_sing_tokenized_2 ], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfu3aE2T7H41"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji.pkl', 'rb') as f:  \n",
        "    x_train_sing_tokenized, x_train_sing_normal, x_val_sing_tokenized, x_val_sing_normal, x_test_sing_tokenized, x_test_sing_normal, empty_indices_sing_train, x_train_sing_tokenized_2, \\\n",
        "                 x_train_sing_normal_2, empty_indices_sing_val, x_val_sing_tokenized_2, x_val_sing_normal_2, y_sing_train, y_sing_val, y_train_sing_2, y_val_sing_2, y_sing_test, y_test_sing_2,\\\n",
        "                 empty_indices_sing_test, x_test_sing_normal_2, x_test_sing_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbZ32AnX9sXR",
        "outputId": "c6dc079a-29f8-4109-c764-9bd2bcfc8f7b"
      },
      "source": [
        "len(x_train_sing_tokenized_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCKzMv5F66aY"
      },
      "source": [
        "X_train_sing_w2vec = convert_word2vec(word2vec, x_train_sing_tokenized_2, strategy='mean')\n",
        "X_val_sing_w2vec = convert_word2vec(word2vec, x_val_sing_tokenized_2, strategy='mean')\n",
        "X_test_sing_w2vec = convert_word2vec(word2vec, x_test_sing_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-eC3wmv66fX"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_sing_train['emoji_sentence_list'] = df_sing_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_sing_train = df_sing_train['emoji_sentence_list'].values\n",
        "\n",
        "df_sing_val['emoji_sentence_list'] = df_sing_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_sing_val = df_sing_val['emoji_sentence_list'].values\n",
        "\n",
        "df_sing_test['emoji_sentence_list'] = df_sing_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_sing_test = df_sing_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkZOFmbZ66j9"
      },
      "source": [
        "X_train_sing_e2vec = convert_emoji2vec(e2v, emoji_corpus_sing_train, strategy='mean')\n",
        "X_val_sing_e2vec = convert_emoji2vec(e2v, emoji_corpus_sing_val, strategy='mean')\n",
        "X_test_sing_e2vec = convert_emoji2vec(e2v, emoji_corpus_sing_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5B_8QeZ8S91",
        "outputId": "7314a22e-1956-44a8-e62b-565896987b8e"
      },
      "source": [
        "print(len(X_train_sing_w2vec))\n",
        "print(len(X_train_sing_w2vec[4]))\n",
        "\n",
        "print(len(X_val_sing_w2vec))\n",
        "print(len(X_val_sing_w2vec[4]))\n",
        "\n",
        "print(len(X_test_sing_w2vec))\n",
        "print(len(X_test_sing_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15015\n",
            "300\n",
            "2153\n",
            "300\n",
            "4341\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al3zV9Qe8TB0",
        "outputId": "72143b7c-18b1-49a4-c53f-229be21309ba"
      },
      "source": [
        "print(len(X_train_sing_e2vec))\n",
        "print(len(X_train_sing_e2vec[4]))\n",
        "\n",
        "print(len(X_val_sing_e2vec))\n",
        "print(len(X_val_sing_e2vec[4]))\n",
        "\n",
        "print(len(X_test_sing_e2vec))\n",
        "print(len(X_test_sing_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15015\n",
            "300\n",
            "2153\n",
            "300\n",
            "4341\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB8nhFLGbj7p"
      },
      "source": [
        "#### Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krigRs6z87So"
      },
      "source": [
        "X_train_sing_vec = (np.array(X_train_sing_w2vec) + np.array(X_train_sing_e2vec))/2\n",
        "X_val_sing_vec = (np.array(X_val_sing_w2vec) + np.array(X_val_sing_e2vec))/2\n",
        "X_test_sing_vec = (np.array(X_test_sing_w2vec) + np.array(X_test_sing_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi-L4mHI87XZ"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_sing_vec, X_val_sing_vec, X_test_sing_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd7GQKsE87e4"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec.pkl', 'rb') as f:  \n",
        "    X_train_sing_vec, X_val_sing_vec, X_test_sing_vec = pickle.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WwMp9oobnc3"
      },
      "source": [
        "#### Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcKY4UsN0ous"
      },
      "source": [
        "X_train_sing_vec_concat = np.concatenate((X_train_sing_w2vec, X_train_sing_e2vec), axis=1) \n",
        "X_val_sing_vec_concat  = np.concatenate((X_val_sing_w2vec, X_val_sing_e2vec), axis=1) \n",
        "X_test_sing_vec_concat  = np.concatenate((X_test_sing_w2vec, X_test_sing_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJ02Ci4brbq"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec_concat.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_sing_vec_concat, X_val_sing_vec_concat, X_test_sing_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lkXVR32brgd"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec_concat.pkl', 'rb') as f:  \n",
        "    X_train_sing_vec_concat, X_val_sing_vec_concat, X_test_sing_vec_concat = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWED9-T91BBc"
      },
      "source": [
        "## (ONLY) MULTI EMOJIS WITH REPEATS - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dClnKTpX1HD4"
      },
      "source": [
        "df_mul_repeat_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/multi_emoji/emoji_nsp_dataset_multi_emoji_train.csv')\n",
        "df_mul_repeat_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/multi_emoji/emoji_nsp_dataset_multi_emoji_valid.csv')\n",
        "df_mul_repeat_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/multi_emoji/emoji_nsp_dataset_multi_emoji_test.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TIGjSwgy1HGz",
        "outputId": "b2c18d57-03d0-42d5-d159-c2eabbdeab65"
      },
      "source": [
        "df_mul_repeat_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6704</td>\n",
              "      <td>good morning [USER] you woke up so early  anyw...</td>\n",
              "      <td>ğŸ˜¶ğŸ˜ŠğŸ’š</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10651</td>\n",
              "      <td>MVP  4x Scoring champ  3x All NBA FIRST TEAM 3...</td>\n",
              "      <td>âœ…âœ…âœ…âœ…</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6345</td>\n",
              "      <td>[USER] Your tears baby boy ...Sleep sad</td>\n",
              "      <td>ğŸŒšğŸŒšğŸ‘Œ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5268</td>\n",
              "      <td>15 php ---&amp;gt; Follow [USER] ---&amp;gt; RT &amp;amp; ...</td>\n",
              "      <td>ğŸ’—ğŸ“Œ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5897</td>\n",
              "      <td>this emoji looks like sia</td>\n",
              "      <td>ğŸ˜­ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™ğŸ™</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0   6704  ...        1\n",
              "1  10651  ...        1\n",
              "2   6345  ...        1\n",
              "3   5268  ...        1\n",
              "4   5897  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHdzG_ny1HJR",
        "outputId": "16759c9e-0096-4f7a-d565-dc66625f22f6"
      },
      "source": [
        "print(len(df_mul_repeat_train))\n",
        "print(len(df_mul_repeat_val))\n",
        "print(len(df_mul_repeat_test))\n",
        "\n",
        "df_mul_repeat_train = df_mul_repeat_train.dropna().drop_duplicates()\n",
        "df_mul_repeat_val = df_mul_repeat_val.dropna().drop_duplicates()\n",
        "df_mul_repeat_test = df_mul_repeat_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_mul_repeat_train))\n",
        "print(len(df_mul_repeat_val))\n",
        "print(len(df_mul_repeat_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16801\n",
            "2401\n",
            "4800\n",
            "16801\n",
            "2401\n",
            "4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9fJOj3M1HMr",
        "outputId": "e4d98d84-a632-48af-dcad-585128ae134f"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_mul_repeat_tokenized, x_train_mul_repeat_normal = clean_text(df_mul_repeat_train['tweets'].values)\n",
        "x_val_mul_repeat_tokenized, x_val_mul_repeat_normal = clean_text(df_mul_repeat_val['tweets'].values)\n",
        "x_test_mul_repeat_tokenized, x_test_mul_repeat_normal = clean_text(df_mul_repeat_test['tweets'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.010810375213623047\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.1181480884552002\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.03280997276306152\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  2.2395598888397217\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0016427040100097656\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.01767277717590332\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.004660844802856445\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.321491003036499\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0034494400024414062\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.03859567642211914\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.009351968765258789\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.6670784950256348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHe_Lu8A3DdZ"
      },
      "source": [
        "y_mul_repeat_train = df_mul_repeat_train['follows?'].values\n",
        "y_mul_repeat_val = df_mul_repeat_val['follows?'].values\n",
        "y_mul_repeat_test = df_mul_repeat_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmM9dPN4EYgm",
        "outputId": "c8c34004-ef23-4943-d1ce-0ea5d3553c43"
      },
      "source": [
        "df_mul_repeat_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4789, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KqsKFZqxEfSO",
        "outputId": "77ac71cf-5b3f-4d11-8a63-884c7268c9c0"
      },
      "source": [
        "df_mul_repeat_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20092</td>\n",
              "      <td>[USER] CONGRATS! This is...SO CUTE...//clenche...</td>\n",
              "      <td>ğŸ’ğŸ™ŒğŸš€</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12536</td>\n",
              "      <td>Hair Appt Booked  Just Need To Go Shopping For...</td>\n",
              "      <td>âœŠğŸ½</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394</td>\n",
              "      <td>[USER] Lmao so true 3 for y'all 1 for usHoping...</td>\n",
              "      <td>ğŸ’™âœ¨</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8301</td>\n",
              "      <td>[USER] Happy happy birthday!!! . Your day soun...</td>\n",
              "      <td>ğŸ‰ğŸ‰ğŸ‰ğŸ¤¯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1226</td>\n",
              "      <td>My coworker hates going to restaurants with me...</td>\n",
              "      <td>ğŸ®ğŸ’œ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  20092  ...        0\n",
              "1  12536  ...        0\n",
              "2    394  ...        1\n",
              "3   8301  ...        1\n",
              "4   1226  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEkXCvSnEILf",
        "outputId": "26132861-8baf-4ae2-caef-f22e5d908f84"
      },
      "source": [
        "print(len(x_test_mul_repeat_tokenized))\n",
        "print(len(y_mul_repeat_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4789\n",
            "4789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBVTkrz3Dg8"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_mul_repeat_2 = []\n",
        "x_train_mul_repeat_tokenized_2 = []\n",
        "x_train_mul_repeat_normal_2 = []\n",
        "empty_indices_mul_repeat_train = []\n",
        "\n",
        "for i in range(len(x_train_mul_repeat_tokenized)):\n",
        "  if len(x_train_mul_repeat_tokenized[i])==0:\n",
        "    empty_indices_mul_repeat_train.append(i)\n",
        "  else:\n",
        "    x_train_mul_repeat_tokenized_2.append(x_train_mul_repeat_tokenized[i])\n",
        "    x_train_mul_repeat_normal_2.append(x_train_mul_repeat_normal[i])\n",
        "    y_train_mul_repeat_2.append(y_mul_repeat_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAHZ1Bw-3Dkh"
      },
      "source": [
        "#remove empty values for val \n",
        "y_val_mul_repeat_2 = []\n",
        "x_val_mul_repeat_tokenized_2 = []\n",
        "x_val_mul_repeat_normal_2 = []\n",
        "empty_indices_mul_repeat_val = []\n",
        "\n",
        "for i in range(len(x_val_mul_repeat_tokenized)):\n",
        "  if len(x_val_mul_repeat_tokenized[i])==0:\n",
        "    empty_indices_mul_repeat_val.append(i)\n",
        "  else:\n",
        "    x_val_mul_repeat_tokenized_2.append(x_val_mul_repeat_tokenized[i])\n",
        "    x_val_mul_repeat_normal_2.append(x_val_mul_repeat_normal[i])\n",
        "    y_val_mul_repeat_2.append(y_mul_repeat_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJl-PaH5hCl"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_mul_repeat_2 = []\n",
        "x_test_mul_repeat_tokenized_2 = []\n",
        "x_test_mul_repeat_normal_2 = []\n",
        "empty_indices_mul_repeat_test = []\n",
        "\n",
        "for i in range(len(x_test_mul_repeat_tokenized)):\n",
        "  if len(x_test_mul_repeat_tokenized[i])==0:\n",
        "    empty_indices_mul_repeat_test.append(i)\n",
        "  else:\n",
        "    x_test_mul_repeat_tokenized_2.append(x_test_mul_repeat_tokenized[i])\n",
        "    x_test_mul_repeat_normal_2.append(x_test_mul_repeat_normal[i])\n",
        "    y_test_mul_repeat_2.append(y_mul_repeat_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyTLTBi_5hGI",
        "outputId": "c6d10b30-3a82-43b0-e700-105ff8902456"
      },
      "source": [
        "print(empty_indices_mul_repeat_train)\n",
        "print(len(empty_indices_mul_repeat_train))\n",
        "print(len(x_train_mul_repeat_tokenized))\n",
        "print(len(x_train_mul_repeat_tokenized_2))\n",
        "print(len(x_train_mul_repeat_normal_2))\n",
        "print(len(y_train_mul_repeat_2))\n",
        "\n",
        "print(empty_indices_mul_repeat_val)\n",
        "print(len(empty_indices_mul_repeat_val))\n",
        "print(len(x_val_mul_repeat_tokenized))\n",
        "print(len(x_val_mul_repeat_tokenized_2))\n",
        "print(len(x_val_mul_repeat_normal_2))\n",
        "print(len(y_val_mul_repeat_2))\n",
        "\n",
        "print(empty_indices_mul_repeat_test)\n",
        "print(len(empty_indices_mul_repeat_test))\n",
        "print(len(x_test_mul_repeat_tokenized))\n",
        "print(len(x_test_mul_repeat_tokenized_2))\n",
        "print(len(x_test_mul_repeat_normal_2))\n",
        "print(len(y_test_mul_repeat_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "16801\n",
            "16801\n",
            "16801\n",
            "16801\n",
            "[]\n",
            "0\n",
            "2401\n",
            "2401\n",
            "2401\n",
            "2401\n",
            "[]\n",
            "0\n",
            "4800\n",
            "4800\n",
            "4800\n",
            "4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEcWNim65hKD"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_mul_repeat_tokenized, x_train_mul_repeat_normal, x_val_mul_repeat_tokenized, x_val_mul_repeat_normal, x_test_mul_repeat_tokenized, x_test_mul_repeat_normal, empty_indices_mul_repeat_train, x_train_mul_repeat_tokenized_2, \\\n",
        "                 x_train_mul_repeat_normal_2, empty_indices_mul_repeat_val, x_val_mul_repeat_tokenized_2, x_val_mul_repeat_normal_2, y_mul_repeat_train, y_mul_repeat_val, y_train_mul_repeat_2, y_val_mul_repeat_2, y_mul_repeat_test, y_test_mul_repeat_2,\\\n",
        "                 empty_indices_mul_repeat_test, x_test_mul_repeat_normal_2, x_test_mul_repeat_tokenized_2], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHcNhCY8KySi"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis.pkl', 'rb') as f:  \n",
        "    x_train_mul_repeat_tokenized, x_train_mul_repeat_normal, x_val_mul_repeat_tokenized, x_val_mul_repeat_normal, x_test_mul_repeat_tokenized, x_test_mul_repeat_normal, empty_indices_mul_repeat_train, x_train_mul_repeat_tokenized_2, \\\n",
        "                 x_train_mul_repeat_normal_2, empty_indices_mul_repeat_val, x_val_mul_repeat_tokenized_2, x_val_mul_repeat_normal_2, y_mul_repeat_train, y_mul_repeat_val, y_train_mul_repeat_2, y_val_mul_repeat_2, y_mul_repeat_test, y_test_mul_repeat_2,\\\n",
        "                 empty_indices_mul_repeat_test, x_test_mul_repeat_normal_2, x_test_mul_repeat_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMpUokhqKyWf"
      },
      "source": [
        "X_train_mul_repeat_w2vec = convert_word2vec(word2vec, x_train_mul_repeat_tokenized_2, strategy='mean')\n",
        "X_val_mul_repeat_w2vec = convert_word2vec(word2vec, x_val_mul_repeat_tokenized_2, strategy='mean')\n",
        "X_test_mul_repeat_w2vec = convert_word2vec(word2vec, x_test_mul_repeat_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZIfBBfhK7Q8"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_mul_repeat_train['emoji_sentence_list'] = df_mul_repeat_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_repeat_train = df_mul_repeat_train['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_repeat_val['emoji_sentence_list'] = df_mul_repeat_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_repeat_val = df_mul_repeat_val['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_repeat_test['emoji_sentence_list'] = df_mul_repeat_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_repeat_test = df_mul_repeat_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxdaL-YK7U0"
      },
      "source": [
        "X_train_mul_repeat_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_repeat_train, strategy='mean')\n",
        "X_val_mul_repeat_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_repeat_val, strategy='mean')\n",
        "X_test_mul_repeat_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_repeat_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORDwv4g5KybJ",
        "outputId": "a2f2f940-9812-4556-ccaf-76fd5bfe70a5"
      },
      "source": [
        "print(len(X_train_mul_repeat_w2vec))\n",
        "print(len(X_train_mul_repeat_w2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_repeat_w2vec))\n",
        "print(len(X_val_mul_repeat_w2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_repeat_w2vec))\n",
        "print(len(X_test_mul_repeat_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16801\n",
            "300\n",
            "2401\n",
            "300\n",
            "4800\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MRmFUFmLHBR",
        "outputId": "cbd785ca-06f8-4afa-d3aa-f22d64306fad"
      },
      "source": [
        "print(len(X_train_mul_repeat_e2vec))\n",
        "print(len(X_train_mul_repeat_e2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_repeat_e2vec))\n",
        "print(len(X_val_mul_repeat_e2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_repeat_e2vec))\n",
        "print(len(X_test_mul_repeat_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16801\n",
            "300\n",
            "2401\n",
            "300\n",
            "4800\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fumuF82McSFz"
      },
      "source": [
        "#### Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpCaYdLzLHFI"
      },
      "source": [
        "X_train_mul_repeat_vec = (np.array(X_train_mul_repeat_w2vec) + np.array(X_train_mul_repeat_e2vec))/2\n",
        "X_val_mul_repeat_vec = (np.array(X_val_mul_repeat_w2vec) + np.array(X_val_mul_repeat_e2vec))/2\n",
        "X_test_mul_repeat_vec = (np.array(X_test_mul_repeat_w2vec) + np.array(X_test_mul_repeat_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQp-nCDELNGw"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_repeat_vec, X_val_mul_repeat_vec, X_test_mul_repeat_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXwiN2kLNKC"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_repeat_vec, X_val_mul_repeat_vec, X_test_mul_repeat_vec = pickle.load(f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty0XEM88cVDv"
      },
      "source": [
        "#### Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMnVCthj3Dn2"
      },
      "source": [
        "X_train_mul_repeat_vec_concat = np.concatenate((X_train_mul_repeat_w2vec, X_train_mul_repeat_e2vec), axis=1) \n",
        "X_val_mul_repeat_vec_concat  = np.concatenate((X_val_mul_repeat_w2vec, X_val_mul_repeat_e2vec), axis=1) \n",
        "X_test_mul_repeat_vec_concat  = np.concatenate((X_test_mul_repeat_w2vec, X_test_mul_repeat_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdRVmNWOcXbq"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_repeat_vec_concat, X_val_mul_repeat_vec_concat, X_test_mul_repeat_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEQ6Ht02cXgh"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_repeat_vec_concat, X_val_mul_repeat_vec_concat, X_test_mul_repeat_vec_concat = pickle.load(f)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ons1B4P1EqR"
      },
      "source": [
        "## FULL DATA (SINGLE AND MULTI) WITH NO REPEATS - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A7rZZzF1KPy"
      },
      "source": [
        "df_mul_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/no_repeats/emoji_nsp_dataset_no_repeats_train.csv')\n",
        "df_mul_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/no_repeats/emoji_nsp_dataset_no_repeats_valid.csv')\n",
        "df_mul_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/no_repeats/emoji_nsp_dataset_no_repeats_test.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dGECt3HO1Kfk",
        "outputId": "8e8aada5-9edf-46fb-dce3-26e0d13808e6"
      },
      "source": [
        "df_mul_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50553</td>\n",
              "      <td>The dababy memes make no sense and thatâ€™s why ...</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>74541</td>\n",
              "      <td>a year ago today i would be holding my breath ...</td>\n",
              "      <td>ğŸ™</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50992</td>\n",
              "      <td>I told my mama about how the music industry is...</td>\n",
              "      <td>ğŸ’¯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95343</td>\n",
              "      <td>[USER] [USER] Thankyou guys</td>\n",
              "      <td>ğŸ’€</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60555</td>\n",
              "      <td>You want new SUBS? Like ï¸ Retweet Follow me  R...</td>\n",
              "      <td>ğŸ˜¬</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  50553  ...        1\n",
              "1  74541  ...        0\n",
              "2  50992  ...        1\n",
              "3  95343  ...        0\n",
              "4  60555  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjgLJHO_1Ki2",
        "outputId": "047e9b24-5bb5-49d2-9299-883a7f2ce991"
      },
      "source": [
        "print(len(df_mul_train))\n",
        "print(len(df_mul_val))\n",
        "print(len(df_mul_test))\n",
        "\n",
        "df_mul_train = df_mul_train.dropna().drop_duplicates()\n",
        "df_mul_val = df_mul_val.dropna().drop_duplicates()\n",
        "df_mul_test = df_mul_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_mul_train))\n",
        "print(len(df_mul_val))\n",
        "print(len(df_mul_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15475\n",
            "2229\n",
            "4433\n",
            "15475\n",
            "2229\n",
            "4433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATl6Dp2B1Klb",
        "outputId": "4940db8a-9566-419a-bb10-478f10a07cb1"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_mul_tokenized, x_train_mul_normal = clean_text(df_mul_train['tweets'].values)\n",
        "x_val_mul_tokenized, x_val_mul_normal = clean_text(df_mul_val['tweets'].values)\n",
        "x_test_mul_tokenized, x_test_mul_normal = clean_text(df_mul_test['tweets'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.014504194259643555\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.08419013023376465\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.024480104446411133\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  1.8592925071716309\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.000911712646484375\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.012573957443237305\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.0032439231872558594\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.26091432571411133\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0018279552459716797\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.024820804595947266\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.008264541625976562\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.5202980041503906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOxMVEsl3FNe"
      },
      "source": [
        "y_mul_train = df_mul_train['follows?'].values\n",
        "y_mul_val = df_mul_val['follows?'].values\n",
        "y_mul_test = df_mul_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW89ftqe3FQ9"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_mul_2 = []\n",
        "x_train_mul_tokenized_2 = []\n",
        "x_train_mul_normal_2 = []\n",
        "empty_indices_mul_train = []\n",
        "\n",
        "for i in range(len(x_train_mul_tokenized)):\n",
        "  if len(x_train_mul_tokenized[i])==0:\n",
        "    empty_indices_mul_train.append(i)\n",
        "  else:\n",
        "    x_train_mul_tokenized_2.append(x_train_mul_tokenized[i])\n",
        "    x_train_mul_normal_2.append(x_train_mul_normal[i])\n",
        "    y_train_mul_2.append(y_mul_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYJYi5V_3FT3"
      },
      "source": [
        "#remove empty values for val\n",
        "y_val_mul_2 = []\n",
        "x_val_mul_tokenized_2 = []\n",
        "x_val_mul_normal_2 = []\n",
        "empty_indices_mul_val = []\n",
        "\n",
        "for i in range(len(x_val_mul_tokenized)):\n",
        "  if len(x_val_mul_tokenized[i])==0:\n",
        "    empty_indices_mul_val.append(i)\n",
        "  else:\n",
        "    x_val_mul_tokenized_2.append(x_val_mul_tokenized[i])\n",
        "    x_val_mul_normal_2.append(x_val_mul_normal[i])\n",
        "    y_val_mul_2.append(y_mul_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IhXAiW5i4E"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_mul_2 = []\n",
        "x_test_mul_tokenized_2 = []\n",
        "x_test_mul_normal_2 = []\n",
        "empty_indices_mul_test = []\n",
        "\n",
        "for i in range(len(x_test_mul_tokenized)):\n",
        "  if len(x_test_mul_tokenized[i])==0:\n",
        "    empty_indices_mul_test.append(i)\n",
        "  else:\n",
        "    x_test_mul_tokenized_2.append(x_test_mul_tokenized[i])\n",
        "    x_test_mul_normal_2.append(x_test_mul_normal[i])\n",
        "    y_test_mul_2.append(y_mul_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVO6tw575i7p",
        "outputId": "ae78add1-50bb-41ff-a027-83ba22c17582"
      },
      "source": [
        "print(empty_indices_mul_train)\n",
        "print(len(empty_indices_mul_train))\n",
        "print(len(x_train_mul_tokenized))\n",
        "print(len(x_train_mul_tokenized_2))\n",
        "print(len(x_train_mul_normal_2))\n",
        "print(len(y_train_mul_2))\n",
        "\n",
        "print(empty_indices_mul_val)\n",
        "print(len(empty_indices_mul_val))\n",
        "print(len(x_val_mul_tokenized))\n",
        "print(len(x_val_mul_tokenized_2))\n",
        "print(len(x_val_mul_normal_2))\n",
        "print(len(y_val_mul_2))\n",
        "\n",
        "print(empty_indices_mul_test)\n",
        "print(len(empty_indices_mul_test))\n",
        "print(len(x_test_mul_tokenized))\n",
        "print(len(x_test_mul_tokenized_2))\n",
        "print(len(x_test_mul_normal_2))\n",
        "print(len(y_test_mul_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "15475\n",
            "15475\n",
            "15475\n",
            "15475\n",
            "[]\n",
            "0\n",
            "2229\n",
            "2229\n",
            "2229\n",
            "2229\n",
            "[]\n",
            "0\n",
            "4433\n",
            "4433\n",
            "4433\n",
            "4433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GZ2k7npO5Bx"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_mul_tokenized, x_train_mul_normal, x_val_mul_tokenized, x_val_mul_normal, x_test_mul_tokenized, x_test_mul_normal, empty_indices_mul_train, x_train_mul_tokenized_2, \\\n",
        "                 x_train_mul_normal_2, empty_indices_mul_val, x_val_mul_tokenized_2, x_val_mul_normal_2, y_mul_train, y_mul_val, y_train_mul_2, y_val_mul_2, y_mul_test, y_test_mul_2,\\\n",
        "                 empty_indices_mul_test, x_test_mul_normal_2, x_test_mul_tokenized_2], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlP3XYPDO5GG"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis.pkl', 'rb') as f:  \n",
        "    x_train_mul_tokenized, x_train_mul_normal, x_val_mul_tokenized, x_val_mul_normal, x_test_mul_tokenized, x_test_mul_normal, empty_indices_mul_train, x_train_mul_tokenized_2, \\\n",
        "                 x_train_mul_normal_2, empty_indices_mul_val, x_val_mul_tokenized_2, x_val_mul_normal_2, y_mul_train, y_mul_val, y_train_mul_2, y_val_mul_2, y_mul_test, y_test_mul_2,\\\n",
        "                 empty_indices_mul_test, x_test_mul_normal_2, x_test_mul_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeUzJvzjO5KN"
      },
      "source": [
        "X_train_mul_w2vec = convert_word2vec(word2vec, x_train_mul_tokenized_2, strategy='mean')\n",
        "X_val_mul_w2vec = convert_word2vec(word2vec, x_val_mul_tokenized_2, strategy='mean')\n",
        "X_test_mul_w2vec = convert_word2vec(word2vec, x_test_mul_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTeLkMWZO5RB"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_mul_train['emoji_sentence_list'] = df_mul_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_train = df_mul_train['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_val['emoji_sentence_list'] = df_mul_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_val = df_mul_val['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_test['emoji_sentence_list'] = df_mul_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_test = df_mul_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaH825a4O5Ve"
      },
      "source": [
        "X_train_mul_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_train, strategy='mean')\n",
        "X_val_mul_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_val, strategy='mean')\n",
        "X_test_mul_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-bLILP5jBg",
        "outputId": "bc8d7b10-16be-4ca0-fef4-b80c853ff22a"
      },
      "source": [
        "print(len(X_train_mul_w2vec))\n",
        "print(len(X_train_mul_w2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_w2vec))\n",
        "print(len(X_val_mul_w2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_w2vec))\n",
        "print(len(X_test_mul_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15475\n",
            "300\n",
            "2229\n",
            "300\n",
            "4433\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9hS1zRIPK6D",
        "outputId": "b84245bf-c6ea-4ab9-fde4-977d0949779d"
      },
      "source": [
        "print(len(X_train_mul_e2vec))\n",
        "print(len(X_train_mul_e2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_e2vec))\n",
        "print(len(X_val_mul_e2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_e2vec))\n",
        "print(len(X_test_mul_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15475\n",
            "300\n",
            "2229\n",
            "300\n",
            "4433\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pe5JYUocxfh"
      },
      "source": [
        "#### Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVRlEsh5PK-e"
      },
      "source": [
        "X_train_mul_vec = (np.array(X_train_mul_w2vec) + np.array(X_train_mul_e2vec))/2\n",
        "X_val_mul_vec = (np.array(X_val_mul_w2vec) + np.array(X_val_mul_e2vec))/2\n",
        "X_test_mul_vec = (np.array(X_test_mul_w2vec) + np.array(X_test_mul_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf9jZyZEPRMD"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_vec, X_val_mul_vec, X_test_mul_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unYdKmdvPRQ9"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_vec, X_val_mul_vec, X_test_mul_vec = pickle.load(f)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgqpUpnFc1ET"
      },
      "source": [
        "#### Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qHS0wqA1Koi"
      },
      "source": [
        "X_train_mul_vec_concat = np.concatenate((X_train_mul_w2vec, X_train_mul_e2vec), axis=1) \n",
        "X_val_mul_vec_concat  = np.concatenate((X_val_mul_w2vec, X_val_mul_e2vec), axis=1) \n",
        "X_test_mul_vec_concat  = np.concatenate((X_test_mul_w2vec, X_test_mul_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XN_AZ-Ac4Pb"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_vec_concat, X_val_mul_vec_concat, X_test_mul_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8YK-WvQc4VI"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_vec_concat, X_val_mul_vec_concat, X_test_mul_vec_concat = pickle.load(f)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI-zJq7rPXl5"
      },
      "source": [
        "## LogisticRegression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIjbDVtyngjP"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "def metric(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "my_scorer = make_scorer(metric, greater_is_better=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FWaT4WfnoD1"
      },
      "source": [
        "def run_model(model, X_train, y_train, X_val, y_val):\n",
        "  print('     ## Fitting')\n",
        "  model.fit(X_train, y_train)\n",
        "  print('     ## Predicting')\n",
        "  preds = model.predict(X_val)\n",
        "  print(' ## F1 Score (weighted) is -', f1_score(y_val, preds, average='weighted'))\n",
        "  print(' ## Accuracy is -', accuracy_score(y_val, preds))\n",
        "  print('      ')\n",
        "  print('               Confusion Matrix')\n",
        "  print(confusion_matrix(y_val, preds))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD7i47THCe55"
      },
      "source": [
        "lr = LogisticRegression()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nQWK7vPNmt2"
      },
      "source": [
        "def run_model_gridsearch_lr(model, X_train, y_train, X_val, y_val):\n",
        "  \n",
        "  cv=5\n",
        "  parameters = {'C': np.logspace(0, 4, 10),'penalty': ['l1', 'l2']}\n",
        "  clf = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, scoring=my_scorer, verbose=0)\n",
        "  print(' ## Fitting GridSearch')\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  print(\"tuned hpyerparameters :(best parameters) \",clf.best_params_)\n",
        "  print(\"score :\",clf.best_score_)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBDZOzkEVmZ6"
      },
      "source": [
        "def scores(y_val, preds):\n",
        "  print(' ## F1 Score (weighted) is -', f1_score(y_val, preds, average='weighted'))\n",
        "  print(' ## Accuracy is -', accuracy_score(y_val, preds))\n",
        "  print('      ')\n",
        "  print('               Confusion Matrix')\n",
        "  print(confusion_matrix(y_val, preds))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMXorfACy5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8REJot7IyKF"
      },
      "source": [
        "###**LR with FULL DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCAa_Nu8ibFJ"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4hCXxbB_-1",
        "outputId": "dffda13a-53af-4612-c9b5-2e952a7fa075"
      },
      "source": [
        "# BASELINE\n",
        "run_model(lr, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5179993984471877\n",
            " ## Accuracy is - 0.517962710322874\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[558 522]\n",
            " [538 581]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcmFPx_-ydzC",
        "outputId": "45bea908-1241-401b-e66d-47a6b10904b6"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 3593.813663804626, 'penalty': 'l2'}\n",
            "score : 0.515086937552015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-tEwZYpyuwG",
        "outputId": "905e9fce-a889-4ee4-942e-4720dd3860a8"
      },
      "source": [
        "# FINESUNED \n",
        "best_lr_full = LogisticRegression(penalty = 'l2', C = 3593.813663804626)\n",
        "run_model(best_lr_full, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5197692060167853\n",
            " ## Accuracy is - 0.519781718963165\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[573 507]\n",
            " [549 570]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhNBPqZAdcAm"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLEgDzghxkC9",
        "outputId": "b91023c9-614e-419d-d984-b24098581369"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_full_base = lr.predict(X_test_vec)\n",
        "pred_lr_full_prob_base = lr.predict_proba(X_test_vec)\n",
        "scores(y_test, pred_lr_full_base)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5173889777206634\n",
            " ## Accuracy is - 0.5173501577287066\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1170 1089]\n",
            " [1053 1126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9zBdLT-ddh9",
        "outputId": "7529bf67-5b4b-46b7-ef2a-082506183177"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_full = best_lr_full.predict(X_test_vec)\n",
        "pred_lr_full_prob = best_lr_full.predict_proba(X_test_vec)\n",
        "scores(y_test, pred_lr_full)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5245992385409034\n",
            " ## Accuracy is - 0.5245606128886886\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1184 1075]\n",
            " [1035 1144]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAqvlY2teoUG",
        "outputId": "aa2b33ee-cdaf-4b59-edc9-c945bca6e43b"
      },
      "source": [
        "pred_lr_full_prob #[prob for class0, prob for class1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45513382, 0.54486618],\n",
              "       [0.4308906 , 0.5691094 ],\n",
              "       [0.37023349, 0.62976651],\n",
              "       ...,\n",
              "       [0.50978928, 0.49021072],\n",
              "       [0.5311429 , 0.4688571 ],\n",
              "       [0.40109193, 0.59890807]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLkaHBPAioHf"
      },
      "source": [
        "#### With Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgcuWGXQitTR",
        "outputId": "0a41099e-b931-46a8-dc5e-3c73691c27be"
      },
      "source": [
        "#BASELINE\n",
        "run_model(lr, X_train_vec_concat, y_train, X_val_vec_concat, y_val)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5179993984471877\n",
            " ## Accuracy is - 0.517962710322874\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[558 522]\n",
            " [538 581]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c94Zon6itWo",
        "outputId": "c95b7425-5447-4ddd-da23-d9a6de3dd0bb"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_vec_concat, y_train, X_val_vec_concat, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 2.7825594022071245, 'penalty': 'l2'}\n",
            "score : 0.5128374049413716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M9B0C7Sitac",
        "outputId": "9af127cf-3785-41af-8399-36e54b1c5b1b"
      },
      "source": [
        "#FINETUNED\n",
        "best_lr_full_concat = LogisticRegression(penalty = 'l2', C = 2.7825594022071245)\n",
        "run_model(best_lr_full_concat, X_train_vec_concat, y_train, X_val_vec_concat, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5178031935717086\n",
            " ## Accuracy is - 0.517962710322874\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[582 498]\n",
            " [562 557]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhZ0-oj-WZlM"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrCey4dn0_y8",
        "outputId": "dd662c05-b03e-41c0-fb9b-4ad19d467a01"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_full_concat_base = lr.predict(X_test_vec_concat)\n",
        "pred_lr_full_prob_concat_base = lr.predict_proba(X_test_vec_concat)\n",
        "scores(y_test, pred_lr_full_concat_base)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5173889777206634\n",
            " ## Accuracy is - 0.5173501577287066\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1170 1089]\n",
            " [1053 1126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuSxn4XeWZtq",
        "outputId": "09f20902-7cd9-46c6-edd7-5a0c28fd0cff"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_full_concat = best_lr_full_concat.predict(X_test_vec_concat)\n",
        "pred_lr_full_prob_concat = best_lr_full_concat.predict_proba(X_test_vec_concat)\n",
        "scores(y_test, pred_lr_full_concat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5200812782739727\n",
            " ## Accuracy is - 0.5200540784136999\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1185 1074]\n",
            " [1056 1123]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbvsc9MMDlsx",
        "outputId": "d84667fc-4a3c-47c0-e3c0-84329233ae85"
      },
      "source": [
        "pred_lr_full_prob_concat #[prob for class0, prob for class1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43541843, 0.56458157],\n",
              "       [0.4205097 , 0.5794903 ],\n",
              "       [0.26461422, 0.73538578],\n",
              "       ...,\n",
              "       [0.46542256, 0.53457744],\n",
              "       [0.51649599, 0.48350401],\n",
              "       [0.43416939, 0.56583061]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOn69JY3I05t"
      },
      "source": [
        "###**LR with SINGLE EMOJI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1okP-t7hdOqo"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-qKUF1dC6KJ",
        "outputId": "1ebe0779-d2ed-45aa-b935-bf1fe7533b54"
      },
      "source": [
        "# FOR SINGLE EMOJI\n",
        "run_model(lr, X_train_sing_vec, y_sing_train, X_val_sing_vec, y_sing_val)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5049510032156806\n",
            " ## Accuracy is - 0.5058058522991176\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[506 584]\n",
            " [480 583]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz8aKKsHNttO",
        "outputId": "cfeb8208-ee24-4e9b-c32e-f821efcf2684"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_sing_vec, y_sing_train, X_val_sing_vec, y_sing_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 10000.0, 'penalty': 'l2'}\n",
            "score : 0.5031135666609666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D8mPpS4NtxI",
        "outputId": "047a3165-0ade-4f08-bfa4-479c78e8bb7e"
      },
      "source": [
        "best_lr_sing = LogisticRegression(penalty = 'l2', C = 10000.0)\n",
        "run_model(best_lr_sing, X_train_sing_vec, y_sing_train, X_val_sing_vec, y_sing_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5021978592440751\n",
            " ## Accuracy is - 0.5030190431955411\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[504 586]\n",
            " [484 579]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffo8DIZXWHcL"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yJDZl6r1mu_",
        "outputId": "61aa2af2-068e-474c-c0ef-8fe6662c8057"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_sing_base = lr.predict(X_test_sing_vec)\n",
        "pred_lr_sing_prob_base = lr.predict_proba(X_test_sing_vec)\n",
        "scores(y_sing_test, pred_lr_sing_base)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.4869595082363849\n",
            " ## Accuracy is - 0.48721492743607464\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1023 1181]\n",
            " [1045 1092]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCuXoh_bWHkY",
        "outputId": "6388958b-cfae-41cc-f591-a6dc5b42935d"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_sing = best_lr_sing.predict(X_test_sing_vec)\n",
        "scores(y_sing_test, pred_lr_sing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.4878466603498624\n",
            " ## Accuracy is - 0.4879060124395301\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1047 1157]\n",
            " [1066 1071]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1lcjPsfZoq"
      },
      "source": [
        "#### With Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0FQyfa2fbKg",
        "outputId": "26cb37a4-5583-4015-90f6-ea061c7eac1d"
      },
      "source": [
        "run_model(lr, X_train_sing_vec_concat, y_sing_train, X_val_sing_vec_concat, y_sing_val)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.4998031042482971\n",
            " ## Accuracy is - 0.5002322340919647\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[513 577]\n",
            " [499 564]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_uI7KM2fpRh",
        "outputId": "24f0cbd6-8301-4a0e-9a73-fb3953536b2a"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_sing_vec_concat, y_sing_train, X_val_sing_vec_concat, y_sing_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 21.544346900318832, 'penalty': 'l2'}\n",
            "score : 0.5051196878848289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP0pgQ8ffpW9",
        "outputId": "6d1331e2-b632-457a-e19a-8e9c6445fd0f"
      },
      "source": [
        "#FINETUNED \n",
        "best_lr_sing_concat = LogisticRegression(penalty = 'l2', C = 21.544346900318832)\n",
        "run_model(best_lr_sing_concat, X_train_sing_vec_concat, y_sing_train, X_val_sing_vec_concat, y_sing_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.49451687383181664\n",
            " ## Accuracy is - 0.4946586158848119\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[520 570]\n",
            " [518 545]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfN-bIBVgdF-"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o938tm3m3GfK",
        "outputId": "2c42f37d-9aed-46f9-feb1-1746c9eba7a8"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_sing_concat_base = lr.predict(X_test_sing_vec_concat)\n",
        "pred_lr_sing_prob_concat_base = lr.predict_proba(X_test_sing_vec_concat)\n",
        "scores(y_sing_test, pred_lr_sing_concat_base)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5002397398943275\n",
            " ## Accuracy is - 0.5003455425017277\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1067 1137]\n",
            " [1032 1105]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caLs5ZSdgd6z",
        "outputId": "43334a56-38d9-4072-b996-236043b922d0"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_sing_concat = best_lr_sing_concat.predict(X_test_sing_vec_concat)\n",
        "scores(y_sing_test, pred_lr_sing_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.49732795452647843\n",
            " ## Accuracy is - 0.4973508408200875\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1074 1130]\n",
            " [1052 1085]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfW-jaQsNOvG"
      },
      "source": [
        "###**MULTI EMOJIS WITH REPEATS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuMp8wnDg_gp"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChwSiaacNO56",
        "outputId": "51ec8bf2-5ef2-43f0-9fb7-bf016d8db2ba"
      },
      "source": [
        "# BASELINE\n",
        "run_model(lr, X_train_mul_repeat_vec, y_mul_repeat_train, X_val_mul_repeat_vec, y_mul_repeat_val)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5187493899908503\n",
            " ## Accuracy is - 0.5189504373177842\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[651 556]\n",
            " [599 595]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL_NOBZrnrgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29da110-3d4f-4d7a-e64e-2cb7f98b7918"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_repeat_vec, y_mul_repeat_train, X_val_mul_repeat_vec, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 2.7825594022071245, 'penalty': 'l2'}\n",
            "score : 0.5246267106645911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhq0bza_Nu2E",
        "outputId": "ae8e87b9-dd80-4085-c38f-97aacaa8fdd6"
      },
      "source": [
        "#FINETUNED\n",
        "best_lr_mul_repeat = LogisticRegression(penalty = 'l2', C = 2.7825594022071245)\n",
        "run_model(best_lr_mul_repeat, X_train_mul_repeat_vec, y_mul_repeat_train, X_val_mul_repeat_vec, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5062493741464569\n",
            " ## Accuracy is - 0.5064556434818825\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[636 571]\n",
            " [614 580]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc_roNBTV3pz"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w_9x66r3qRn",
        "outputId": "1bb84019-5926-4413-9beb-8a723e1c4583"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_base = lr.predict(X_test_mul_repeat_vec)\n",
        "pred_lr_mul_prob_base = lr.predict_proba(X_test_mul_repeat_vec)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_base)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ShdwYMwV3wc",
        "outputId": "c85e70cd-0d6e-4cad-c208-358a906f38ac"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul_repeat = best_lr_mul_repeat.predict(X_test_mul_repeat_vec)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5193760638968085\n",
            " ## Accuracy is - 0.519375\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1238 1152]\n",
            " [1155 1255]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP_7iMGPhCOZ"
      },
      "source": [
        "#### With Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsRGoa-KhIJU",
        "outputId": "02cf9e29-6c77-48c3-a8c2-a92256bc409b"
      },
      "source": [
        "run_model(lr, X_train_mul_repeat_vec_concat, y_mul_repeat_train, X_val_mul_repeat_vec_concat, y_mul_repeat_val)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5187493899908503\n",
            " ## Accuracy is - 0.5189504373177842\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[651 556]\n",
            " [599 595]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmKiUyslhZJS",
        "outputId": "0ecae6c8-8603-43a9-c28a-856ad7ac5edf"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_repeat_vec_concat, y_mul_repeat_train, X_val_mul_repeat_vec_concat, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2'}\n",
            "score : 0.5222718993614576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj23kEHHhZOw",
        "outputId": "564150ae-876b-4025-dd15-aa3784b78989"
      },
      "source": [
        "best_lr_mul_repeat_concat = LogisticRegression(penalty = 'l2', C = 1.0)\n",
        "run_model(best_lr_mul_repeat_concat, X_train_mul_repeat_vec_concat, y_mul_repeat_train, X_val_mul_repeat_vec_concat, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5187493899908503\n",
            " ## Accuracy is - 0.5189504373177842\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[651 556]\n",
            " [599 595]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6WGr-Xhn8o"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cieg4jgD4DpM",
        "outputId": "9eb451be-b42d-469a-951c-ee0d5956310f"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_concat_base = lr.predict(X_test_mul_repeat_vec_concat)\n",
        "pred_lr_mul_prob_concat_base = lr.predict_proba(X_test_mul_repeat_vec_concat)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_concat_base)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxCCDCzMhoHd",
        "outputId": "9e5a1733-f903-48e5-ed5f-6e73f6dbbb9c"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul_repeat_concat = best_lr_mul_repeat_concat.predict(X_test_mul_repeat_vec_concat)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXGMZxStQx4J"
      },
      "source": [
        "###**FULL EMOJIS NO REPEATS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca1ihGKXh_ax"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69EaKC7MQyCE",
        "outputId": "cb6950d7-ac55-4fbc-c20d-fcab2c44ec15"
      },
      "source": [
        "run_model(lr, X_train_mul_vec, y_mul_train, X_val_mul_vec, y_mul_val)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.519122216228706\n",
            " ## Accuracy is - 0.5190668461193361\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[572 514]\n",
            " [558 585]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWTMqs9nQyGg",
        "outputId": "d3dbe1de-99d2-4ba3-f347-cc6bedc42de3"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_vec, y_mul_train, X_val_mul_vec, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 7.742636826811269, 'penalty': 'l2'}\n",
            "score : 0.5058041572685422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUkKQyYQS5t1",
        "outputId": "c4d2b810-5ed5-4ba9-dfbd-4aa5e4630079"
      },
      "source": [
        "best_lr_mul = LogisticRegression(penalty = 'l2', C = 7.742636826811269)\n",
        "run_model(best_lr_mul, X_train_mul_vec, y_mul_train, X_val_mul_vec, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.506974828951965\n",
            " ## Accuracy is - 0.5069537909376401\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[563 523]\n",
            " [576 567]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_R8WgYFTQKo"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKRVrP9c4q7s",
        "outputId": "8afa1ec7-b4db-4012-ce75-71d8191f7c07"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_base = lr.predict(X_test_mul_vec)\n",
        "pred_lr_mul_prob__base = lr.predict_proba(X_test_mul_vec)\n",
        "scores(y_mul_test, pred_lr_mul_base)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5158905918420099\n",
            " ## Accuracy is - 0.5159034513873224\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1158 1064]\n",
            " [1082 1129]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_rVW2-8T0Yn",
        "outputId": "1dd5fb35-2b6d-43e3-b06e-801b19a6f31b"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul = best_lr_mul.predict(X_test_mul_vec)\n",
        "scores(y_mul_test, pred_lr_mul)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5097595798975241\n",
            " ## Accuracy is - 0.509812767877284\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1156 1066]\n",
            " [1107 1104]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBNDCCERiEuQ"
      },
      "source": [
        "#### With Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-TiQSVtiFAx",
        "outputId": "bf88cf79-add0-477d-eca3-60b4633473fb"
      },
      "source": [
        "run_model(lr, X_train_mul_vec_concat, y_mul_train, X_val_mul_vec_concat, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.519122216228706\n",
            " ## Accuracy is - 0.5190668461193361\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[572 514]\n",
            " [558 585]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev3DaCkLiNHj",
        "outputId": "a8f2e0df-3d91-41d2-9714-9fb45c7cd0a5"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_vec_concat, y_mul_train, X_val_mul_vec_concat, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 166.81005372000593, 'penalty': 'l2'}\n",
            "score : 0.5102422337754854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaGr28EpiNM8",
        "outputId": "b2942e3d-5dd2-4b74-fd4d-0279db3bd354"
      },
      "source": [
        "best_lr_mul_concat = LogisticRegression(penalty = 'l2', C = 166.81005372000593)\n",
        "run_model(best_lr_mul_concat, X_train_mul_vec_concat, y_mul_train, X_val_mul_vec_concat, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5164243110024794\n",
            " ## Accuracy is - 0.5163750560789592\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[570 516]\n",
            " [562 581]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCgZpqr4idFE"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAZaIfk45AaQ",
        "outputId": "6e6c319e-e97c-4ddb-c24d-22b8f777ebdf"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_concat_base = lr.predict(X_test_mul_vec_concat)\n",
        "pred_lr_mul_prob_concat_base = lr.predict_proba(X_test_mul_vec_concat)\n",
        "scores(y_mul_test, pred_lr_mul_concat_base)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5158905918420099\n",
            " ## Accuracy is - 0.5159034513873224\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1158 1064]\n",
            " [1082 1129]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEeC_eu_idtO",
        "outputId": "a06cd0af-a4a2-4d19-cd57-b7aa84ad45f9"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul_concat = best_lr_mul_concat.predict(X_test_mul_vec_concat)\n",
        "scores(y_mul_test, pred_lr_mul_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5153876281750626\n",
            " ## Accuracy is - 0.515452289645838\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1171 1051]\n",
            " [1097 1114]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DClgnHseTWpy"
      },
      "source": [
        "##**SUMMARY PREDICTION ON TEST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF4Rk3zgivJw"
      },
      "source": [
        "###**w Avg Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvuDRIhVSNOS",
        "outputId": "a9ba8f80-14df-4914-e35b-cbae9d3c9faa"
      },
      "source": [
        "#FULL DATA\n",
        "print(\"FULL DATA\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_full = best_lr_full.predict(X_test_vec)\n",
        "scores(y_test, pred_lr_full)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#FULL EMOJIS WITH NO REPEATS\n",
        "print(\" \")\n",
        "print(\"FULL NO REPEATS\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_mul = best_lr_mul.predict(X_test_mul_vec)\n",
        "scores(y_mul_test, pred_lr_mul)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#SINGLE EMOJI\n",
        "print(\" \")\n",
        "print(\"SINGLE EMOJI ONLY\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_sing = best_lr_sing.predict(X_test_sing_vec)\n",
        "scores(y_sing_test, pred_lr_sing)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#MULTI EMOJIS WITH REPEATS\n",
        "print(\" \")\n",
        "print(\"MULTI EMOJIS ONLY WITH REPEATS\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_mul_repeat = best_lr_mul_repeat.predict(X_test_mul_repeat_vec)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL DATA\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5245992385409034\n",
            " ## Accuracy is - 0.5245606128886886\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1184 1075]\n",
            " [1035 1144]]\n",
            "==========================================\n",
            " \n",
            "FULL NO REPEATS\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5097595798975241\n",
            " ## Accuracy is - 0.509812767877284\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1156 1066]\n",
            " [1107 1104]]\n",
            "==========================================\n",
            " \n",
            "SINGLE EMOJI ONLY\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.4878466603498624\n",
            " ## Accuracy is - 0.4879060124395301\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1047 1157]\n",
            " [1066 1071]]\n",
            "==========================================\n",
            " \n",
            "MULTI EMOJIS ONLY WITH REPEATS\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5193760638968085\n",
            " ## Accuracy is - 0.519375\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1238 1152]\n",
            " [1155 1255]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUmp6-rIi3ly"
      },
      "source": [
        "###**w Concat Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtmqBLZzi3z4",
        "outputId": "ccc60f85-b402-42a4-edfd-26eada5dfe9e"
      },
      "source": [
        "#FULL DATA\n",
        "print(\"FULL DATA CONCAT\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_full_concat = best_lr_full_concat.predict(X_test_vec_concat)\n",
        "scores(y_test, pred_lr_full_concat)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#FULL EMOJIS WITH NO REPEATS\n",
        "print(\" \")\n",
        "print(\"FULL NO REPEATS CONCAT\")\n",
        "print(\"-------------------\")\n",
        "# pred_lr_mul = best_lr_mul.predict(X_test_mul_vec)\n",
        "# scores(y_mul_test, pred_lr_mul)\n",
        "pred_lr_mul_concat = best_lr_mul_concat.predict(X_test_mul_vec_concat)\n",
        "scores(y_mul_test, pred_lr_mul_concat)\n",
        "\n",
        "print(\"==========================================\")\n",
        "\n",
        "#SINGLE EMOJI\n",
        "print(\" \")\n",
        "print(\"SINGLE EMOJI ONLY CONCAT\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_sing_concat = best_lr_sing_concat.predict(X_test_sing_vec_concat)\n",
        "scores(y_sing_test, pred_lr_sing_concat)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#MULTI EMOJIS WITH REPEATS\n",
        "print(\" \")\n",
        "print(\"MULTI EMOJIS ONLY WITH REPEATS CONCAT\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_mul_repeat_concat = best_lr_mul_repeat_concat.predict(X_test_mul_repeat_vec_concat)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat_concat)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL DATA CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5200812782739727\n",
            " ## Accuracy is - 0.5200540784136999\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1185 1074]\n",
            " [1056 1123]]\n",
            "==========================================\n",
            " \n",
            "FULL NO REPEATS CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5153876281750626\n",
            " ## Accuracy is - 0.515452289645838\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1171 1051]\n",
            " [1097 1114]]\n",
            "==========================================\n",
            " \n",
            "SINGLE EMOJI ONLY CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.49732795452647843\n",
            " ## Accuracy is - 0.4973508408200875\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1074 1130]\n",
            " [1052 1085]]\n",
            "==========================================\n",
            " \n",
            "MULTI EMOJIS ONLY WITH REPEATS CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJgMSkMCSNR4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oNXjcrakG3g"
      },
      "source": [
        "##**ERROR ANALYSIS FOR BEST RESULTS (FULL DATA w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAnP2Ac8kPsz"
      },
      "source": [
        "def evaluate_incorrect(y_test, preds, input_df, preds_prob):\n",
        "  df_test = input_df.copy()\n",
        "  df_test['prob_zero'] = preds_prob[:, 0]\n",
        "  print(df_test.shape)\n",
        "  eval_incorrect = df_test.index[y_test != preds]\n",
        "\n",
        "  output_incorrect = df_test[df_test.index.isin(eval_incorrect)]\n",
        "  # print(eval)\n",
        "  # print(eval.shape)\n",
        "  # print(y_test != preds)\n",
        "  # print(y_test == preds)\n",
        "\n",
        "  return output_incorrect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM2Nl5jjkPv4"
      },
      "source": [
        "def evaluate_correct(y_test, preds, input_df, preds_prob):\n",
        "  df_test = input_df.copy()\n",
        "  df_test['prob_zero'] = preds_prob[:, 0]\n",
        "  print(df_test.shape)\n",
        "\n",
        "  eval_correct = df_test.index[y_test == preds]\n",
        "  output_correct = df_test[df_test.index.isin(eval_correct)]\n",
        "  # print(eval)\n",
        "  # print(eval.shape)\n",
        "  # print(y_test != preds)\n",
        "  # print(y_test == preds)\n",
        "\n",
        "  return output_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gngE_j3dOK38"
      },
      "source": [
        "best_lr_full = LogisticRegression(penalty = 'l2', C = 3593.813663804626)\n",
        "run_model(best_lr_full, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0hU2HXRNglB",
        "outputId": "58287bee-dff2-4e1f-a0b1-eb72554bcd26"
      },
      "source": [
        "best_lr_full.predict_proba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method LogisticRegression.predict_proba of LogisticRegression(C=3593.813663804626, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ru6C2e-NyRz"
      },
      "source": [
        "pred_lr_full_prob = best_lr_full.predict_proba(X_test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF812jzVkPzS",
        "outputId": "60a88b72-3a36-4b0f-d329-11b263f90c71"
      },
      "source": [
        "pred_lr_full_prob[:, 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45513382, 0.4308906 , 0.37023349, ..., 0.50978928, 0.5311429 ,\n",
              "       0.40109193])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "cXxG2aCUNxcR",
        "outputId": "8b58dc89-1b3c-4b19-8547-5cbf64f2d104"
      },
      "source": [
        "output_incorrect = evaluate_incorrect(y_test, pred_lr_full, df_test, pred_lr_full_prob)\n",
        "output_incorrect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4438, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77593</td>\n",
              "      <td>Youâ€™re just so beautiful</td>\n",
              "      <td>ğŸ’€</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40054</td>\n",
              "      <td>Want to tease someone until they cry</td>\n",
              "      <td>ğŸ˜¢</td>\n",
              "      <td>1</td>\n",
              "      <td>0.553649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32019</td>\n",
              "      <td>Iâ€™ll figure this out. I always do and I always...</td>\n",
              "      <td>ğŸ˜¤</td>\n",
              "      <td>1</td>\n",
              "      <td>0.569586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3979</td>\n",
              "      <td>[USER] [USER] Underrated tweet.</td>\n",
              "      <td>ğŸ‘ğŸ¼</td>\n",
              "      <td>1</td>\n",
              "      <td>0.519481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35360</td>\n",
              "      <td>[USER] Can you do body rolls too?</td>\n",
              "      <td>ğŸ§</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>23112</td>\n",
              "      <td>[USER] Hitting the Plymouth tomorrow.  If you ...</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>1</td>\n",
              "      <td>0.568806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>81505</td>\n",
              "      <td>[USER] [USER] I'm sorry for your loss!</td>\n",
              "      <td>ğŸ˜Š</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4432</th>\n",
              "      <td>11677</td>\n",
              "      <td>tmap ep. 38 gave us so much happiness. Today's...</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "      <td>0.571603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4433</th>\n",
              "      <td>14708</td>\n",
              "      <td>Learning to LOVE yourself the RIGHT away it th...</td>\n",
              "      <td>ğŸ¥°</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4436</th>\n",
              "      <td>33923</td>\n",
              "      <td>[USER] We downgraded our CSP to the Flex last ...</td>\n",
              "      <td>ğŸ˜¬</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2110 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... prob_zero\n",
              "0     77593  ...  0.455134\n",
              "3     40054  ...  0.553649\n",
              "4     32019  ...  0.569586\n",
              "6      3979  ...  0.519481\n",
              "7     35360  ...  0.521023\n",
              "...     ...  ...       ...\n",
              "4429  23112  ...  0.568806\n",
              "4431  81505  ...  0.455440\n",
              "4432  11677  ...  0.571603\n",
              "4433  14708  ...  0.583106\n",
              "4436  33923  ...  0.531143\n",
              "\n",
              "[2110 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77U5VcDyT3_L"
      },
      "source": [
        "output_incorrect.to_csv(\"/content/drive/MyDrive/2021_NLU/data/full_data/output_incorrect.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLXh-LuRT4ZO"
      },
      "source": [
        "incorrect = pd.read_csv(\"/content/drive/MyDrive/2021_NLU/data/full_data/output_incorrect.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw6GzVCUUCXZ",
        "outputId": "2816eaf1-c064-4684-e87d-2a44a3894f8c"
      },
      "source": [
        "print(incorrect.columns)\n",
        "print(incorrect.shape)\n",
        "print(len(x_test_tokenized))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['index', 'tweets', 'emoji_sentence', 'follows?', 'prob_zero'], dtype='object')\n",
            "(2110, 5)\n",
            "4438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "iXMm9OZHUCcV",
        "outputId": "c4256b23-2aca-4019-c2df-aa76f1c035a8"
      },
      "source": [
        "# below df is original + model predicting prob of zero\n",
        "# original says 'follows=0', which means it doesn't follow \n",
        "# but the below shows 'incorrect' prediction\n",
        "# and model predicted it doesn't follow with a 0.139464 prob \n",
        "# which means the model predicted it \"follows\" with a 0.860536 (1-0.139464) prob  \n",
        "incorrect[incorrect['follows?'] == 0].sort_values(by='prob_zero').head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>65383</td>\n",
              "      <td>[USER] Amin amin amin</td>\n",
              "      <td>ğŸ™ƒ</td>\n",
              "      <td>0</td>\n",
              "      <td>0.139464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>96456</td>\n",
              "      <td>Gud morning</td>\n",
              "      <td>ğŸ—¿</td>\n",
              "      <td>0</td>\n",
              "      <td>0.144617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1674</th>\n",
              "      <td>104591</td>\n",
              "      <td>[USER] Confessional?</td>\n",
              "      <td>ğŸ¤§</td>\n",
              "      <td>0</td>\n",
              "      <td>0.166362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>61741</td>\n",
              "      <td>my chakra bracelet broke</td>\n",
              "      <td>ğŸ‡®ğŸ‡¹ğŸ‡ªğŸ‡¸ğŸ¶</td>\n",
              "      <td>0</td>\n",
              "      <td>0.174965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>63123</td>\n",
              "      <td>bloodhound apexlegends</td>\n",
              "      <td>â™‹ğŸ”®</td>\n",
              "      <td>0</td>\n",
              "      <td>0.190229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>71190</td>\n",
              "      <td>A fashion designer</td>\n",
              "      <td>ğŸ‘ğŸ¼ğŸ¤·â™‚</td>\n",
              "      <td>0</td>\n",
              "      <td>0.211639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>95632</td>\n",
              "      <td>GROSS people post GROSS tweets.</td>\n",
              "      <td>ğŸ¤£</td>\n",
              "      <td>0</td>\n",
              "      <td>0.221515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1427</th>\n",
              "      <td>87870</td>\n",
              "      <td>Sensible administration.</td>\n",
              "      <td>ğŸ¦µğŸ¿ğŸ‘ğŸ¿ğŸ‘ğŸ¿ğŸ˜‚ğŸ¤£ğŸ˜‚</td>\n",
              "      <td>0</td>\n",
              "      <td>0.238544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>69482</td>\n",
              "      <td>.â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒa correlated saviorâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒAnd...</td>\n",
              "      <td>ğŸ™Œ</td>\n",
              "      <td>0</td>\n",
              "      <td>0.245230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>64260</td>\n",
              "      <td>Petit prince</td>\n",
              "      <td>ğŸ¤£</td>\n",
              "      <td>0</td>\n",
              "      <td>0.246465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... prob_zero\n",
              "561    65383  ...  0.139464\n",
              "1068   96456  ...  0.144617\n",
              "1674  104591  ...  0.166362\n",
              "214    61741  ...  0.174965\n",
              "1307   63123  ...  0.190229\n",
              "526    71190  ...  0.211639\n",
              "311    95632  ...  0.221515\n",
              "1427   87870  ...  0.238544\n",
              "1864   69482  ...  0.245230\n",
              "1619   64260  ...  0.246465\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "radSb2XarcZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c12a0d-9511-4b6e-caf6-66afd144f11a"
      },
      "source": [
        "(5+3+3+5+4+6+6+8+5+3)/10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "i4QEeAoEUiM5",
        "outputId": "7b50eca9-03d8-40f9-ba2f-7cd09301399f"
      },
      "source": [
        "incorrect[incorrect['follows?'] == 1].sort_values(by='prob_zero', ascending = False).head(11)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>29079</td>\n",
              "      <td>[USER] comfort moot</td>\n",
              "      <td>ğŸ¥º</td>\n",
              "      <td>1</td>\n",
              "      <td>0.877194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>52521</td>\n",
              "      <td>[USER] Noted</td>\n",
              "      <td>ğŸ“</td>\n",
              "      <td>1</td>\n",
              "      <td>0.808980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1763</th>\n",
              "      <td>44533</td>\n",
              "      <td>the quotes</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "      <td>0.806977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>11453</td>\n",
              "      <td>BOT  BOT     BOT  BOT    BOT  BOT     BOT  BO...</td>\n",
              "      <td>ğŸ’€ğŸ”ğŸ’¥ğŸ”ªğŸ˜¡ğŸ‘ğŸ’©ğŸ‘™ğŸ’¡ğŸ’€ğŸ”ªğŸ’©ğŸŒµ</td>\n",
              "      <td>1</td>\n",
              "      <td>0.740729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>37314</td>\n",
              "      <td>Donâ€™t challenge the</td>\n",
              "      <td>ğŸ</td>\n",
              "      <td>1</td>\n",
              "      <td>0.732235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>51905</td>\n",
              "      <td>WTF, Amazon!? This is horrible!</td>\n",
              "      <td>ğŸ˜¡</td>\n",
              "      <td>1</td>\n",
              "      <td>0.730434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1925</th>\n",
              "      <td>41707</td>\n",
              "      <td>considering tossing the unopened box of cinnam...</td>\n",
              "      <td>ğŸ˜¬</td>\n",
              "      <td>1</td>\n",
              "      <td>0.728836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>4868</td>\n",
              "      <td>[USER] Library</td>\n",
              "      <td>ğŸ˜²</td>\n",
              "      <td>1</td>\n",
              "      <td>0.722231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>3466</td>\n",
              "      <td>me to 300?</td>\n",
              "      <td>â›½</td>\n",
              "      <td>1</td>\n",
              "      <td>0.712570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>49692</td>\n",
              "      <td>Wow wow wow</td>\n",
              "      <td>ğŸ˜ğŸ˜ğŸ˜</td>\n",
              "      <td>1</td>\n",
              "      <td>0.710795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>7599</td>\n",
              "      <td>[USER] Rinse. Repeat.</td>\n",
              "      <td>ğŸ˜‚</td>\n",
              "      <td>1</td>\n",
              "      <td>0.704552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... prob_zero\n",
              "1171  29079  ...  0.877194\n",
              "1177  52521  ...  0.808980\n",
              "1763  44533  ...  0.806977\n",
              "120   11453  ...  0.740729\n",
              "1309  37314  ...  0.732235\n",
              "281   51905  ...  0.730434\n",
              "1925  41707  ...  0.728836\n",
              "1115   4868  ...  0.722231\n",
              "449    3466  ...  0.712570\n",
              "1989  49692  ...  0.710795\n",
              "884    7599  ...  0.704552\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDKw-CVsUChk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92227686-0a04-41cb-f87c-f2b79cdfa517"
      },
      "source": [
        "(5+3+3+5+4+6+6+8+5+3+3+3+3+4+6+8+3+4+6+4)/20"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JfhIReUsDm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQSKPfW8UsH9",
        "outputId": "f158668b-c547-454d-a68c-1d2256ef1ced"
      },
      "source": [
        "output_correct = evaluate_correct(y_test, pred_lr_full, df_test, pred_lr_full_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4438, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9-yb4isUsN2"
      },
      "source": [
        "output_correct.to_csv(\"/content/drive/MyDrive/2021_NLU/data/full_data/output_correct.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2pAq_H57UsSq",
        "outputId": "42d938a0-0090-4401-d91d-4bfa440ffd80"
      },
      "source": [
        "output_correct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42801</td>\n",
              "      <td>Watch your PH balance not my page</td>\n",
              "      <td>ğŸ™‚</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45798</td>\n",
              "      <td>fast gcash  â€¢ follow me &amp;amp; [USER] â€¢ rt end...</td>\n",
              "      <td>ğŸ’¸ğŸ’¸â³</td>\n",
              "      <td>1</td>\n",
              "      <td>0.370233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44976</td>\n",
              "      <td>15 gcash â€¢ like and rt [USER]'s pinned â€¢ retwe...</td>\n",
              "      <td>ğŸ“Œ</td>\n",
              "      <td>1</td>\n",
              "      <td>0.274290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>75250</td>\n",
              "      <td>Hennessy and dangerous. And I canâ€™t front like...</td>\n",
              "      <td>ğŸ™‚</td>\n",
              "      <td>0</td>\n",
              "      <td>0.502358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>59363</td>\n",
              "      <td>Standing at the bus stop today, with my mask o...</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>0</td>\n",
              "      <td>0.521341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>37450</td>\n",
              "      <td>[USER] alright then we move  just hmu whenever</td>\n",
              "      <td>ğŸ¤</td>\n",
              "      <td>1</td>\n",
              "      <td>0.465126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4430</th>\n",
              "      <td>18250</td>\n",
              "      <td>self sabotaged at work again and got Mac and c...</td>\n",
              "      <td>ğŸ˜”</td>\n",
              "      <td>1</td>\n",
              "      <td>0.487529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4434</th>\n",
              "      <td>53064</td>\n",
              "      <td>[USER] Follow me to gainFollowersDaily.</td>\n",
              "      <td>ğŸ‘»ğŸ°ğŸŒ¹</td>\n",
              "      <td>1</td>\n",
              "      <td>0.387965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4435</th>\n",
              "      <td>75342</td>\n",
              "      <td>I would never let a female use a strap because...</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4437</th>\n",
              "      <td>22679</td>\n",
              "      <td>[USER] happiest birthday aya!!  have a blast</td>\n",
              "      <td>ğŸ’—ğŸ¥³</td>\n",
              "      <td>1</td>\n",
              "      <td>0.401092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2328 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... prob_zero\n",
              "1     42801  ...  0.430891\n",
              "2     45798  ...  0.370233\n",
              "5     44976  ...  0.274290\n",
              "9     75250  ...  0.502358\n",
              "12    59363  ...  0.521341\n",
              "...     ...  ...       ...\n",
              "4428  37450  ...  0.465126\n",
              "4430  18250  ...  0.487529\n",
              "4434  53064  ...  0.387965\n",
              "4435  75342  ...  0.509789\n",
              "4437  22679  ...  0.401092\n",
              "\n",
              "[2328 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "KLpHqxchXiA7",
        "outputId": "34bf6831-da7d-4f9b-cb06-211889058643"
      },
      "source": [
        "output_correct[output_correct['prob_zero']  > 0.7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "      <th>emoji_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>61362</td>\n",
              "      <td>Actives today?</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>0</td>\n",
              "      <td>0.800815</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>79490</td>\n",
              "      <td>Found a spider in my room  throwing away my room</td>\n",
              "      <td>ğŸ˜Š</td>\n",
              "      <td>0</td>\n",
              "      <td>0.743156</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>58636</td>\n",
              "      <td>Urgent action! Please read.</td>\n",
              "      <td>ğŸ¤</td>\n",
              "      <td>0</td>\n",
              "      <td>0.732539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>62258</td>\n",
              "      <td>A blessing</td>\n",
              "      <td>ğŸ¥³</td>\n",
              "      <td>0</td>\n",
              "      <td>0.728554</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>103314</td>\n",
              "      <td>I want to move on and never look back</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>0</td>\n",
              "      <td>0.738640</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1170</th>\n",
              "      <td>74023</td>\n",
              "      <td>Shea Butter Baby</td>\n",
              "      <td>ğŸ˜‚</td>\n",
              "      <td>0</td>\n",
              "      <td>0.791787</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>90596</td>\n",
              "      <td>Need some nasty hotel  drunk sex</td>\n",
              "      <td>ğŸ¤¨</td>\n",
              "      <td>0</td>\n",
              "      <td>0.711217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>62976</td>\n",
              "      <td>Dr. Rachel Levine makes history.</td>\n",
              "      <td>ğŸ˜­ğŸ˜­</td>\n",
              "      <td>0</td>\n",
              "      <td>0.713636</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>71108</td>\n",
              "      <td>The bros</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>0</td>\n",
              "      <td>0.706372</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>97014</td>\n",
              "      <td>Please text me</td>\n",
              "      <td>â™¾ğŸ’”</td>\n",
              "      <td>0</td>\n",
              "      <td>0.757426</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>105309</td>\n",
              "      <td>[USER] manual labour</td>\n",
              "      <td>ğŸ˜‚</td>\n",
              "      <td>0</td>\n",
              "      <td>0.746659</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2784</th>\n",
              "      <td>64365</td>\n",
              "      <td>Sexy af</td>\n",
              "      <td>ğŸ’¢</td>\n",
              "      <td>0</td>\n",
              "      <td>0.896276</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3028</th>\n",
              "      <td>84767</td>\n",
              "      <td>and i overslept again.</td>\n",
              "      <td>ğŸ¤§</td>\n",
              "      <td>0</td>\n",
              "      <td>0.715209</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>87539</td>\n",
              "      <td>[USER] confort moot</td>\n",
              "      <td>ğŸ˜Š</td>\n",
              "      <td>0</td>\n",
              "      <td>0.736160</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3870</th>\n",
              "      <td>103649</td>\n",
              "      <td>Grandmas should live forever</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>0</td>\n",
              "      <td>0.740893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4114</th>\n",
              "      <td>62196</td>\n",
              "      <td>Vibin w/ someone who got the same goofy energy...</td>\n",
              "      <td>â˜¹</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... emoji_sentence_len\n",
              "80     61362  ...                  1\n",
              "467    79490  ...                  1\n",
              "600    58636  ...                  1\n",
              "896    62258  ...                  1\n",
              "951   103314  ...                  1\n",
              "1170   74023  ...                  1\n",
              "1208   90596  ...                  1\n",
              "1482   62976  ...                  2\n",
              "2034   71108  ...                  1\n",
              "2261   97014  ...                  2\n",
              "2500  105309  ...                  1\n",
              "2784   64365  ...                  1\n",
              "3028   84767  ...                  1\n",
              "3453   87539  ...                  1\n",
              "3870  103649  ...                  1\n",
              "4114   62196  ...                  1\n",
              "\n",
              "[16 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3oelJIiVMpg"
      },
      "source": [
        "correct_prob = output_correct[output_correct['follows?'] == 0].prob_zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "pG3CN4-SVSsg",
        "outputId": "f5536819-2bab-4e05-bce9-8933a1a3c504"
      },
      "source": [
        "plt.hist(correct_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([555., 356., 167.,  59.,  29.,  10.,   5.,   2.,   0.,   1.]),\n",
              " array([0.50005471, 0.5396768 , 0.57929889, 0.61892097, 0.65854306,\n",
              "        0.69816515, 0.73778723, 0.77740932, 0.81703141, 0.85665349,\n",
              "        0.89627558]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPx0lEQVR4nO3da6xlZ13H8e+PDi1Ggd6GppkpPVWGYEmE4qRW0YBtgF6UKbemeGGoo5OYajBodJAXItFY3lAkEkylhIEIpVZJR1ovTS8aiUVO6Y22tj2UaTpDYQ6lrRIELf59sZ+RPcOZOfvM2fvs3YfvJznZz3rWs/b676d7fmedtfZeTVUhSerLM6ZdgCRp/Ax3SeqQ4S5JHTLcJalDhrskdWjdtAsAOPHEE2tubm7aZUjS08ptt932tapav9S6mQj3ubk55ufnp12GJD2tJHn4UOs8LSNJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR2aiW+orsbcjuumtu/dl10wtX1L0uF45C5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tBI4Z5kd5K7k9yRZL71HZ/khiQPtsfjWn+SvD/JQpK7krxski9AkvS9VnLk/rNV9dKq2tyWdwA3VtUm4Ma2DHAesKn9bAc+OK5iJUmjWc1pmS3AztbeCVw41P/RGrgVODbJyavYjyRphUYN9wL+McltSba3vpOq6tHW/gpwUmtvAB4Z2nZP6ztAku1J5pPMLy4uHkHpkqRDGfV/kP3TVbU3yfOAG5L8+/DKqqoktZIdV9UVwBUAmzdvXtG2kqTDG+nIvar2tsd9wKeAM4Gv7j/d0h73teF7gVOGNt/Y+iRJa2TZcE/yg0mevb8NvBr4ArAL2NqGbQWube1dwFvap2bOAp4cOn0jSVoDo5yWOQn4VJL94z9eVX+f5HPA1Um2AQ8DF7Xx1wPnAwvAN4FLxl61JOmwlg33qnoIeMkS/Y8B5yzRX8ClY6lOknRE/IaqJHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOjRyuCc5KsntST7dlk9L8tkkC0k+meTo1n9MW15o6+cmU7ok6VBWcuT+NuC+oeX3AJdX1QuAx4FtrX8b8Hjrv7yNkyStoZHCPclG4ALgQ205wNnANW3ITuDC1t7Slmnrz2njJUlrZNQj9/cBvwv8b1s+AXiiqp5qy3uADa29AXgEoK1/so2XJK2RZcM9yc8B+6rqtnHuOMn2JPNJ5hcXF8f51JL0fW+UI/eXA69Nshu4isHpmD8Fjk2yro3ZCOxt7b3AKQBt/XOBxw5+0qq6oqo2V9Xm9evXr+pFSJIOtGy4V9U7qmpjVc0BFwM3VdUvAjcDb2zDtgLXtvautkxbf1NV1VirliQd1mo+5/57wNuTLDA4p35l678SOKH1vx3YsboSJUkrtW75Id9VVbcAt7T2Q8CZS4z5FvCmMdQmSTpCfkNVkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0IruLaMDze24bir73X3ZBVPZr6SnD4/cJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUPLhnuSZyX5tyR3JrknyR+2/tOSfDbJQpJPJjm69R/Tlhfa+rnJvgRJ0sFGOXL/NnB2Vb0EeClwbpKzgPcAl1fVC4DHgW1t/Dbg8dZ/eRsnSVpDy4Z7DXyjLT6z/RRwNnBN698JXNjaW9oybf05STK2iiVJyxrpnHuSo5LcAewDbgC+CDxRVU+1IXuADa29AXgEoK1/EjhhiefcnmQ+yfzi4uLqXoUk6QAjhXtVfaeqXgpsBM4EXrTaHVfVFVW1uao2r1+/frVPJ0kasqJPy1TVE8DNwE8CxyZZ11ZtBPa29l7gFIC2/rnAY2OpVpI0klE+LbM+ybGt/QPAq4D7GIT8G9uwrcC1rb2rLdPW31RVNc6iJUmHt275IZwM7ExyFINfBldX1aeT3AtcleSPgNuBK9v4K4GPJVkAvg5cPIG6JUmHsWy4V9VdwBlL9D/E4Pz7wf3fAt40luokSUfEb6hKUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ8uGe5JTktyc5N4k9yR5W+s/PskNSR5sj8e1/iR5f5KFJHcledmkX4Qk6UCjHLk/Bfx2VZ0OnAVcmuR0YAdwY1VtAm5sywDnAZvaz3bgg2OvWpJ0WMuGe1U9WlWfb+3/BO4DNgBbgJ1t2E7gwtbeAny0Bm4Fjk1y8tgrlyQd0orOuSeZA84APgucVFWPtlVfAU5q7Q3AI0Ob7Wl9Bz/X9iTzSeYXFxdXWLYk6XBGDvckPwT8NfBbVfUfw+uqqoBayY6r6oqq2lxVm9evX7+STSVJyxgp3JM8k0Gw/2VV/U3r/ur+0y3tcV/r3wucMrT5xtYnSVojo3xaJsCVwH1V9d6hVbuAra29Fbh2qP8t7VMzZwFPDp2+kSStgXUjjHk58MvA3UnuaH2/D1wGXJ1kG/AwcFFbdz1wPrAAfBO4ZKwVS5KWtWy4V9W/ADnE6nOWGF/ApausS5K0Cn5DVZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHVolM+5a8bM7bhuavvefdkFU9u3pNF55C5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUoWXDPcmHk+xL8oWhvuOT3JDkwfZ4XOtPkvcnWUhyV5KXTbJ4SdLSRjly/whw7kF9O4Abq2oTcGNbBjgP2NR+tgMfHE+ZkqSVWDbcq+qfga8f1L0F2NnaO4ELh/o/WgO3AscmOXlcxUqSRnOk59xPqqpHW/srwEmtvQF4ZGjcntb3PZJsTzKfZH5xcfEIy5AkLWXVF1SrqoA6gu2uqKrNVbV5/fr1qy1DkjTkSMP9q/tPt7THfa1/L3DK0LiNrU+StIaONNx3AVtbeytw7VD/W9qnZs4Cnhw6fSNJWiPrlhuQ5BPAK4ETk+wB/gC4DLg6yTbgYeCiNvx64HxgAfgmcMkEapYkLWPZcK+qNx9i1TlLjC3g0tUWJUlaHb+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDy95+QBo2t+O6qex392UXTGW/0tOVR+6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOuTtB/S04G0PpJXxyF2SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yI9CSocxrY9ggh/D1OpM5Mg9yblJ7k+ykGTHJPYhSTq0sR+5JzkK+ADwKmAP8Lkku6rq3nHvS+qZX9zSakzitMyZwEJVPQSQ5CpgC2C4S08D34+nonp8zZMI9w3AI0PLe4CfOHhQku3A9rb4jST3H+H+TgS+doTbTtqs1mZdKzertc1qXXAEteU9E6rkQDM1Zwe95pXWduqhVkztgmpVXQFcsdrnSTJfVZvHUNLYzWpt1rVys1rbrNYFs1vbrNYF461tEhdU9wKnDC1vbH2SpDUyiXD/HLApyWlJjgYuBnZNYD+SpEMY+2mZqnoqyW8A/wAcBXy4qu4Z936GrPrUzgTNam3WtXKzWtus1gWzW9us1gVjrC1VNa7nkiTNCG8/IEkdMtwlqUMzHe7L3cYgyVuTLCa5o/386tC6rUkebD9bZ6iu7wz1j/1C8yi3fkhyUZJ7k9yT5OND/VObs2XqmticjfDf8vKhfT+Q5ImhdRObrzHUNs05e36Sm5PcnuSuJOcPrXtH2+7+JK8ZZ12rqS3JXJL/GpqzP1/juk5NcmOr6ZYkG4fWHdn7rKpm8ofBxdgvAj8MHA3cCZx+0Ji3An+2xLbHAw+1x+Na+7hp19XWfWPKc7YJuH3/fADPm5E5W7KuSc7ZKHUdNP43GXxAYKLztdrapj1nDC4K/nprnw7sHmrfCRwDnNae56gZqW0O+MIU5+yvgK2tfTbwsdW+z2b5yP3/b2NQVf8N7L+NwSheA9xQVV+vqseBG4BzZ6CuSRultl8DPtDmhara1/qnPWeHqmuSVvrf8s3AJ1p7kvO12tomaZS6CnhOaz8X+HJrbwGuqqpvV9WXgIX2fLNQ2ySNUtfpwE2tffPQ+iN+n81yuC91G4MNS4x7Q/tT5pok+788Neq2a10XwLOSzCe5NcmFY6ppJbW9EHhhks+0Gs5dwbbTqAsmN2cjv+YkpzI42tz/D3CS87Xa2mC6c/Yu4JeS7AGuZ/BXxajbTqs2gNPa6Zp/SvIza1zXncDrW/t1wLOTnDDitkua5XAfxd8Cc1X1Ywx+o+2ccj37Ha6uU2vw9eJfAN6X5EfWuLZ1DE6BvJLB0d5fJDl2jWtYyuHqmvacweDLeNdU1XemsO/lLFXbNOfszcBHqmojcD7wsSSzkjWHqu1R4PlVdQbwduDjSZ5zmOcZt98BXpHkduAVDL7Vv6r32qxM+FKWvY1BVT1WVd9uix8CfnzUbadUF1W1tz0+BNwCnDGmukaqjcFv/l1V9T/tT+MHGITqVOfsMHVNcs5W8pov5sDTHpO+zcZqapv2nG0Drm77/1fgWQxuiDULc7Zkbe1U0WOt/zYG58hfuFZ1VdWXq+r17ZfLO1vfEyO+pqVN4gLCmC5CrGNw8eA0vnsR4sUHjTl5qP064NahixBfYnAB4rjWPn4G6joOOKa1TwQe5DAXySZU27nAzqEaHgFOmIE5O1RdE5uzUepq414E7KZ96W/S77Ex1DbVOQP+Dnhra/8og/PaAV7MgRdUH2K8F1RXU9v6/bUwuPC5d43f/ycCz2jtPwbevdr32VgmdVI/DP5seoDBb9F3tr53A69t7T8B7mmTdTPwoqFtf4XBBZsF4JJZqAv4KeDu1n83sG0KcxbgvQzur383cPGMzNmSdU16zparqy2/C7hsiW0nNl+rqW3ac8bg4uBn2v7vAF49tO0723b3A+dN4f2/ZG3AG9q/2TuAzwM/v8Z1vZHBL+EHGPy1f8xq32fefkCSOjTL59wlSUfIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkd+j+nIr/ui1P/VAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-hBXOEuVSx3"
      },
      "source": [
        "incorrect_prob = 1-output_correct[output_correct['follows?'] == 1].prob_zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "xbB6wuw3VS22",
        "outputId": "84c0c6f3-8f7a-4536-eab4-f78740903f8f"
      },
      "source": [
        "plt.hist(incorrect_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([446., 302., 149., 100.,  69.,  37.,  24.,   8.,   6.,   3.]),\n",
              " array([0.50006746, 0.53385972, 0.56765199, 0.60144425, 0.63523651,\n",
              "        0.66902878, 0.70282104, 0.7366133 , 0.77040557, 0.80419783,\n",
              "        0.83799009]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w3ErQorWbA1"
      },
      "source": [
        "output_correct['emoji_sentence_len'] = output_correct['emoji_sentence'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "KIDQISuBWbGA",
        "outputId": "db8716e4-936a-4c3a-a0da-b7c35ba3343f"
      },
      "source": [
        "output_correct[output_correct['emoji_sentence_len'] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "      <th>emoji_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42801</td>\n",
              "      <td>Watch your PH balance not my page</td>\n",
              "      <td>ğŸ™‚</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430891</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44976</td>\n",
              "      <td>15 gcash â€¢ like and rt [USER]'s pinned â€¢ retwe...</td>\n",
              "      <td>ğŸ“Œ</td>\n",
              "      <td>1</td>\n",
              "      <td>0.274290</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>75250</td>\n",
              "      <td>Hennessy and dangerous. And I canâ€™t front like...</td>\n",
              "      <td>ğŸ™‚</td>\n",
              "      <td>0</td>\n",
              "      <td>0.502358</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>59363</td>\n",
              "      <td>Standing at the bus stop today, with my mask o...</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>0</td>\n",
              "      <td>0.521341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>104893</td>\n",
              "      <td>Man everything be so funny to me I canâ€™t take ...</td>\n",
              "      <td>ğŸ˜”</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4424</th>\n",
              "      <td>15421</td>\n",
              "      <td>[USER] Ndimi munozonzi my Ex is back in thd pi...</td>\n",
              "      <td>ğŸ˜‰</td>\n",
              "      <td>1</td>\n",
              "      <td>0.493969</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4427</th>\n",
              "      <td>104774</td>\n",
              "      <td>[USER] YES   we have a lot of different styles...</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>0</td>\n",
              "      <td>0.516527</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>37450</td>\n",
              "      <td>[USER] alright then we move  just hmu whenever</td>\n",
              "      <td>ğŸ¤</td>\n",
              "      <td>1</td>\n",
              "      <td>0.465126</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4430</th>\n",
              "      <td>18250</td>\n",
              "      <td>self sabotaged at work again and got Mac and c...</td>\n",
              "      <td>ğŸ˜”</td>\n",
              "      <td>1</td>\n",
              "      <td>0.487529</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4435</th>\n",
              "      <td>75342</td>\n",
              "      <td>I would never let a female use a strap because...</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509789</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1743 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... emoji_sentence_len\n",
              "1      42801  ...                  1\n",
              "5      44976  ...                  1\n",
              "9      75250  ...                  1\n",
              "12     59363  ...                  1\n",
              "13    104893  ...                  1\n",
              "...      ...  ...                ...\n",
              "4424   15421  ...                  1\n",
              "4427  104774  ...                  1\n",
              "4428   37450  ...                  1\n",
              "4430   18250  ...                  1\n",
              "4435   75342  ...                  1\n",
              "\n",
              "[1743 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtU4ZQE4WbK7"
      },
      "source": [
        "output_incorrect['emoji_sentence_len'] = output_incorrect['emoji_sentence'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "1f30Ze5jWbPg",
        "outputId": "3e201d57-2b6a-42c1-fa3d-3b4ca1719b54"
      },
      "source": [
        "output_incorrect[output_incorrect['emoji_sentence_len'] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "      <th>emoji_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77593</td>\n",
              "      <td>Youâ€™re just so beautiful</td>\n",
              "      <td>ğŸ’€</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40054</td>\n",
              "      <td>Want to tease someone until they cry</td>\n",
              "      <td>ğŸ˜¢</td>\n",
              "      <td>1</td>\n",
              "      <td>0.553649</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32019</td>\n",
              "      <td>Iâ€™ll figure this out. I always do and I always...</td>\n",
              "      <td>ğŸ˜¤</td>\n",
              "      <td>1</td>\n",
              "      <td>0.569586</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35360</td>\n",
              "      <td>[USER] Can you do body rolls too?</td>\n",
              "      <td>ğŸ§</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521023</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>76988</td>\n",
              "      <td>good morning</td>\n",
              "      <td>ğŸ™„</td>\n",
              "      <td>0</td>\n",
              "      <td>0.249820</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>23112</td>\n",
              "      <td>[USER] Hitting the Plymouth tomorrow.  If you ...</td>\n",
              "      <td>ğŸ˜</td>\n",
              "      <td>1</td>\n",
              "      <td>0.568806</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>81505</td>\n",
              "      <td>[USER] [USER] I'm sorry for your loss!</td>\n",
              "      <td>ğŸ˜Š</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455440</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4432</th>\n",
              "      <td>11677</td>\n",
              "      <td>tmap ep. 38 gave us so much happiness. Today's...</td>\n",
              "      <td>ğŸ˜­</td>\n",
              "      <td>1</td>\n",
              "      <td>0.571603</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4433</th>\n",
              "      <td>14708</td>\n",
              "      <td>Learning to LOVE yourself the RIGHT away it th...</td>\n",
              "      <td>ğŸ¥°</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583106</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4436</th>\n",
              "      <td>33923</td>\n",
              "      <td>[USER] We downgraded our CSP to the Flex last ...</td>\n",
              "      <td>ğŸ˜¬</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531143</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1608 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... emoji_sentence_len\n",
              "0     77593  ...                  1\n",
              "3     40054  ...                  1\n",
              "4     32019  ...                  1\n",
              "7     35360  ...                  1\n",
              "8     76988  ...                  1\n",
              "...     ...  ...                ...\n",
              "4429  23112  ...                  1\n",
              "4431  81505  ...                  1\n",
              "4432  11677  ...                  1\n",
              "4433  14708  ...                  1\n",
              "4436  33923  ...                  1\n",
              "\n",
              "[1608 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvR7lyRfX31T",
        "outputId": "0ff94643-4a4e-4107-a725-4eff8e748922"
      },
      "source": [
        "df_test['follows?'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2259\n",
              "1    2179\n",
              "Name: follows?, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}