{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_emoji_project_LR_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NNWwwg_V8BV6",
        "DtuXsHxF8hgO",
        "sLkaHBPAioHf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6omA1Kcjev_",
        "outputId": "082a6400-35bc-4e11-d6b2-18de70340bd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn_hEojLp9XH",
        "outputId": "69b535c9-9cbd-4588-e124-187f88063fc6"
      },
      "source": [
        "import gensim.models as gsm\n",
        "import gensim.downloader\n",
        "import pandas as pd\n",
        "import time\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfus74UCYZh5"
      },
      "source": [
        "**Emoji2Vec Download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzvLfnqOpN_Z"
      },
      "source": [
        "e2v = gsm.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/2021_NLU/emoji2vec.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72SXbLsK8Tyg",
        "outputId": "f2e0f0da-4a26-4869-ce86-53faf705b882"
      },
      "source": [
        "e2v.vector_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTxO6FnEpR_U",
        "outputId": "dfd0f6a2-3a40-4432-d6d0-ce042a8a739f"
      },
      "source": [
        "happy_vector = e2v['😂']  \n",
        "happy_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SyeCbyypR2p",
        "outputId": "1a5b8920-0214-4883-cb7d-f1167d29097e"
      },
      "source": [
        "print(len(e2v.vocab))\n",
        "print(e2v.vocab.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1661\n",
            "dict_keys(['🇸🇰', '👔', '🌀', '🚾', '👹', '🚻', '👬', '🇫🇯', '🎧', '🐽', '🚜', '♋', '🚭', '🚷', '📅', '💈', '✔️', '🙎🏼', '🍸', '🤷', '🌂', '🚓', '🍤', '💘', '🚔', '👚', '🐧', '🍥', '🍵', '✂️', '👓', '⛔', '💂', '🆔', '😕', '🎎', '🏊🏻', '❗', '💭', '💬', '🎴', '♉', '⚖', '🇮🇩', '🛵', '⬅️', '📒', '😡', '🇲🇦', '🇨🇭', '🍦', '❗️', '🌐', '🎡', '🇿🇲', '🤒', '🔓', '🎻', '😹', '🚮', '👽', '🌝', '🇭🇺', '🐆', '🇰🇵', '💔', '🎅🏻', '👇🏽', '🍆', '👃🏽', '🐖', '😮', '✴️', '➗', '⌚', '🆎', '👻', '🗻', '🇨🇺', '😟', '💣', '💁', '🦀', '🇬🇭', '🎩', '🇼', '👉🏾', '🙊', '🍚', '🍙', '🚯', '👩🏿', '🇫🇷', '👸🏼', '😿', '😲', '🇲🇰', '🔢', '🚬', '💅', '🏀', '🍷', '🙈', '👭', '🍯', '🏰', '🖨', '🍨', '🆗', '😩', '🎉', '🤐', '🥡', '⚫️', '🏣', '🌹', '🌯', '🎆', '▶️', '🔮', '🙌', '🆚', '🙆', '🎒', '💆', '🔰', '🌜', '🌕', '🎑', '😳', '⚓', '🐫', '♐', '👂', '\\ue50a', '💃', '🐼', '🍣', '🏧', '🎠', '🌴', '😏', '🛅', '💶', '⚽', '♎', '🏫', '😃', '🇸🇮', '🔒', '⛺', '🚥', '💵', '🍺', '💀', '🌅', '🐜', '♣️', '🔔', '🙆🏿', '💉', '💯', '🍕', '👣', '🍌', '🥔', '🐸', '👃🏻', '🍮', '💞', '👵🏽', '🇳🇬', '🚦', '🚣', '💕', '🐾', '🏂', '👎', '🐀', '🚝', '😻', '🛣', '🎈', '🐅', '🇭🇳', '🦃', '🐌', '🏋', '🌎', '✈️', '🇨🇲', '😂', '🌡', '🔏', '😙', '🇸🇧', '👅', '🕸', '🇩🇪', '👨\\u200d👩\\u200d👦\\u200d👦', '🌒', '🍹', '😛', '🏍', '💒', '👯', '❄️', '😒', '🔌', '🌑', '🚤', '🏓', '🍳', '🍔', '🙋🏿', '😀', '🙏', '🌵', '🚏', '🍋', '☘', '🍀', '✌️', '🍠', '🌗', '🏬', '🚉', '🎅🏽', '🍗', '🖖🏽', '⛽', '🌱', '💴', '👐🏾', '🐭', '🈲', '⛄', '🌄', '🎰', '🖖🏼', '🐤', '🈵', '🚌', '🎪', '🎅', '👳', '🍴', '👰', '🏇🏽', '💿', '🙂', '🎓', '🆖', '🚵', '🇪🇬', '🔟', '🐣', '♓️', '🇸🇻', '🙅🏻', '🤰', '🏒', '🇵🇬', '💠', '🎾', '🎳', '🛤', '👺', '🤦', '🇩🇴', '🚂', '💷', '🍏', '🔜', '✡', '👲', '🚘', '📍', '®️', '🌠', '🎃', '🏩', '💳', '😊', '🍟', '♌️', '☔', '🇬🇧', '👟', '🌛', '🏷', '💮', '👋', '🕉', '👃', '🎱', '🍓', '🗨', '🚕', '🇱🇺', '🌇', '👎🏾', '🇶', '🎫', '💧', '😎', '👫', '♋️', '😋', '🖖', '🚺', '😖', '🇦🇼', '🌁', '🐕', '♊', '🐟', '🙎🏻', '♈', '🐝', '🇮🇳', '✋', '🏇', '🙅', '🌻', '9️⃣', 'ℹ️', '5⃣️', '🈁', '👏', '🌉', '👿', '🎐', '🇪🇸', '🎍', '👍🏿', '🚣🏿', '🖇', '🍰', '🇸🇩', '🚎', '🚡', '🎯', '🔼', '👦🏿', '😪', '⛵️', '▪️', '🇱', '🙋', '😴', '😔', '🇦🇲', '⛷', '😱', '📨', '🆙', '🚟', '😰', '💐', '🚰', '✳️', '🌚', '🍬', '🔉', '💱', '🏐', '🍩', '❤️', '👰🏽', '🏄🏼', '🇦🇫', '💜', '⚠️', '🛁', '🎂', '🎷', '🐄', '⏸', '🙀', '🇨🇩', '☕️', '🌈', '🚪', '🇷🇪', '👩', '♐️', '🤢', '🇲🇪', '📤', '🇷🇼', '🇵', '🎨', '💤', '⚰', '🍡', '⚪️', '🚴', '🎽', '😵', '🇳🇪', '😥', '🇬🇵', '👁', '🐺', '🚞', '🚙', '🍞', '🇦🇴', '🎸', '🔣', '🍭', '🌌', '💏', '🌸', '🇧🇲', '👖', '👊🏽', '👆', '🛋', '🌾', '🏆', '🌞', '🌋', '😁', '🏄', '👴🏼', '👩🏾', '🙅🏼', '🏮', '😄', '1⃣️', '🎣', '♒️', '🍛', '📎', '🇸🇷', '⛄️', '🇱🇹', '🚛', '🚅', '🖕', '🐪', '🚁', '🇰🇪', '🛃', '🇵🇷', '🇭🇰', '🇵🇼', '📛', '😅', '🅱️', '🎭', '🍢', '♍️', '🈚', '👴', '🏠', '⚓️', '🗝', '💽', '🎹', '😈', '🇳🇨', '🇻🇳', '📰', '7️⃣', '🍻', '😉', '💍', '🚶', '🙇🏽', '🐞', '🍲', '🍉', '🐲', '🇳🇵', '👤', '😞', '🎶', '🇦🇮', '👄', '🗿', '🌆', '🚀', '👱🏿', '🍼', '🏞', '〽️', '🐍', '4⃣️', '📦', '♌', '♿️', '♒', '🇵🇸', '🇮🇶', '🌃', '🎬', '😷', '👒', '📲', '🔥', '♏️', '🐡', '🎢', '🐨', '📆', '⭕', '🚖', '🏉', '😓', '🏜', '🌿', '🏨', '🎏', '🇦🇹', '🇬🇾', '🌖', '🇧🇼', '🚽', '👐', '🐇', '🇲🇶', '🎲', '🐢', '😸', '🗃', '🕵', '🍱', '🐉', '😺', '😫', '🌭', '🍧', '🍝', '🙍', '🙉', '🇵🇭', '🕷', '🖼', '✏️', '😨', '💻', '🔈', '🇩🇿', '💸', '🏊', '🍶', '🇲🇳', '🚢', '🏁', '🚶🏿', '♑️', '🙇', '🇭🇹', '🐏', '👊🏼', '😤', '🇮🇱', '🐷', '💰', '👆🏿', '↪️', '👕', '🔎', '🏏', '🤵', '💃🏽', '⛺️', '👉🏼', '💙', '😗', '🇬🇺', '🚍', '☎️', '🇨🇰', '🛐', '🇻🇦', '👌', '🚩', '🥄', '🎋', '✊', '⚡', '📿', '🌲', '👀', '🚒', '😌', '🤗', '🇻🇪', '🎄', '📩', '🍖', '🇻🇺', '🏳', '🦇', '🇨🇻', '💫', '🔡', '🍍', '🎤', '👃🏼', '🥙', '🚈', '🔋', '😬', '♨️', '🌥', '🐎', '🕺', '👨\\u200d👨\\u200d👧', '🔪', '✊🏽', '🎿', '🚣🏾', '🙍🏿', '🌼', '🔙', '✋🏿', '🎮', '⚪', '🖤', '🎼', '🇦🇿', '🇿🇦', '♑', '❎', '😭', '📳', '👇🏾', '🎵', '😘', '🙏🏼', '🇼🇸', '😜', '🐻', '🌘', '🇪🇺', '🇹🇨', '🇯', '🐮', '🏥', '🐩', '🇧🇳', '🚱', '🌟', '💇', '🎁', '🍎', '👳🏾', '🚨', '🌰', '🚐', '🇦🇩', '♓', '📹', '🕎', '🌍', '🇧🇧', '🚳', '📱', '🙇🏻', '🐛', '🇯🇵', '✅', '🔫', '🇲🇴', '🇸🇨', '🕍', '🚫', '🐒', '👨\\u200d👩\\u200d👧\\u200d👦', '😼', '🇹🇳', '⚙', '🇦🇬', '3⃣️', '👶🏽', '🌔', '✉️', '🇸🇽', '👨🏼', '🚣🏽', '🕯', '😍', '🇰🇾', '👾', '🚃', '🎛', '🤳', '🌦', '🇬🇦', '🏪', '📝', '🇧🇴', '🇵🇪', '🚹', '⛸', '💩', '🦅', '🤠', '🇰🇮', '🗂', '👈🏾', '♍', '👦🏽', '👞', '🌷', '🕴', '🇹🇼', '👨\\u200d❤️\\u200d💋\\u200d👨', '🇳🇫', '🎊', '🔩', '🇦🇸', '🇮🇴', '🏎', '🙌🏽', '🚶🏾', '🛄', '🚧', '🇹🇬', '💟', '🇸🇪', '🇲🇼', '👈🏻', '💥', '🖌', '👍🏾', '💅🏻', '💗', '💡', '🏟', '🌫', '🌬', '♦️', '⏰', '☯', '💪', '🔑', '💊', '🇬🇮', '☝️', '👩\\u200d❤️\\u200d👩', '♎️', '🖐', '🐗', '🏃', '🇨🇳', '👛', '🚿', '🐔', '🔍', '🐰', '🖲', '👨🏿', '🤞', '🌊', '🔄', '🇦🇶', '🎺', '🛌', '🇲🇿', '👼🏼', '🏄🏿', '🇴🇲', '🤝', '☕', '🙏🏾', '🙌🏿', '🔳', '🐱', '🇵🇾', '💢', '💆🏼', '⬆️', '🎦', '🎀', '🤺', '📚', '🇰🇲', '🌺', '🍊', '💅🏼', '🐙', '🍂', '😶', '😐', '🍐', '🏅', '📃', '❌', '🤣', '🇧🇶', '➖', '🙎🏿', '👱🏾', '👢', '🏵', '🗽', '🍄', '👇', '🇸🇦', '🔬', '🍿', '🙎', '🇸🇬', '🐥', '🤡', '⛰', '🖱', '🌓', '🐑', '🎥', '🏦', '🌙', '🀄', '🍑', '🔨', '🌏', '👎🏼', '💪🏿', '🇲🇹', '🛍', '🇫🇴', '⛪', '🇸🇴', '🇭🇷', '🇿🇼', '💁🏾', '🍘', '⏲', '🇹🇫', '👈🏼', '👸', '💂🏼', '↖️', '📼', '👰🏼', '👪', '🤘', '🍁', '👙', '⛲', '🚸', '🙆🏻', '📇', '🗜', '🇽🇰', '✊🏾', '💚', '🌳', '📻', '🐵', '👉🏽', '😝', '💛', '📧', '🥐', '🐐', '😚', '📖', '🏈', '😦', '🚋', '🐹', '🚼', '🇦🇺', '🇳🇱', '👊🏿', '🚄', '⭐️', '🛥', '💂🏻', '🤥', '👌🏿', '🦁', '💲', '🇾🇹', '🚶🏻', '🤶', '🇰🇷', '⭐', '✊🏿', '🇧🇫', '👮🏽', '☺️', '✋🏻', '🏯', '👷🏾', '⛪️', '💝', '🏘', '🌪', '👈', '🚵🏼', '2⃣️', '🇾🇪', '🤖', '📵', '🇨🇱', '🚠', '🇹🇭', '💨', '🇹🇷', '🍪', '😠', '🆑', '🇷🇴', '👳🏼', '💪🏽', '🕔', '🛀', '🐿', '6⃣️', '👎🏻', '🇨🇨', '👝', '🍃', '🌽', '🇹🇿', '🇨🇽', '🈺', '⛅', '🍫', '☠', '🚆', '🚚', '👉', '🇳🇮', '🤕', '👩\\u200d👩\\u200d👦\\u200d👦', '👍', '🇬🇶', '🇨🇾', '🏚', '🥘', '🐈', '🏔', '8️⃣', '🇧🇻', '🇮🇨', '🇸', '👧🏿', '👲🏿', '☀️', '🙅🏽', '🕖', '❓', '🇨🇵', '⛎', '🏕', '👘', '🙇🏾', '🉐', '🇮🇹', '📫', '🏑', '🐚', '🇺🇬', '🔦', '🕳', '🇪🇭', '🇿', '🇫🇮', '👏🏿', '🇺🇾', '🇮🇪', '😽', '👨\\u200d👩\\u200d👧\\u200d👧', '😾', '🙋🏽', '👆🏽', '🗡', '🀄️', '👸🏾', '⛈', '🦆', '👗', '📐', '👧🏾', '👮🏿', '🕰', '♏', '🎖', '🏄🏾', '🇹🇦', '🗣', '👼🏻', '🔸', '🃏', '🖊', '🛂', '🌶', '👂🏼', '🇨🇮', '🥒', '🤾', '📯', '😢', '🔇', '💾', '🦏', '🇺🇸', '👁\\u200d🗨', '😯', '⚔', '🇲🇭', '🍇', '👵🏼', '🥃', '💅🏽', '🚊', '🇧🇦', '🤑', '🇹🇯', '💹', '👑', '6️⃣', '⏱', '🇲🇽', '☢', '🇰🇿', '🇬🇫', '📡', '🇲🇾', '📏', '🆒', '🙅🏿', '👴🏿', '🅿️', '🗾', '❇️', '🇱🇧', '💋', '👡', '👍🏻', '🈯', '👏🏾', '🐴', '🇨🇫', '💇🏼', '🙋🏻', '💼', '🇬🇹', '🙄', '👥', '🇱🇦', '👷🏿', '🇯🇲', '🥀', '💓', '🛳', '♉️', '🇧🇹', '🇳🇴', '⁉️', '🔛', '🖋', '👌🏾', '📮', '♊️', '👨', '😑', '📕', '📂', '👮', '😧', '🇦🇷', '🗺', '🏺', '👵🏿', '🖖🏿', '👊', '🆓', '🐋', '🖥', '♥️', '🇷🇸', '👷', '🉑', '✋🏽', '🐓', '☮', '👈🏿', '🐃', '🇸🇱', '🥕', '📪', '🐶', '🇹🇻', '🚵🏽', '🇸🇲', '🤧', '🛏', '🇧🇩', '🔚', '◼️', '🔊', '🚗', '🇧🇮', '🕚', '🇷🇺', '🇵🇳', '⛅️', '🏊🏽', '📭', '㊙️', '🔆', '⚛', '🔐', '🇰🇳', '☂', '📌', '⛳', '📀', '🇹🇩', '🙍🏽', '👼🏿', '🇧🇭', '✝', '⚗', '👨\\u200d❤️\\u200d👨', '👋🏼', '🛀🏽', '🙃', '😇', '⚫', '📓', '🍽', '🇩🇲', '📬', '🔠', '📟', '🇮', '🈂️', '📴', '⛓', '📺', '📢', '🎟', '🕓', '🔝', '🈹', '👼', '🔁', '🍜', '⚡️', '👍🏼', '💑', '🙎🏽', '🇧🇯', '👠', '🔗', '🇫🇰', '👷🏽', '📶', '💎', '🔕', '📋', '✨', '🤹', '🚴🏼', '🕗', '🏊🏿', '🔯', '🇰🇬', '🦈', '👱', '‼️', '🔷', '🕑', '🙍🏾', '🎅🏿', '🈴', '🐠', '👨\\u200d👨\\u200d👦', '🈶', '✋🏾', '◀️', '👧🏻', '🏃🏾', '🤚', '🇸🇸', '◽️', '🇬🇩', '👰🏻', '🏃🏼', '🙁', '🇲🇷', '🇶🇦', '👴🏻', '🇬🇲', '🇨🇦', '🖖🏻', '💌', '🎅🏾', '🇱🇰', '👩\\u200d👩\\u200d👦', '👇🏿', '💄', '🇦🇪', '⛔️', '🇩🇯', '🏇🏾', '💦', '🇪🇷', '☔️', '🤤', '🇲🇻', '🐯', '👸🏻', '🚵🏻', '⛲️', '🚶🏽', '♈️', '🇵🇰', '👎🏽', '📑', '🇱🇷', '⛽️', '👍🏽', '🏊🏼', '⛳️', '📠', '🔂', '♻️', '🛀🏿', '🧀', '🗯', '🚴🏿', '🍈', '⤴️', '1️⃣', '😆', '🆘', '💺', '🇻🇬', '🇫🇲', '🇳🇿', '☹', '💪🏻', '👴🏾', '☄', '👇🏻', '💃🏿', '📄', '👶', '🇺🇿', '💅🏾', '⬜️', '🍾', '🔖', '🇨🇿', '🇪🇨', '🔱', '🇦🇽', '📷', '❣', 'Ⓜ️', '🇳🇷', '🇲🇺', '👵', '🇬🇷', '❕', '🦊', '▫️', '🕶', '🇧🇷', '🇵🇹', '🇲🇱', '🕋', '👏🏼', '🐊', '🛬', '🔤', '🏹', '🌮', '🔽', '➿', '㊗️', '🗳', '🏇🏻', '🇸🇿', '🇸🇳', '👩🏼', '🤔', '💃🏻', '🛰', '👂🏾', '🇵🇦', '👷🏼', '🛀🏾', '⚾', '🇴', '🚑', '🥗', '🇬🇱', '🕒', '🚴🏽', '🛠', '🍒', '👌🏽', '👦', '🥓', '👸🏽', '🏙', '👲🏻', '🇺🇦', '🚣🏻', '➰', '👐🏻', '🇪🇹', '◻️', '🍅', '🇨🇷', '🦂', '0️⃣', '⏩', '👉🏿', '🖍', '🇹🇲', '👰🏾', '💖', '🅾️', '🦉', '📘', '🇧🇸', '🇹🇰', '💆🏻', '📊', '✋🏼', '🇧🇪', '⛩', '🇪🇪', '🇦🇱', '⌚️', '🇰🇭', '🌤', '🇯🇴', '🚲', '#️⃣', '🇳🇺', '↙️', '🏌', '👩\\u200d👩\\u200d👧\\u200d👧', '✒️', '🔹', '🏡', '☁️', '🇦🇨', '🇬', '👇🏼', '🗓', '💃🏾', '🕹', '◽', '🏇🏼', '🇱🇾', '👳🏿', '👌🏻', '🏇🏿', '🇵🇫', '🛑', '👜', '⬛️', '🇳', '🏤', '🇱🇮', '🔭', '😣', '🏃🏻', '🤴', '🇸🇾', '🙋🏼', '📣', '⌛', '🇬🇬', '⬇️', '👐🏼', '📞', '🇲🇩', '➕', '🇧🇿', '👩\\u200d❤️\\u200d💋\\u200d👩', '🇳🇦', '🇪', '📜', '🇱🇨', '👃🏿', '💁🏼', '💁🏽', '🎌', '🙆🏼', '🕙', '🙍🏼', '👵🏻', '🈷️', '👶🏻', '👲🏼', '⏹', '🎗', '⛹', '🔴', '🌨', '📗', '☃', '💇🏻', '🇵🇱', '⚱', '🇬🇼', '🚴🏾', '👩\\u200d👩\\u200d👧', '🕐', '🎅🏼', '🇩🇬', '🗒', '🇨🇼', '👱🏻', '👨\\u200d👨\\u200d👧\\u200d👧', '📔', '🙅🏾', '♿', '♠️', '☪', '🛀🏼', '👆🏻', '🇯🇪', '🏢', '📈', '🤓', '☑️', '🥂', '🚇', '5️⃣', '🙌🏻', '🏝', '🐂', '⚽️', '🏄🏽', '🇮🇸', '🗞', '👂🏿', '🦄', '👦🏻', '👨\\u200d👨\\u200d👧\\u200d👦', '⬛', '🔀', '🙆🏾', '🈸', '◾️', '👧', '👐🏽', '🇲🇸', '🚶🏼', '™️', '🆕', '🔧', '🗼', '🕛', '3️⃣', '🙌🏼', '💇🏿', '🇱🇸', '🇲🇬', '👋🏾', '🇮🇷', '☣', '🔞', '🏸', '🈳', '👵🏾', '💁🏿', '🇲🇵', '🕌', '🕕', '✍', '🔵', '📁', '👼🏾', '⤵️', '©️', '👲🏾', '🇻', '🇨🇴', '👊🏻', '🕊', '💃🏼', '👋🏿', '🇧🇬', '📥', '〰️', '🐁', '🖖🏾', '🎚', '❔', '👨\\u200d👩\\u200d👧', '↗️', '🚴🏻', '🇹🇹', '🛢', '👱🏽', '👐🏿', '🇹🇴', '👋🏻', '⚒', '📉', '💂🏽', '🐘', '⏏', '👨🏾', '🙌🏾', '🇬🇪', '↔️', '👎🏿', '🎞', '🇰🇼', '🦋', '💪🏾', '🇮🇲', '👨\\u200d👨\\u200d👦\\u200d👦', '👨🏽', '4️⃣', '👧🏽', '👮🏼', '👳🏻', '👶🏾', '💂🏾', '👌🏼', '👧🏼', '🎙', '🇻🇮', '✖️', '🏊🏾', '🛴', '↕️', '🐦', '👶🏿', '🇻🇨', '🙏🏻', '👼🏽', '🇧🇾', '🌧', '⌛️', '💅🏿', '🇬🇳', '⌨', '👏🏻', '⏺', '🏛', '🇨🇬', '🤛', '🛩', '👊🏾', '⭕️', '👉🏻', '🙇🏿', '💇🏾', '*⃣', '◾', '📽', '🥑', '👃🏾', '⛑', '🕘', '🙏🏽', '⛴', '🇲🇨', '7⃣️', '💆🏿', '✊🏻', '👮🏾', '👂🏽', '🔅', '🚵🏾', '🗄', '🙋🏾', '👳🏽', '🏗', '2️⃣', '👋🏽', '🏄🏻', '💁🏻', '🇩🇰', '👏🏽', '🔘', '👱🏼', '🌩', '🇱🇻', '🎇', '\\u200d', '👶🏼', '➡️', '🇲🇲', '⛱', '↘️', '🚣🏼', '🏃🏽', '🏴', '🛎', '🅰️', '🙎🏾', '👩🏻', '✊🏼', '👩🏽', '⛏', '9⃣️', '👨🏻', '🔃', '💆🏽', '👆🏼', '💂🏿', '🛫', '🚵🏿', '🛡', '👂🏻', '🥖', '🇺', '👮🏻', '⏪', '📙', '🏭', '👰🏿', '👦🏾', '👆🏾', '💇🏽', '🛀🏻', '👲🏽', '🙇🏼', '🤙', '🔲', '🇹🇱', '⏳', '👦🏼', '🇸🇹', '🇽', '🙍🏻', '🐳', '🙆🏽', '👈🏽', '🏃🏿', '💪🏼', '🗑', '👴🏽', '🤜', '📸', '🐬', '💆🏾', '🏖', '⬜', '👷🏻', '👸🏿', '🔶', '⚾️', '☸', '↩️', '☦', '👩\\u200d👩\\u200d👧\\u200d👦', '🙏🏿'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COtWbV2QYjF3"
      },
      "source": [
        "**Word2Vec Download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M0DFXRrpkdq",
        "outputId": "c79592d9-9e19-4448-8776-1c6f4e906111"
      },
      "source": [
        "word2vec = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVcr51LL38lL"
      },
      "source": [
        "pickle.dump(word2vec, open('/content/drive/MyDrive/2021_NLU/data/full_data/word2vec.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yH7euci0mEU"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/word2vec.pkl', 'rb') as f:  \n",
        "    word2vec = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_owdfNn0ar6"
      },
      "source": [
        "## FULL DATA (SINGLE AND MULTI) - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjw34dNoqAQw"
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/full_data/emoji_nsp_dataset_train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39ly4uVw2anB"
      },
      "source": [
        "df_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/full_data/emoji_nsp_dataset_valid.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR8PpYFo99HG"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/full_data/emoji_nsp_dataset_test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1TAAIGd9rBi_",
        "outputId": "399f4e8f-6e22-4d93-8cad-9630fae59f5b"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50553</td>\n",
              "      <td>The dababy memes make no sense and that’s why ...</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>74541</td>\n",
              "      <td>a year ago today i would be holding my breath ...</td>\n",
              "      <td>😵</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50992</td>\n",
              "      <td>I told my mama about how the music industry is...</td>\n",
              "      <td>💯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95343</td>\n",
              "      <td>[USER] [USER] Thankyou guys</td>\n",
              "      <td>💯</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60555</td>\n",
              "      <td>You want new SUBS? Like ️ Retweet Follow me  R...</td>\n",
              "      <td>😂😂</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  50553  ...        1\n",
              "1  74541  ...        0\n",
              "2  50992  ...        1\n",
              "3  95343  ...        0\n",
              "4  60555  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCl9_bZvrsQm",
        "outputId": "b1a991b0-d9c2-4283-d61e-2b61993b3a92"
      },
      "source": [
        "df_train.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index             15540\n",
              "tweets            15540\n",
              "emoji_sentence    15540\n",
              "follows?          15540\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebl2VyhL44Kl",
        "outputId": "b1832780-0391-4269-f79a-e8593ac03cea"
      },
      "source": [
        "df_train[\"emoji_sentence\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         😎\n",
              "1         🤭\n",
              "2         🥺\n",
              "3         🙏\n",
              "4         🙃\n",
              "         ..\n",
              "15535     🤷\n",
              "15536     🤣\n",
              "15537     🥺\n",
              "15538    🙌🍺\n",
              "15539    🙄😋\n",
              "Name: emoji_sentence, Length: 15540, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaS2Ayhm6j6q",
        "outputId": "053d5ffc-60d2-4749-f42c-c9256fa753c0"
      },
      "source": [
        "df_train[\"emoji_sentence\"].isna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        False\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "14396    False\n",
              "14397    False\n",
              "14398    False\n",
              "14399    False\n",
              "14400    False\n",
              "Name: emoji_sentence, Length: 14401, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvzvJ2-nqm2",
        "outputId": "6a9b8f5c-b9d1-4ca6-adf5-80045d715ba9"
      },
      "source": [
        "print(len(df_train))\n",
        "print(len(df_val))\n",
        "print(len(df_test))\n",
        "\n",
        "df_train = df_train.dropna().drop_duplicates()\n",
        "df_val = df_val.dropna().drop_duplicates()\n",
        "df_test = df_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_val))\n",
        "print(len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "2199\n",
            "4438\n",
            "15540\n",
            "2199\n",
            "4438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNWwwg_V8BV6"
      },
      "source": [
        "###Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrP-V85go6Ez"
      },
      "source": [
        "def make_lowercase(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - list of documents\n",
        "\t- output: data - list of documents after lowercasing everything\n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\tstart = time.time()\n",
        "\tdata = [i.lower() for i in data]\n",
        "\n",
        "\tend = time.time()\n",
        "\tprint('\\n       ##### Lowercasing Done! Time Taken - ',end-start)\n",
        "\treturn data                                                                       \n",
        "\n",
        "\n",
        "def punctuation_removal(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - list of documents\n",
        "\t- output: data - list of documents after removing punctuation\n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\tstart = time.time()\n",
        "\tdata = [i.translate(str.maketrans(string.punctuation,' '*len(string.punctuation))) for i in data]\n",
        "\tend = time.time()\n",
        "\tprint('\\n       ##### Punctuation removed! Time Taken - ',end-start)\n",
        "\treturn data\n",
        "\n",
        "def whitespace_removal(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - \n",
        "\t- output: data - \n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\tstart = time.time()\n",
        "\tdata = [' '.join(mystring.split()) for mystring in data]\n",
        "\t# data = [i.strip() for i in data]\n",
        "\tend = time.time()\n",
        "\tprint('\\n       ##### Whitespace removed! Time Taken - ',end-start)\n",
        "\treturn data\n",
        "\n",
        "# TOKENIZATION with NLTK\n",
        "def tokenization_nltk(data, debug=False):\n",
        "\t'''\n",
        "\t- input: data - \n",
        "\t- output: data - \n",
        "\t'''\n",
        "\tif(debug):\n",
        "\t\tprint(\"data_sample out of \",len(data))\n",
        "\t\tprint(data[:sample_to_print])\n",
        "\t# Using NLTK\n",
        "\tstart = time.time()\n",
        "\tdata = [nltk.word_tokenize(i) for i in data]\n",
        "\tend = time.time()\n",
        "\t# Using Spacy - Spacy takes too much time\n",
        "\t#data = [[token.text for token in nlp_spacy(i)] for i in data]\n",
        "\tprint('\\n       ##### Tokenization Done using NLTK! Time Taken - ', end-start)\n",
        "\treturn data\n",
        "\n",
        "# #used to search in nltk stop_words\n",
        "# def BinarySearch(a, x): \n",
        "# \ti = bisect_left(a, x) \n",
        "# \tif i != len(a) and a[i] == x:\n",
        "# \t\treturn i \n",
        "# \telse: \n",
        "# \t\treturn -1\n",
        "\n",
        "# def stopwords_removal(data, stop_words_nltk, debug=False):\n",
        "# \t'''\n",
        "# \t- input: data - \n",
        "# \t- output: data - \n",
        "# \t'''\n",
        "# \tif(debug):\n",
        "# \t\tprint(\"stopwords_removal_nltk data_sample out of \",len(data))\n",
        "# \t\tprint(data[:sample_to_print])\n",
        "# \t#using NLTK\n",
        "# \tstart = time.time()\n",
        "# \tdata = [[j for j in doc if (BinarySearch(stop_words_nltk,j)<0)] for doc in data]\n",
        "# \tdata = [[x for x in word if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())] for word in data]\n",
        "# \tend = time.time()\n",
        "# \tprint('\\n       ##### Stopwords Removed using NLTK! Time Taken - ',end-start)\n",
        "# \treturn data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T0O29AYoGgT"
      },
      "source": [
        "def clean_text(sample, debug=False):\n",
        "  '''\n",
        "  sample should be a list of documents\n",
        "  '''\n",
        "\n",
        "\n",
        "  # sample = remove_string_with_nonASCII(sample)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  # sample = preprocess_tweet_text(sample)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "    \n",
        "  sample = make_lowercase(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  sample = punctuation_removal(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  sample = whitespace_removal(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  sample = tokenization_nltk(sample)\n",
        "  if debug:\n",
        "    print(sample[:2])\n",
        "\n",
        "  # sample = tokenization_spacy(sample)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  # sample = lemmatization_tokenization_spacy(sample)\n",
        "  # if debug:\n",
        "    # print(sample[:2])\n",
        "\n",
        "  # sample = stopwords_removal(sample, stop_words_nltk)\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  # sample = make_bigrams_gensim(sample, bigrams_min_count=10, bigrams_threshold=10) #params from gensim\n",
        "  # if debug:\n",
        "  #   print(sample[:2])\n",
        "\n",
        "  sample_normal = [' '.join(i) for i in sample]\n",
        "  # Sample tokenized is used for Word2Vec\n",
        "\n",
        "  return sample, sample_normal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iddyM7tMqGa0",
        "outputId": "275907a0-80fe-40be-fe3e-6f4defd3a8e1"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_tokenized, x_train_normal = clean_text(df_train['tweets'].values)\n",
        "x_val_tokenized, x_val_normal = clean_text(df_val['tweets'].values)\n",
        "x_test_tokenized, x_test_normal = clean_text(df_test['tweets'].values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.012780904769897461\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.09380507469177246\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.02262401580810547\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  2.0198376178741455\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.00092315673828125\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.013142824172973633\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.003053903579711914\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.2526061534881592\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0018680095672607422\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.02589106559753418\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.006514072418212891\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.5394716262817383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mFlX8HC8Nj2"
      },
      "source": [
        "y_train = df_train['follows?'].values\n",
        "y_val = df_val['follows?'].values\n",
        "y_test = df_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szipRmZv8Ntj"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_2 = []\n",
        "x_train_tokenized_2 = []\n",
        "x_train_normal_2 = []\n",
        "empty_indices_train = []\n",
        "\n",
        "for i in range(len(x_train_tokenized)):\n",
        "  if len(x_train_tokenized[i])==0:\n",
        "    empty_indices_train.append(i)\n",
        "  else:\n",
        "    x_train_tokenized_2.append(x_train_tokenized[i])\n",
        "    x_train_normal_2.append(x_train_normal[i])\n",
        "    y_train_2.append(y_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcTijrpg9A1Z"
      },
      "source": [
        "#remove empty values for val\n",
        "y_val_2 = []\n",
        "x_val_tokenized_2 = []\n",
        "x_val_normal_2 = []\n",
        "empty_indices_val = []\n",
        "\n",
        "for i in range(len(x_val_tokenized)):\n",
        "  if len(x_val_tokenized[i])==0:\n",
        "    empty_indices_val.append(i)\n",
        "  else:\n",
        "    x_val_tokenized_2.append(x_val_tokenized[i])\n",
        "    x_val_normal_2.append(x_val_normal[i])\n",
        "    y_val_2.append(y_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yqUX_iR9A5W"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_2 = []\n",
        "x_test_tokenized_2 = []\n",
        "x_test_normal_2 = []\n",
        "empty_indices_test = []\n",
        "\n",
        "for i in range(len(x_test_tokenized)):\n",
        "  if len(x_test_tokenized[i])==0:\n",
        "    empty_indices_test.append(i)\n",
        "  else:\n",
        "    x_test_tokenized_2.append(x_test_tokenized[i])\n",
        "    x_test_normal_2.append(x_test_normal[i])\n",
        "    y_test_2.append(y_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdSWeXeQ9BB6",
        "outputId": "cb9341e6-abe7-4e23-ab5f-76fe795e15cb"
      },
      "source": [
        "print(empty_indices_train)\n",
        "print(len(empty_indices_train))\n",
        "print(len(x_train_tokenized))\n",
        "print(len(x_train_tokenized_2))\n",
        "print(len(x_train_normal_2))\n",
        "print(len(y_train_2))\n",
        "\n",
        "print(empty_indices_val)\n",
        "print(len(empty_indices_val))\n",
        "print(len(x_val_tokenized))\n",
        "print(len(x_val_tokenized_2))\n",
        "print(len(x_val_normal_2))\n",
        "print(len(y_val_2))\n",
        "\n",
        "print(empty_indices_test)\n",
        "print(len(empty_indices_test))\n",
        "print(len(x_test_tokenized))\n",
        "print(len(x_test_tokenized_2))\n",
        "print(len(x_test_normal_2))\n",
        "print(len(y_test_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "15540\n",
            "15540\n",
            "15540\n",
            "15540\n",
            "[]\n",
            "0\n",
            "2199\n",
            "2199\n",
            "2199\n",
            "2199\n",
            "[]\n",
            "0\n",
            "4438\n",
            "4438\n",
            "4438\n",
            "4438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhFYPLWu8HNA"
      },
      "source": [
        "### Save tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyp_54CI9BF-"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_data.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_tokenized, x_train_normal, x_val_tokenized, x_val_normal, x_test_tokenized, x_test_normal, empty_indices_train, x_train_tokenized_2, \\\n",
        "                 x_train_normal_2, empty_indices_val, x_val_tokenized_2, x_val_normal_2, y_train, y_val, y_train_2, y_val_2, y_test, y_test_2,\\\n",
        "                 empty_indices_test, x_test_normal_2, x_test_tokenized_2 ], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lIVgsadxKLA"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_data.pkl', 'rb') as f:  \n",
        "    x_train_tokenized, x_train_normal, x_val_tokenized, x_val_normal, x_test_tokenized, x_test_normal, empty_indices_train, x_train_tokenized_2, \\\n",
        "                 x_train_normal_2, empty_indices_val, x_val_tokenized_2, x_val_normal_2, y_train, y_val, y_train_2, y_val_2, y_test, y_test_2,\\\n",
        "                 empty_indices_test, x_test_normal_2, x_test_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38nUJAfi9NXB"
      },
      "source": [
        "# def create_df(xdata, emojidata, ydata):\n",
        "#   temp=[\" \".join(i) for i in xdata]\n",
        "#   df_new = pd.DataFrame(temp)\n",
        "#   df_new[\"Emoji\"] = emojidata\n",
        "#   df_new[\"Target\"] = ydata\n",
        "\n",
        "#   df_new.columns = [\"Tweet\", \"Emoji\", \"Target\"]\n",
        "#   return df_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIS_kfnY9NbN"
      },
      "source": [
        "# df_new_val = create_df(x_val_tokenized_2,  y_val_2)\n",
        "# df_new_train = create_df(x_train_tokenized_2, y_train_2)\n",
        "# df_new_test = create_df(x_test_tokenized_2, df_test['emoji_sentence'], y_test_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj3WZZ_I4uK7"
      },
      "source": [
        "# df_new_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1JhRi9i1iF",
        "outputId": "27a45dff-24db-4c07-ba2e-e512484b7e84"
      },
      "source": [
        "df_test['tokenized_tweets'] = x_test_tokenized\n",
        "df_test['tokenized_len'] = df_test['tokenized_tweets'].apply(lambda x: len(x))\n",
        "print(df_test['tokenized_len'].mean())\n",
        "print(df_test['tokenized_len'].median())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.242000901306895\n",
            "10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Gvk_ol9UY5"
      },
      "source": [
        "# # Saving the objects:\n",
        "# with open('/content/drive/MyDrive/2021_NLU/data/full_data/df_new.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "#     pickle.dump([df_new_val, df_new_train, df_new_test], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKDpl79C9UcJ"
      },
      "source": [
        "# with open('/content/drive/MyDrive/2020 NLP/Project/df_new.pkl', 'rb') as f:  \n",
        "#     df_new_val, df_new_train, df_new_test = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtuXsHxF8hgO"
      },
      "source": [
        "### Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQmEFUlC9gU5"
      },
      "source": [
        "def convert_word2vec(model, corpus, strategy):\n",
        "  # return [[model[token] for token in sentence] for sentence in corpus]\n",
        "  output = []\n",
        "  for sentence in corpus:\n",
        "    vector_ = np.zeros(model.vector_size)\n",
        "    for token in sentence:\n",
        "      try:\n",
        "        token_vector = model[token]\n",
        "        vector_ = vector_ + token_vector\n",
        "      except:\n",
        "        vector_ = vector_ + np.zeros(model.vector_size)\n",
        "    if strategy=='mean':\n",
        "      vector_ = vector_/len(sentence)\n",
        "    elif strategy=='add':\n",
        "      pass\n",
        "    output.append(vector_)\n",
        "  # output is a list\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIHpx-MO9gZs"
      },
      "source": [
        "X_train_w2vec = convert_word2vec(word2vec, x_train_tokenized_2, strategy='mean')\n",
        "X_val_w2vec = convert_word2vec(word2vec, x_val_tokenized_2, strategy='mean')\n",
        "X_test_w2vec = convert_word2vec(word2vec, x_test_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNA44FrAzOER"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_train['emoji_sentence_list'] = df_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_train = df_train['emoji_sentence_list'].values\n",
        "\n",
        "df_val['emoji_sentence_list'] = df_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_val = df_val['emoji_sentence_list'].values\n",
        "\n",
        "df_test['emoji_sentence_list'] = df_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_test = df_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0wjcIlwDJMw"
      },
      "source": [
        "def convert_emoji2vec(model, corpus, strategy):\n",
        "  # return [[model[token] for token in sentence] for sentence in corpus]\n",
        "  output = []\n",
        "  for emojis in corpus:\n",
        "    vector_ = np.zeros(model.vector_size)\n",
        "    for emoji in emojis:\n",
        "      try:\n",
        "        token_vector = model[emoji]\n",
        "        vector_ = vector_ + token_vector\n",
        "      except:\n",
        "        vector_ = vector_ + np.zeros(model.vector_size)\n",
        "    if strategy=='mean':\n",
        "      vector_ = vector_/len(emojis)\n",
        "    elif strategy=='add':\n",
        "      pass\n",
        "    output.append(vector_)\n",
        "  # output is a list\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqWMsSTD9gnq"
      },
      "source": [
        "X_train_e2vec = convert_emoji2vec(e2v, emoji_corpus_train, strategy='mean')\n",
        "X_val_e2vec = convert_emoji2vec(e2v, emoji_corpus_val, strategy='mean')\n",
        "X_test_e2vec = convert_emoji2vec(e2v, emoji_corpus_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5xk3GbOACeb",
        "outputId": "376d85ea-ba16-4a6a-8f8c-1806176ef82e"
      },
      "source": [
        "print(len(X_train_w2vec))\n",
        "print(len(X_train_w2vec[4]))\n",
        "\n",
        "print(len(X_val_w2vec))\n",
        "print(len(X_val_w2vec[4]))\n",
        "\n",
        "print(len(X_test_w2vec))\n",
        "print(len(X_test_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "300\n",
            "2199\n",
            "300\n",
            "4438\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33EYEGrA_cti",
        "outputId": "77ed942c-3e85-4b56-c15d-73675b3ff88e"
      },
      "source": [
        "print(len(X_train_e2vec))\n",
        "print(len(X_train_e2vec[4]))\n",
        "\n",
        "print(len(X_val_e2vec))\n",
        "print(len(X_val_e2vec[4]))\n",
        "\n",
        "print(len(X_test_e2vec))\n",
        "print(len(X_test_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "300\n",
            "2199\n",
            "300\n",
            "4438\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmQCEf5Ig3ZB"
      },
      "source": [
        "#### Averaged Vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kRpTqbjAYxB"
      },
      "source": [
        "X_train_vec = (np.array(X_train_w2vec) + np.array(X_train_e2vec))/2\n",
        "X_val_vec = (np.array(X_val_w2vec) + np.array(X_val_e2vec))/2\n",
        "X_test_vec = (np.array(X_test_w2vec) + np.array(X_test_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXcy1curADf_",
        "outputId": "ce0614c7-9069-434c-959a-4d685572458c"
      },
      "source": [
        "X_train_w2vec[0][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04621582, -0.00656535,  0.04308268,  0.0743042 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf71tBhPA4Fw",
        "outputId": "a55e5076-ad81-48c6-82e3-b38c2c0cde06"
      },
      "source": [
        "X_train_e2vec[0][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03221022,  0.03802984, -0.00126745,  0.07279918])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhW5xZdmA4KQ",
        "outputId": "e1aa2d0f-0a59-4719-939b-0d5a294ca9ea"
      },
      "source": [
        "X_train_vec[0][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03921302, 0.01573225, 0.02090762, 0.07355169])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKrkAztPBO-t",
        "outputId": "6db4cacb-fa27-4fde-c832-ae0281058eda"
      },
      "source": [
        "len(X_train_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODMNoNOhEZt"
      },
      "source": [
        "#### Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1WbET1chHtn"
      },
      "source": [
        "X_train_vec_concat = np.concatenate((X_train_w2vec, X_train_e2vec), axis=1) \n",
        "X_val_vec_concat  = np.concatenate((X_val_w2vec, X_val_e2vec), axis=1) \n",
        "X_test_vec_concat  = np.concatenate((X_test_w2vec, X_test_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TurUa1-xaHlA",
        "outputId": "3523c11d-8231-4394-9390-2d7713c252a3"
      },
      "source": [
        "print(len(X_train_w2vec))\n",
        "print(len(X_train_e2vec))\n",
        "print(len(X_train_vec_concat))\n",
        "print(len(X_train_w2vec[4]))\n",
        "print(len(X_train_vec_concat[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15540\n",
            "15540\n",
            "15540\n",
            "300\n",
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He-E1rm5Z6v6",
        "outputId": "9a8690ed-c7fc-49b0-e0a7-4ef12f135584"
      },
      "source": [
        "len(X_train_vec_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbr_jNujjRUQ",
        "outputId": "8c2143be-cbb7-440f-ad54-0ea0b764c64e"
      },
      "source": [
        "X_train_vec_concat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15540, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftrgTt0h8Z7R"
      },
      "source": [
        "### Save Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j16u5CJuzldt"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_vec, X_val_vec, X_test_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwUDi7-OzlhL"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec.pkl', 'rb') as f:  \n",
        "    X_train_vec, X_val_vec, X_test_vec = pickle.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlaP0o8huEP"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec_concat.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_vec_concat, X_val_vec_concat, X_test_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpYchOBhhuIX"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/full_data/full_vec.pkl', 'rb') as f:  \n",
        "    X_train_vec_concat, X_val_vec_concat, X_test_vec_concat = pickle.load(f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SehXB2kF0ljA"
      },
      "source": [
        "## (ONLY) SINGLE EMOJI - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBfMT8ND0ob2"
      },
      "source": [
        "df_sing_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/single_emoji/emoji_nsp_dataset_single_emoji_train.csv')\n",
        "df_sing_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/single_emoji/emoji_nsp_dataset_single_emoji_valid.csv')\n",
        "df_sing_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/single_emoji/emoji_nsp_dataset_single_emoji_test.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "b4vjIbWT0ofB",
        "outputId": "99e42f27-7cd2-46ff-d43d-25d0d7d95653"
      },
      "source": [
        "df_sing_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67113</td>\n",
              "      <td>Craving Black Cake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35900</td>\n",
              "      <td>y’all i was kidding, pls don’t attack me</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1045</td>\n",
              "      <td>omg bye so true</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11764</td>\n",
              "      <td>Nooo I’m at the end of the og Futurama eps</td>\n",
              "      <td>😢</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1642</td>\n",
              "      <td>[USER] [USER] [USER] [USER] Not worth wasting ...</td>\n",
              "      <td>😍</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  67113  ...        0\n",
              "1  35900  ...        1\n",
              "2   1045  ...        1\n",
              "3  11764  ...        1\n",
              "4   1642  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4I6fFWe0oj6",
        "outputId": "8f5480ae-21c3-409a-ec33-a64d5b563cdf"
      },
      "source": [
        "print(len(df_sing_train))\n",
        "print(len(df_sing_val))\n",
        "print(len(df_sing_test))\n",
        "\n",
        "df_sing_train = df_sing_train.dropna().drop_duplicates()\n",
        "df_sing_val = df_sing_val.dropna().drop_duplicates()\n",
        "df_sing_test = df_sing_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_sing_train))\n",
        "print(len(df_sing_val))\n",
        "print(len(df_sing_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15015\n",
            "2153\n",
            "4341\n",
            "15015\n",
            "2153\n",
            "4341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGCW8hdc0omx",
        "outputId": "25aea3cd-7cb8-4608-da32-978f40d28a3b"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_sing_tokenized, x_train_sing_normal = clean_text(df_sing_train['tweets'].values)\n",
        "x_val_sing_tokenized, x_val_sing_normal = clean_text(df_sing_val['tweets'].values)\n",
        "x_test_sing_tokenized, x_test_sing_normal = clean_text(df_sing_test['tweets'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.011325836181640625\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.07462406158447266\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.020409584045410156\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  1.7219054698944092\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0008127689361572266\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.009940624237060547\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.0026712417602539062\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.24480819702148438\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0017445087432861328\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.023852109909057617\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.006357908248901367\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.4971282482147217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVdQHYmk0orG"
      },
      "source": [
        "y_sing_train = df_sing_train['follows?'].values\n",
        "y_sing_val = df_sing_val['follows?'].values\n",
        "y_sing_test = df_sing_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_tTjjSL3nGe"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_sing_2 = []\n",
        "x_train_sing_tokenized_2 = []\n",
        "x_train_sing_normal_2 = []\n",
        "empty_indices_sing_train = []\n",
        "\n",
        "for i in range(len(x_train_sing_tokenized)):\n",
        "  if len(x_train_sing_tokenized[i])==0:\n",
        "    empty_indices_sing_train.append(i)\n",
        "  else:\n",
        "    x_train_sing_tokenized_2.append(x_train_sing_tokenized[i])\n",
        "    x_train_sing_normal_2.append(x_train_sing_normal[i])\n",
        "    y_train_sing_2.append(y_sing_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blwEBMvm4Cry"
      },
      "source": [
        "#remove empty values for val\n",
        "y_val_sing_2 = []\n",
        "x_val_sing_tokenized_2 = []\n",
        "x_val_sing_normal_2 = []\n",
        "empty_indices_sing_val = []\n",
        "\n",
        "for i in range(len(x_val_sing_tokenized)):\n",
        "  if len(x_val_sing_tokenized[i])==0:\n",
        "    empty_indices_sing_val.append(i)\n",
        "  else:\n",
        "    x_val_sing_tokenized_2.append(x_val_sing_tokenized[i])\n",
        "    x_val_sing_normal_2.append(x_val_sing_normal[i])\n",
        "    y_val_sing_2.append(y_sing_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etNPNC7G4Cu6"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_sing_2 = []\n",
        "x_test_sing_tokenized_2 = []\n",
        "x_test_sing_normal_2 = []\n",
        "empty_indices_sing_test = []\n",
        "\n",
        "for i in range(len(x_test_sing_tokenized)):\n",
        "  if len(x_test_sing_tokenized[i])==0:\n",
        "    empty_indices_sing_test.append(i)\n",
        "  else:\n",
        "    x_test_sing_tokenized_2.append(x_test_sing_tokenized[i])\n",
        "    x_test_sing_normal_2.append(x_test_sing_normal[i])\n",
        "    y_test_sing_2.append(y_sing_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daxAEWZN3nJ9",
        "outputId": "aa25807f-3e2b-4df1-a560-5ffa4b1f52d8"
      },
      "source": [
        "print(empty_indices_sing_train)\n",
        "print(len(empty_indices_sing_train))\n",
        "print(len(x_train_sing_tokenized))\n",
        "print(len(x_train_sing_tokenized_2))\n",
        "print(len(x_train_sing_normal_2))\n",
        "print(len(y_train_sing_2))\n",
        "\n",
        "print(empty_indices_sing_val)\n",
        "print(len(empty_indices_sing_val))\n",
        "print(len(x_val_sing_tokenized))\n",
        "print(len(x_val_sing_tokenized_2))\n",
        "print(len(x_val_sing_normal_2))\n",
        "print(len(y_val_sing_2))\n",
        "\n",
        "print(empty_indices_sing_test)\n",
        "print(len(empty_indices_sing_test))\n",
        "print(len(x_test_sing_tokenized))\n",
        "print(len(x_test_sing_tokenized_2))\n",
        "print(len(x_test_sing_normal_2))\n",
        "print(len(y_test_sing_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "15015\n",
            "15015\n",
            "15015\n",
            "15015\n",
            "[]\n",
            "0\n",
            "2153\n",
            "2153\n",
            "2153\n",
            "2153\n",
            "[]\n",
            "0\n",
            "4341\n",
            "4341\n",
            "4341\n",
            "4341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZZMjTd3nNi"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_sing_tokenized, x_train_sing_normal, x_val_sing_tokenized, x_val_sing_normal, x_test_sing_tokenized, x_test_sing_normal, empty_indices_sing_train, x_train_sing_tokenized_2, \\\n",
        "                 x_train_sing_normal_2, empty_indices_sing_val, x_val_sing_tokenized_2, x_val_sing_normal_2, y_sing_train, y_sing_val, y_train_sing_2, y_val_sing_2, y_sing_test, y_test_sing_2,\\\n",
        "                 empty_indices_sing_test, x_test_sing_normal_2, x_test_sing_tokenized_2 ], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfu3aE2T7H41"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji.pkl', 'rb') as f:  \n",
        "    x_train_sing_tokenized, x_train_sing_normal, x_val_sing_tokenized, x_val_sing_normal, x_test_sing_tokenized, x_test_sing_normal, empty_indices_sing_train, x_train_sing_tokenized_2, \\\n",
        "                 x_train_sing_normal_2, empty_indices_sing_val, x_val_sing_tokenized_2, x_val_sing_normal_2, y_sing_train, y_sing_val, y_train_sing_2, y_val_sing_2, y_sing_test, y_test_sing_2,\\\n",
        "                 empty_indices_sing_test, x_test_sing_normal_2, x_test_sing_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbZ32AnX9sXR",
        "outputId": "c6dc079a-29f8-4109-c764-9bd2bcfc8f7b"
      },
      "source": [
        "len(x_train_sing_tokenized_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCKzMv5F66aY"
      },
      "source": [
        "X_train_sing_w2vec = convert_word2vec(word2vec, x_train_sing_tokenized_2, strategy='mean')\n",
        "X_val_sing_w2vec = convert_word2vec(word2vec, x_val_sing_tokenized_2, strategy='mean')\n",
        "X_test_sing_w2vec = convert_word2vec(word2vec, x_test_sing_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-eC3wmv66fX"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_sing_train['emoji_sentence_list'] = df_sing_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_sing_train = df_sing_train['emoji_sentence_list'].values\n",
        "\n",
        "df_sing_val['emoji_sentence_list'] = df_sing_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_sing_val = df_sing_val['emoji_sentence_list'].values\n",
        "\n",
        "df_sing_test['emoji_sentence_list'] = df_sing_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_sing_test = df_sing_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkZOFmbZ66j9"
      },
      "source": [
        "X_train_sing_e2vec = convert_emoji2vec(e2v, emoji_corpus_sing_train, strategy='mean')\n",
        "X_val_sing_e2vec = convert_emoji2vec(e2v, emoji_corpus_sing_val, strategy='mean')\n",
        "X_test_sing_e2vec = convert_emoji2vec(e2v, emoji_corpus_sing_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5B_8QeZ8S91",
        "outputId": "7314a22e-1956-44a8-e62b-565896987b8e"
      },
      "source": [
        "print(len(X_train_sing_w2vec))\n",
        "print(len(X_train_sing_w2vec[4]))\n",
        "\n",
        "print(len(X_val_sing_w2vec))\n",
        "print(len(X_val_sing_w2vec[4]))\n",
        "\n",
        "print(len(X_test_sing_w2vec))\n",
        "print(len(X_test_sing_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15015\n",
            "300\n",
            "2153\n",
            "300\n",
            "4341\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al3zV9Qe8TB0",
        "outputId": "72143b7c-18b1-49a4-c53f-229be21309ba"
      },
      "source": [
        "print(len(X_train_sing_e2vec))\n",
        "print(len(X_train_sing_e2vec[4]))\n",
        "\n",
        "print(len(X_val_sing_e2vec))\n",
        "print(len(X_val_sing_e2vec[4]))\n",
        "\n",
        "print(len(X_test_sing_e2vec))\n",
        "print(len(X_test_sing_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15015\n",
            "300\n",
            "2153\n",
            "300\n",
            "4341\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB8nhFLGbj7p"
      },
      "source": [
        "#### Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krigRs6z87So"
      },
      "source": [
        "X_train_sing_vec = (np.array(X_train_sing_w2vec) + np.array(X_train_sing_e2vec))/2\n",
        "X_val_sing_vec = (np.array(X_val_sing_w2vec) + np.array(X_val_sing_e2vec))/2\n",
        "X_test_sing_vec = (np.array(X_test_sing_w2vec) + np.array(X_test_sing_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi-L4mHI87XZ"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_sing_vec, X_val_sing_vec, X_test_sing_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd7GQKsE87e4"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec.pkl', 'rb') as f:  \n",
        "    X_train_sing_vec, X_val_sing_vec, X_test_sing_vec = pickle.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WwMp9oobnc3"
      },
      "source": [
        "#### Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcKY4UsN0ous"
      },
      "source": [
        "X_train_sing_vec_concat = np.concatenate((X_train_sing_w2vec, X_train_sing_e2vec), axis=1) \n",
        "X_val_sing_vec_concat  = np.concatenate((X_val_sing_w2vec, X_val_sing_e2vec), axis=1) \n",
        "X_test_sing_vec_concat  = np.concatenate((X_test_sing_w2vec, X_test_sing_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJ02Ci4brbq"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec_concat.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_sing_vec_concat, X_val_sing_vec_concat, X_test_sing_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lkXVR32brgd"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/single_emoji/single_emoji_vec_concat.pkl', 'rb') as f:  \n",
        "    X_train_sing_vec_concat, X_val_sing_vec_concat, X_test_sing_vec_concat = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWED9-T91BBc"
      },
      "source": [
        "## (ONLY) MULTI EMOJIS WITH REPEATS - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dClnKTpX1HD4"
      },
      "source": [
        "df_mul_repeat_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/multi_emoji/emoji_nsp_dataset_multi_emoji_train.csv')\n",
        "df_mul_repeat_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/multi_emoji/emoji_nsp_dataset_multi_emoji_valid.csv')\n",
        "df_mul_repeat_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/multi_emoji/emoji_nsp_dataset_multi_emoji_test.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TIGjSwgy1HGz",
        "outputId": "b2c18d57-03d0-42d5-d159-c2eabbdeab65"
      },
      "source": [
        "df_mul_repeat_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6704</td>\n",
              "      <td>good morning [USER] you woke up so early  anyw...</td>\n",
              "      <td>😶😊💚</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10651</td>\n",
              "      <td>MVP  4x Scoring champ  3x All NBA FIRST TEAM 3...</td>\n",
              "      <td>✅✅✅✅</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6345</td>\n",
              "      <td>[USER] Your tears baby boy ...Sleep sad</td>\n",
              "      <td>🌚🌚👌</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5268</td>\n",
              "      <td>15 php ---&amp;gt; Follow [USER] ---&amp;gt; RT &amp;amp; ...</td>\n",
              "      <td>💗📌</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5897</td>\n",
              "      <td>this emoji looks like sia</td>\n",
              "      <td>😭🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙🍙</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0   6704  ...        1\n",
              "1  10651  ...        1\n",
              "2   6345  ...        1\n",
              "3   5268  ...        1\n",
              "4   5897  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHdzG_ny1HJR",
        "outputId": "16759c9e-0096-4f7a-d565-dc66625f22f6"
      },
      "source": [
        "print(len(df_mul_repeat_train))\n",
        "print(len(df_mul_repeat_val))\n",
        "print(len(df_mul_repeat_test))\n",
        "\n",
        "df_mul_repeat_train = df_mul_repeat_train.dropna().drop_duplicates()\n",
        "df_mul_repeat_val = df_mul_repeat_val.dropna().drop_duplicates()\n",
        "df_mul_repeat_test = df_mul_repeat_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_mul_repeat_train))\n",
        "print(len(df_mul_repeat_val))\n",
        "print(len(df_mul_repeat_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16801\n",
            "2401\n",
            "4800\n",
            "16801\n",
            "2401\n",
            "4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9fJOj3M1HMr",
        "outputId": "e4d98d84-a632-48af-dcad-585128ae134f"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_mul_repeat_tokenized, x_train_mul_repeat_normal = clean_text(df_mul_repeat_train['tweets'].values)\n",
        "x_val_mul_repeat_tokenized, x_val_mul_repeat_normal = clean_text(df_mul_repeat_val['tweets'].values)\n",
        "x_test_mul_repeat_tokenized, x_test_mul_repeat_normal = clean_text(df_mul_repeat_test['tweets'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.010810375213623047\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.1181480884552002\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.03280997276306152\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  2.2395598888397217\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0016427040100097656\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.01767277717590332\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.004660844802856445\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.321491003036499\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0034494400024414062\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.03859567642211914\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.009351968765258789\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.6670784950256348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHe_Lu8A3DdZ"
      },
      "source": [
        "y_mul_repeat_train = df_mul_repeat_train['follows?'].values\n",
        "y_mul_repeat_val = df_mul_repeat_val['follows?'].values\n",
        "y_mul_repeat_test = df_mul_repeat_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmM9dPN4EYgm",
        "outputId": "c8c34004-ef23-4943-d1ce-0ea5d3553c43"
      },
      "source": [
        "df_mul_repeat_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4789, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KqsKFZqxEfSO",
        "outputId": "77ac71cf-5b3f-4d11-8a63-884c7268c9c0"
      },
      "source": [
        "df_mul_repeat_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20092</td>\n",
              "      <td>[USER] CONGRATS! This is...SO CUTE...//clenche...</td>\n",
              "      <td>💎🙌🚀</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12536</td>\n",
              "      <td>Hair Appt Booked  Just Need To Go Shopping For...</td>\n",
              "      <td>✊🏽</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394</td>\n",
              "      <td>[USER] Lmao so true 3 for y'all 1 for usHoping...</td>\n",
              "      <td>💙✨</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8301</td>\n",
              "      <td>[USER] Happy happy birthday!!! . Your day soun...</td>\n",
              "      <td>🎉🎉🎉🤯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1226</td>\n",
              "      <td>My coworker hates going to restaurants with me...</td>\n",
              "      <td>🍮💜</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  20092  ...        0\n",
              "1  12536  ...        0\n",
              "2    394  ...        1\n",
              "3   8301  ...        1\n",
              "4   1226  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEkXCvSnEILf",
        "outputId": "26132861-8baf-4ae2-caef-f22e5d908f84"
      },
      "source": [
        "print(len(x_test_mul_repeat_tokenized))\n",
        "print(len(y_mul_repeat_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4789\n",
            "4789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBVTkrz3Dg8"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_mul_repeat_2 = []\n",
        "x_train_mul_repeat_tokenized_2 = []\n",
        "x_train_mul_repeat_normal_2 = []\n",
        "empty_indices_mul_repeat_train = []\n",
        "\n",
        "for i in range(len(x_train_mul_repeat_tokenized)):\n",
        "  if len(x_train_mul_repeat_tokenized[i])==0:\n",
        "    empty_indices_mul_repeat_train.append(i)\n",
        "  else:\n",
        "    x_train_mul_repeat_tokenized_2.append(x_train_mul_repeat_tokenized[i])\n",
        "    x_train_mul_repeat_normal_2.append(x_train_mul_repeat_normal[i])\n",
        "    y_train_mul_repeat_2.append(y_mul_repeat_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAHZ1Bw-3Dkh"
      },
      "source": [
        "#remove empty values for val \n",
        "y_val_mul_repeat_2 = []\n",
        "x_val_mul_repeat_tokenized_2 = []\n",
        "x_val_mul_repeat_normal_2 = []\n",
        "empty_indices_mul_repeat_val = []\n",
        "\n",
        "for i in range(len(x_val_mul_repeat_tokenized)):\n",
        "  if len(x_val_mul_repeat_tokenized[i])==0:\n",
        "    empty_indices_mul_repeat_val.append(i)\n",
        "  else:\n",
        "    x_val_mul_repeat_tokenized_2.append(x_val_mul_repeat_tokenized[i])\n",
        "    x_val_mul_repeat_normal_2.append(x_val_mul_repeat_normal[i])\n",
        "    y_val_mul_repeat_2.append(y_mul_repeat_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJl-PaH5hCl"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_mul_repeat_2 = []\n",
        "x_test_mul_repeat_tokenized_2 = []\n",
        "x_test_mul_repeat_normal_2 = []\n",
        "empty_indices_mul_repeat_test = []\n",
        "\n",
        "for i in range(len(x_test_mul_repeat_tokenized)):\n",
        "  if len(x_test_mul_repeat_tokenized[i])==0:\n",
        "    empty_indices_mul_repeat_test.append(i)\n",
        "  else:\n",
        "    x_test_mul_repeat_tokenized_2.append(x_test_mul_repeat_tokenized[i])\n",
        "    x_test_mul_repeat_normal_2.append(x_test_mul_repeat_normal[i])\n",
        "    y_test_mul_repeat_2.append(y_mul_repeat_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyTLTBi_5hGI",
        "outputId": "c6d10b30-3a82-43b0-e700-105ff8902456"
      },
      "source": [
        "print(empty_indices_mul_repeat_train)\n",
        "print(len(empty_indices_mul_repeat_train))\n",
        "print(len(x_train_mul_repeat_tokenized))\n",
        "print(len(x_train_mul_repeat_tokenized_2))\n",
        "print(len(x_train_mul_repeat_normal_2))\n",
        "print(len(y_train_mul_repeat_2))\n",
        "\n",
        "print(empty_indices_mul_repeat_val)\n",
        "print(len(empty_indices_mul_repeat_val))\n",
        "print(len(x_val_mul_repeat_tokenized))\n",
        "print(len(x_val_mul_repeat_tokenized_2))\n",
        "print(len(x_val_mul_repeat_normal_2))\n",
        "print(len(y_val_mul_repeat_2))\n",
        "\n",
        "print(empty_indices_mul_repeat_test)\n",
        "print(len(empty_indices_mul_repeat_test))\n",
        "print(len(x_test_mul_repeat_tokenized))\n",
        "print(len(x_test_mul_repeat_tokenized_2))\n",
        "print(len(x_test_mul_repeat_normal_2))\n",
        "print(len(y_test_mul_repeat_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "16801\n",
            "16801\n",
            "16801\n",
            "16801\n",
            "[]\n",
            "0\n",
            "2401\n",
            "2401\n",
            "2401\n",
            "2401\n",
            "[]\n",
            "0\n",
            "4800\n",
            "4800\n",
            "4800\n",
            "4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEcWNim65hKD"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_mul_repeat_tokenized, x_train_mul_repeat_normal, x_val_mul_repeat_tokenized, x_val_mul_repeat_normal, x_test_mul_repeat_tokenized, x_test_mul_repeat_normal, empty_indices_mul_repeat_train, x_train_mul_repeat_tokenized_2, \\\n",
        "                 x_train_mul_repeat_normal_2, empty_indices_mul_repeat_val, x_val_mul_repeat_tokenized_2, x_val_mul_repeat_normal_2, y_mul_repeat_train, y_mul_repeat_val, y_train_mul_repeat_2, y_val_mul_repeat_2, y_mul_repeat_test, y_test_mul_repeat_2,\\\n",
        "                 empty_indices_mul_repeat_test, x_test_mul_repeat_normal_2, x_test_mul_repeat_tokenized_2], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHcNhCY8KySi"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis.pkl', 'rb') as f:  \n",
        "    x_train_mul_repeat_tokenized, x_train_mul_repeat_normal, x_val_mul_repeat_tokenized, x_val_mul_repeat_normal, x_test_mul_repeat_tokenized, x_test_mul_repeat_normal, empty_indices_mul_repeat_train, x_train_mul_repeat_tokenized_2, \\\n",
        "                 x_train_mul_repeat_normal_2, empty_indices_mul_repeat_val, x_val_mul_repeat_tokenized_2, x_val_mul_repeat_normal_2, y_mul_repeat_train, y_mul_repeat_val, y_train_mul_repeat_2, y_val_mul_repeat_2, y_mul_repeat_test, y_test_mul_repeat_2,\\\n",
        "                 empty_indices_mul_repeat_test, x_test_mul_repeat_normal_2, x_test_mul_repeat_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMpUokhqKyWf"
      },
      "source": [
        "X_train_mul_repeat_w2vec = convert_word2vec(word2vec, x_train_mul_repeat_tokenized_2, strategy='mean')\n",
        "X_val_mul_repeat_w2vec = convert_word2vec(word2vec, x_val_mul_repeat_tokenized_2, strategy='mean')\n",
        "X_test_mul_repeat_w2vec = convert_word2vec(word2vec, x_test_mul_repeat_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZIfBBfhK7Q8"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_mul_repeat_train['emoji_sentence_list'] = df_mul_repeat_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_repeat_train = df_mul_repeat_train['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_repeat_val['emoji_sentence_list'] = df_mul_repeat_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_repeat_val = df_mul_repeat_val['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_repeat_test['emoji_sentence_list'] = df_mul_repeat_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_repeat_test = df_mul_repeat_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxdaL-YK7U0"
      },
      "source": [
        "X_train_mul_repeat_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_repeat_train, strategy='mean')\n",
        "X_val_mul_repeat_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_repeat_val, strategy='mean')\n",
        "X_test_mul_repeat_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_repeat_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORDwv4g5KybJ",
        "outputId": "a2f2f940-9812-4556-ccaf-76fd5bfe70a5"
      },
      "source": [
        "print(len(X_train_mul_repeat_w2vec))\n",
        "print(len(X_train_mul_repeat_w2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_repeat_w2vec))\n",
        "print(len(X_val_mul_repeat_w2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_repeat_w2vec))\n",
        "print(len(X_test_mul_repeat_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16801\n",
            "300\n",
            "2401\n",
            "300\n",
            "4800\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MRmFUFmLHBR",
        "outputId": "cbd785ca-06f8-4afa-d3aa-f22d64306fad"
      },
      "source": [
        "print(len(X_train_mul_repeat_e2vec))\n",
        "print(len(X_train_mul_repeat_e2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_repeat_e2vec))\n",
        "print(len(X_val_mul_repeat_e2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_repeat_e2vec))\n",
        "print(len(X_test_mul_repeat_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16801\n",
            "300\n",
            "2401\n",
            "300\n",
            "4800\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fumuF82McSFz"
      },
      "source": [
        "#### Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpCaYdLzLHFI"
      },
      "source": [
        "X_train_mul_repeat_vec = (np.array(X_train_mul_repeat_w2vec) + np.array(X_train_mul_repeat_e2vec))/2\n",
        "X_val_mul_repeat_vec = (np.array(X_val_mul_repeat_w2vec) + np.array(X_val_mul_repeat_e2vec))/2\n",
        "X_test_mul_repeat_vec = (np.array(X_test_mul_repeat_w2vec) + np.array(X_test_mul_repeat_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQp-nCDELNGw"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_repeat_vec, X_val_mul_repeat_vec, X_test_mul_repeat_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXwiN2kLNKC"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_repeat_vec, X_val_mul_repeat_vec, X_test_mul_repeat_vec = pickle.load(f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty0XEM88cVDv"
      },
      "source": [
        "#### Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMnVCthj3Dn2"
      },
      "source": [
        "X_train_mul_repeat_vec_concat = np.concatenate((X_train_mul_repeat_w2vec, X_train_mul_repeat_e2vec), axis=1) \n",
        "X_val_mul_repeat_vec_concat  = np.concatenate((X_val_mul_repeat_w2vec, X_val_mul_repeat_e2vec), axis=1) \n",
        "X_test_mul_repeat_vec_concat  = np.concatenate((X_test_mul_repeat_w2vec, X_test_mul_repeat_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdRVmNWOcXbq"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_repeat_vec_concat, X_val_mul_repeat_vec_concat, X_test_mul_repeat_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEQ6Ht02cXgh"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/multi_emoji/mul_repeat_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_repeat_vec_concat, X_val_mul_repeat_vec_concat, X_test_mul_repeat_vec_concat = pickle.load(f)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ons1B4P1EqR"
      },
      "source": [
        "## FULL DATA (SINGLE AND MULTI) WITH NO REPEATS - Download, Preprocess, Create Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A7rZZzF1KPy"
      },
      "source": [
        "df_mul_train = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/no_repeats/emoji_nsp_dataset_no_repeats_train.csv')\n",
        "df_mul_val = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/no_repeats/emoji_nsp_dataset_no_repeats_valid.csv')\n",
        "df_mul_test = pd.read_csv('/content/drive/MyDrive/2021_NLU/data/no_repeats/emoji_nsp_dataset_no_repeats_test.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dGECt3HO1Kfk",
        "outputId": "8e8aada5-9edf-46fb-dce3-26e0d13808e6"
      },
      "source": [
        "df_mul_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50553</td>\n",
              "      <td>The dababy memes make no sense and that’s why ...</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>74541</td>\n",
              "      <td>a year ago today i would be holding my breath ...</td>\n",
              "      <td>🙏</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50992</td>\n",
              "      <td>I told my mama about how the music industry is...</td>\n",
              "      <td>💯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95343</td>\n",
              "      <td>[USER] [USER] Thankyou guys</td>\n",
              "      <td>💀</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60555</td>\n",
              "      <td>You want new SUBS? Like ️ Retweet Follow me  R...</td>\n",
              "      <td>😬</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... follows?\n",
              "0  50553  ...        1\n",
              "1  74541  ...        0\n",
              "2  50992  ...        1\n",
              "3  95343  ...        0\n",
              "4  60555  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjgLJHO_1Ki2",
        "outputId": "047e9b24-5bb5-49d2-9299-883a7f2ce991"
      },
      "source": [
        "print(len(df_mul_train))\n",
        "print(len(df_mul_val))\n",
        "print(len(df_mul_test))\n",
        "\n",
        "df_mul_train = df_mul_train.dropna().drop_duplicates()\n",
        "df_mul_val = df_mul_val.dropna().drop_duplicates()\n",
        "df_mul_test = df_mul_test.dropna().drop_duplicates()\n",
        "\n",
        "print(len(df_mul_train))\n",
        "print(len(df_mul_val))\n",
        "print(len(df_mul_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15475\n",
            "2229\n",
            "4433\n",
            "15475\n",
            "2229\n",
            "4433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATl6Dp2B1Klb",
        "outputId": "4940db8a-9566-419a-bb10-478f10a07cb1"
      },
      "source": [
        "# sample_tokenized, sample_normal = clean_text(sample)\n",
        "x_train_mul_tokenized, x_train_mul_normal = clean_text(df_mul_train['tweets'].values)\n",
        "x_val_mul_tokenized, x_val_mul_normal = clean_text(df_mul_val['tweets'].values)\n",
        "x_test_mul_tokenized, x_test_mul_normal = clean_text(df_mul_test['tweets'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.014504194259643555\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.08419013023376465\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.024480104446411133\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  1.8592925071716309\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.000911712646484375\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.012573957443237305\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.0032439231872558594\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.26091432571411133\n",
            "\n",
            "       ##### Lowercasing Done! Time Taken -  0.0018279552459716797\n",
            "\n",
            "       ##### Punctuation removed! Time Taken -  0.024820804595947266\n",
            "\n",
            "       ##### Whitespace removed! Time Taken -  0.008264541625976562\n",
            "\n",
            "       ##### Tokenization Done using NLTK! Time Taken -  0.5202980041503906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOxMVEsl3FNe"
      },
      "source": [
        "y_mul_train = df_mul_train['follows?'].values\n",
        "y_mul_val = df_mul_val['follows?'].values\n",
        "y_mul_test = df_mul_test['follows?'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW89ftqe3FQ9"
      },
      "source": [
        "#remove empty values for train\n",
        "y_train_mul_2 = []\n",
        "x_train_mul_tokenized_2 = []\n",
        "x_train_mul_normal_2 = []\n",
        "empty_indices_mul_train = []\n",
        "\n",
        "for i in range(len(x_train_mul_tokenized)):\n",
        "  if len(x_train_mul_tokenized[i])==0:\n",
        "    empty_indices_mul_train.append(i)\n",
        "  else:\n",
        "    x_train_mul_tokenized_2.append(x_train_mul_tokenized[i])\n",
        "    x_train_mul_normal_2.append(x_train_mul_normal[i])\n",
        "    y_train_mul_2.append(y_mul_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYJYi5V_3FT3"
      },
      "source": [
        "#remove empty values for val\n",
        "y_val_mul_2 = []\n",
        "x_val_mul_tokenized_2 = []\n",
        "x_val_mul_normal_2 = []\n",
        "empty_indices_mul_val = []\n",
        "\n",
        "for i in range(len(x_val_mul_tokenized)):\n",
        "  if len(x_val_mul_tokenized[i])==0:\n",
        "    empty_indices_mul_val.append(i)\n",
        "  else:\n",
        "    x_val_mul_tokenized_2.append(x_val_mul_tokenized[i])\n",
        "    x_val_mul_normal_2.append(x_val_mul_normal[i])\n",
        "    y_val_mul_2.append(y_mul_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IhXAiW5i4E"
      },
      "source": [
        "#remove empty values for test\n",
        "y_test_mul_2 = []\n",
        "x_test_mul_tokenized_2 = []\n",
        "x_test_mul_normal_2 = []\n",
        "empty_indices_mul_test = []\n",
        "\n",
        "for i in range(len(x_test_mul_tokenized)):\n",
        "  if len(x_test_mul_tokenized[i])==0:\n",
        "    empty_indices_mul_test.append(i)\n",
        "  else:\n",
        "    x_test_mul_tokenized_2.append(x_test_mul_tokenized[i])\n",
        "    x_test_mul_normal_2.append(x_test_mul_normal[i])\n",
        "    y_test_mul_2.append(y_mul_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVO6tw575i7p",
        "outputId": "ae78add1-50bb-41ff-a027-83ba22c17582"
      },
      "source": [
        "print(empty_indices_mul_train)\n",
        "print(len(empty_indices_mul_train))\n",
        "print(len(x_train_mul_tokenized))\n",
        "print(len(x_train_mul_tokenized_2))\n",
        "print(len(x_train_mul_normal_2))\n",
        "print(len(y_train_mul_2))\n",
        "\n",
        "print(empty_indices_mul_val)\n",
        "print(len(empty_indices_mul_val))\n",
        "print(len(x_val_mul_tokenized))\n",
        "print(len(x_val_mul_tokenized_2))\n",
        "print(len(x_val_mul_normal_2))\n",
        "print(len(y_val_mul_2))\n",
        "\n",
        "print(empty_indices_mul_test)\n",
        "print(len(empty_indices_mul_test))\n",
        "print(len(x_test_mul_tokenized))\n",
        "print(len(x_test_mul_tokenized_2))\n",
        "print(len(x_test_mul_normal_2))\n",
        "print(len(y_test_mul_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "15475\n",
            "15475\n",
            "15475\n",
            "15475\n",
            "[]\n",
            "0\n",
            "2229\n",
            "2229\n",
            "2229\n",
            "2229\n",
            "[]\n",
            "0\n",
            "4433\n",
            "4433\n",
            "4433\n",
            "4433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GZ2k7npO5Bx"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([x_train_mul_tokenized, x_train_mul_normal, x_val_mul_tokenized, x_val_mul_normal, x_test_mul_tokenized, x_test_mul_normal, empty_indices_mul_train, x_train_mul_tokenized_2, \\\n",
        "                 x_train_mul_normal_2, empty_indices_mul_val, x_val_mul_tokenized_2, x_val_mul_normal_2, y_mul_train, y_mul_val, y_train_mul_2, y_val_mul_2, y_mul_test, y_test_mul_2,\\\n",
        "                 empty_indices_mul_test, x_test_mul_normal_2, x_test_mul_tokenized_2], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlP3XYPDO5GG"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis.pkl', 'rb') as f:  \n",
        "    x_train_mul_tokenized, x_train_mul_normal, x_val_mul_tokenized, x_val_mul_normal, x_test_mul_tokenized, x_test_mul_normal, empty_indices_mul_train, x_train_mul_tokenized_2, \\\n",
        "                 x_train_mul_normal_2, empty_indices_mul_val, x_val_mul_tokenized_2, x_val_mul_normal_2, y_mul_train, y_mul_val, y_train_mul_2, y_val_mul_2, y_mul_test, y_test_mul_2,\\\n",
        "                 empty_indices_mul_test, x_test_mul_normal_2, x_test_mul_tokenized_2 = pickle.load(f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeUzJvzjO5KN"
      },
      "source": [
        "X_train_mul_w2vec = convert_word2vec(word2vec, x_train_mul_tokenized_2, strategy='mean')\n",
        "X_val_mul_w2vec = convert_word2vec(word2vec, x_val_mul_tokenized_2, strategy='mean')\n",
        "X_test_mul_w2vec = convert_word2vec(word2vec, x_test_mul_tokenized_2, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTeLkMWZO5RB"
      },
      "source": [
        "# list(df_train['emoji_sentence'][2])\n",
        "df_mul_train['emoji_sentence_list'] = df_mul_train['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_train = df_mul_train['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_val['emoji_sentence_list'] = df_mul_val['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_val = df_mul_val['emoji_sentence_list'].values\n",
        "\n",
        "df_mul_test['emoji_sentence_list'] = df_mul_test['emoji_sentence'].apply(lambda x: list(x))\n",
        "emoji_corpus_mul_test = df_mul_test['emoji_sentence_list'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaH825a4O5Ve"
      },
      "source": [
        "X_train_mul_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_train, strategy='mean')\n",
        "X_val_mul_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_val, strategy='mean')\n",
        "X_test_mul_e2vec = convert_emoji2vec(e2v, emoji_corpus_mul_test, strategy='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-bLILP5jBg",
        "outputId": "bc8d7b10-16be-4ca0-fef4-b80c853ff22a"
      },
      "source": [
        "print(len(X_train_mul_w2vec))\n",
        "print(len(X_train_mul_w2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_w2vec))\n",
        "print(len(X_val_mul_w2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_w2vec))\n",
        "print(len(X_test_mul_w2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15475\n",
            "300\n",
            "2229\n",
            "300\n",
            "4433\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9hS1zRIPK6D",
        "outputId": "b84245bf-c6ea-4ab9-fde4-977d0949779d"
      },
      "source": [
        "print(len(X_train_mul_e2vec))\n",
        "print(len(X_train_mul_e2vec[4]))\n",
        "\n",
        "print(len(X_val_mul_e2vec))\n",
        "print(len(X_val_mul_e2vec[4]))\n",
        "\n",
        "print(len(X_test_mul_e2vec))\n",
        "print(len(X_test_mul_e2vec[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15475\n",
            "300\n",
            "2229\n",
            "300\n",
            "4433\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pe5JYUocxfh"
      },
      "source": [
        "#### Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVRlEsh5PK-e"
      },
      "source": [
        "X_train_mul_vec = (np.array(X_train_mul_w2vec) + np.array(X_train_mul_e2vec))/2\n",
        "X_val_mul_vec = (np.array(X_val_mul_w2vec) + np.array(X_val_mul_e2vec))/2\n",
        "X_test_mul_vec = (np.array(X_test_mul_w2vec) + np.array(X_test_mul_e2vec))/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf9jZyZEPRMD"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_vec, X_val_mul_vec, X_test_mul_vec], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unYdKmdvPRQ9"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_vec, X_val_mul_vec, X_test_mul_vec = pickle.load(f)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgqpUpnFc1ET"
      },
      "source": [
        "#### Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qHS0wqA1Koi"
      },
      "source": [
        "X_train_mul_vec_concat = np.concatenate((X_train_mul_w2vec, X_train_mul_e2vec), axis=1) \n",
        "X_val_mul_vec_concat  = np.concatenate((X_val_mul_w2vec, X_val_mul_e2vec), axis=1) \n",
        "X_test_mul_vec_concat  = np.concatenate((X_test_mul_w2vec, X_test_mul_e2vec), axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XN_AZ-Ac4Pb"
      },
      "source": [
        "# Saving the objects:\n",
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([X_train_mul_vec_concat, X_val_mul_vec_concat, X_test_mul_vec_concat], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8YK-WvQc4VI"
      },
      "source": [
        "with open('/content/drive/MyDrive/2021_NLU/data/no_repeats/mul_emojis_vec.pkl', 'rb') as f:  \n",
        "    X_train_mul_vec_concat, X_val_mul_vec_concat, X_test_mul_vec_concat = pickle.load(f)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI-zJq7rPXl5"
      },
      "source": [
        "## LogisticRegression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIjbDVtyngjP"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "def metric(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "my_scorer = make_scorer(metric, greater_is_better=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FWaT4WfnoD1"
      },
      "source": [
        "def run_model(model, X_train, y_train, X_val, y_val):\n",
        "  print('     ## Fitting')\n",
        "  model.fit(X_train, y_train)\n",
        "  print('     ## Predicting')\n",
        "  preds = model.predict(X_val)\n",
        "  print(' ## F1 Score (weighted) is -', f1_score(y_val, preds, average='weighted'))\n",
        "  print(' ## Accuracy is -', accuracy_score(y_val, preds))\n",
        "  print('      ')\n",
        "  print('               Confusion Matrix')\n",
        "  print(confusion_matrix(y_val, preds))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD7i47THCe55"
      },
      "source": [
        "lr = LogisticRegression()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nQWK7vPNmt2"
      },
      "source": [
        "def run_model_gridsearch_lr(model, X_train, y_train, X_val, y_val):\n",
        "  \n",
        "  cv=5\n",
        "  parameters = {'C': np.logspace(0, 4, 10),'penalty': ['l1', 'l2']}\n",
        "  clf = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, scoring=my_scorer, verbose=0)\n",
        "  print(' ## Fitting GridSearch')\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  print(\"tuned hpyerparameters :(best parameters) \",clf.best_params_)\n",
        "  print(\"score :\",clf.best_score_)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBDZOzkEVmZ6"
      },
      "source": [
        "def scores(y_val, preds):\n",
        "  print(' ## F1 Score (weighted) is -', f1_score(y_val, preds, average='weighted'))\n",
        "  print(' ## Accuracy is -', accuracy_score(y_val, preds))\n",
        "  print('      ')\n",
        "  print('               Confusion Matrix')\n",
        "  print(confusion_matrix(y_val, preds))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMXorfACy5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8REJot7IyKF"
      },
      "source": [
        "###**LR with FULL DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCAa_Nu8ibFJ"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4hCXxbB_-1",
        "outputId": "dffda13a-53af-4612-c9b5-2e952a7fa075"
      },
      "source": [
        "# BASELINE\n",
        "run_model(lr, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5179993984471877\n",
            " ## Accuracy is - 0.517962710322874\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[558 522]\n",
            " [538 581]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcmFPx_-ydzC",
        "outputId": "45bea908-1241-401b-e66d-47a6b10904b6"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 3593.813663804626, 'penalty': 'l2'}\n",
            "score : 0.515086937552015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-tEwZYpyuwG",
        "outputId": "905e9fce-a889-4ee4-942e-4720dd3860a8"
      },
      "source": [
        "# FINESUNED \n",
        "best_lr_full = LogisticRegression(penalty = 'l2', C = 3593.813663804626)\n",
        "run_model(best_lr_full, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5197692060167853\n",
            " ## Accuracy is - 0.519781718963165\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[573 507]\n",
            " [549 570]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhNBPqZAdcAm"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLEgDzghxkC9",
        "outputId": "b91023c9-614e-419d-d984-b24098581369"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_full_base = lr.predict(X_test_vec)\n",
        "pred_lr_full_prob_base = lr.predict_proba(X_test_vec)\n",
        "scores(y_test, pred_lr_full_base)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5173889777206634\n",
            " ## Accuracy is - 0.5173501577287066\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1170 1089]\n",
            " [1053 1126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9zBdLT-ddh9",
        "outputId": "7529bf67-5b4b-46b7-ef2a-082506183177"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_full = best_lr_full.predict(X_test_vec)\n",
        "pred_lr_full_prob = best_lr_full.predict_proba(X_test_vec)\n",
        "scores(y_test, pred_lr_full)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5245992385409034\n",
            " ## Accuracy is - 0.5245606128886886\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1184 1075]\n",
            " [1035 1144]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAqvlY2teoUG",
        "outputId": "aa2b33ee-cdaf-4b59-edc9-c945bca6e43b"
      },
      "source": [
        "pred_lr_full_prob #[prob for class0, prob for class1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45513382, 0.54486618],\n",
              "       [0.4308906 , 0.5691094 ],\n",
              "       [0.37023349, 0.62976651],\n",
              "       ...,\n",
              "       [0.50978928, 0.49021072],\n",
              "       [0.5311429 , 0.4688571 ],\n",
              "       [0.40109193, 0.59890807]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLkaHBPAioHf"
      },
      "source": [
        "#### With Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgcuWGXQitTR",
        "outputId": "0a41099e-b931-46a8-dc5e-3c73691c27be"
      },
      "source": [
        "#BASELINE\n",
        "run_model(lr, X_train_vec_concat, y_train, X_val_vec_concat, y_val)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5179993984471877\n",
            " ## Accuracy is - 0.517962710322874\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[558 522]\n",
            " [538 581]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c94Zon6itWo",
        "outputId": "c95b7425-5447-4ddd-da23-d9a6de3dd0bb"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_vec_concat, y_train, X_val_vec_concat, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 2.7825594022071245, 'penalty': 'l2'}\n",
            "score : 0.5128374049413716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M9B0C7Sitac",
        "outputId": "9af127cf-3785-41af-8399-36e54b1c5b1b"
      },
      "source": [
        "#FINETUNED\n",
        "best_lr_full_concat = LogisticRegression(penalty = 'l2', C = 2.7825594022071245)\n",
        "run_model(best_lr_full_concat, X_train_vec_concat, y_train, X_val_vec_concat, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5178031935717086\n",
            " ## Accuracy is - 0.517962710322874\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[582 498]\n",
            " [562 557]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhZ0-oj-WZlM"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrCey4dn0_y8",
        "outputId": "dd662c05-b03e-41c0-fb9b-4ad19d467a01"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_full_concat_base = lr.predict(X_test_vec_concat)\n",
        "pred_lr_full_prob_concat_base = lr.predict_proba(X_test_vec_concat)\n",
        "scores(y_test, pred_lr_full_concat_base)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5173889777206634\n",
            " ## Accuracy is - 0.5173501577287066\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1170 1089]\n",
            " [1053 1126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuSxn4XeWZtq",
        "outputId": "09f20902-7cd9-46c6-edd7-5a0c28fd0cff"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_full_concat = best_lr_full_concat.predict(X_test_vec_concat)\n",
        "pred_lr_full_prob_concat = best_lr_full_concat.predict_proba(X_test_vec_concat)\n",
        "scores(y_test, pred_lr_full_concat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5200812782739727\n",
            " ## Accuracy is - 0.5200540784136999\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1185 1074]\n",
            " [1056 1123]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbvsc9MMDlsx",
        "outputId": "d84667fc-4a3c-47c0-e3c0-84329233ae85"
      },
      "source": [
        "pred_lr_full_prob_concat #[prob for class0, prob for class1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43541843, 0.56458157],\n",
              "       [0.4205097 , 0.5794903 ],\n",
              "       [0.26461422, 0.73538578],\n",
              "       ...,\n",
              "       [0.46542256, 0.53457744],\n",
              "       [0.51649599, 0.48350401],\n",
              "       [0.43416939, 0.56583061]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOn69JY3I05t"
      },
      "source": [
        "###**LR with SINGLE EMOJI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1okP-t7hdOqo"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-qKUF1dC6KJ",
        "outputId": "1ebe0779-d2ed-45aa-b935-bf1fe7533b54"
      },
      "source": [
        "# FOR SINGLE EMOJI\n",
        "run_model(lr, X_train_sing_vec, y_sing_train, X_val_sing_vec, y_sing_val)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5049510032156806\n",
            " ## Accuracy is - 0.5058058522991176\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[506 584]\n",
            " [480 583]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz8aKKsHNttO",
        "outputId": "cfeb8208-ee24-4e9b-c32e-f821efcf2684"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_sing_vec, y_sing_train, X_val_sing_vec, y_sing_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 10000.0, 'penalty': 'l2'}\n",
            "score : 0.5031135666609666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D8mPpS4NtxI",
        "outputId": "047a3165-0ade-4f08-bfa4-479c78e8bb7e"
      },
      "source": [
        "best_lr_sing = LogisticRegression(penalty = 'l2', C = 10000.0)\n",
        "run_model(best_lr_sing, X_train_sing_vec, y_sing_train, X_val_sing_vec, y_sing_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5021978592440751\n",
            " ## Accuracy is - 0.5030190431955411\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[504 586]\n",
            " [484 579]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffo8DIZXWHcL"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yJDZl6r1mu_",
        "outputId": "61aa2af2-068e-474c-c0ef-8fe6662c8057"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_sing_base = lr.predict(X_test_sing_vec)\n",
        "pred_lr_sing_prob_base = lr.predict_proba(X_test_sing_vec)\n",
        "scores(y_sing_test, pred_lr_sing_base)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.4869595082363849\n",
            " ## Accuracy is - 0.48721492743607464\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1023 1181]\n",
            " [1045 1092]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCuXoh_bWHkY",
        "outputId": "6388958b-cfae-41cc-f591-a6dc5b42935d"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_sing = best_lr_sing.predict(X_test_sing_vec)\n",
        "scores(y_sing_test, pred_lr_sing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.4878466603498624\n",
            " ## Accuracy is - 0.4879060124395301\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1047 1157]\n",
            " [1066 1071]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1lcjPsfZoq"
      },
      "source": [
        "#### With Concatenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0FQyfa2fbKg",
        "outputId": "26cb37a4-5583-4015-90f6-ea061c7eac1d"
      },
      "source": [
        "run_model(lr, X_train_sing_vec_concat, y_sing_train, X_val_sing_vec_concat, y_sing_val)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.4998031042482971\n",
            " ## Accuracy is - 0.5002322340919647\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[513 577]\n",
            " [499 564]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_uI7KM2fpRh",
        "outputId": "24f0cbd6-8301-4a0e-9a73-fb3953536b2a"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_sing_vec_concat, y_sing_train, X_val_sing_vec_concat, y_sing_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 21.544346900318832, 'penalty': 'l2'}\n",
            "score : 0.5051196878848289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP0pgQ8ffpW9",
        "outputId": "6d1331e2-b632-457a-e19a-8e9c6445fd0f"
      },
      "source": [
        "#FINETUNED \n",
        "best_lr_sing_concat = LogisticRegression(penalty = 'l2', C = 21.544346900318832)\n",
        "run_model(best_lr_sing_concat, X_train_sing_vec_concat, y_sing_train, X_val_sing_vec_concat, y_sing_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.49451687383181664\n",
            " ## Accuracy is - 0.4946586158848119\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[520 570]\n",
            " [518 545]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfN-bIBVgdF-"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o938tm3m3GfK",
        "outputId": "2c42f37d-9aed-46f9-feb1-1746c9eba7a8"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_sing_concat_base = lr.predict(X_test_sing_vec_concat)\n",
        "pred_lr_sing_prob_concat_base = lr.predict_proba(X_test_sing_vec_concat)\n",
        "scores(y_sing_test, pred_lr_sing_concat_base)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5002397398943275\n",
            " ## Accuracy is - 0.5003455425017277\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1067 1137]\n",
            " [1032 1105]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caLs5ZSdgd6z",
        "outputId": "43334a56-38d9-4072-b996-236043b922d0"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_sing_concat = best_lr_sing_concat.predict(X_test_sing_vec_concat)\n",
        "scores(y_sing_test, pred_lr_sing_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.49732795452647843\n",
            " ## Accuracy is - 0.4973508408200875\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1074 1130]\n",
            " [1052 1085]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfW-jaQsNOvG"
      },
      "source": [
        "###**MULTI EMOJIS WITH REPEATS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuMp8wnDg_gp"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChwSiaacNO56",
        "outputId": "51ec8bf2-5ef2-43f0-9fb7-bf016d8db2ba"
      },
      "source": [
        "# BASELINE\n",
        "run_model(lr, X_train_mul_repeat_vec, y_mul_repeat_train, X_val_mul_repeat_vec, y_mul_repeat_val)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5187493899908503\n",
            " ## Accuracy is - 0.5189504373177842\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[651 556]\n",
            " [599 595]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL_NOBZrnrgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29da110-3d4f-4d7a-e64e-2cb7f98b7918"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_repeat_vec, y_mul_repeat_train, X_val_mul_repeat_vec, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 2.7825594022071245, 'penalty': 'l2'}\n",
            "score : 0.5246267106645911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhq0bza_Nu2E",
        "outputId": "ae8e87b9-dd80-4085-c38f-97aacaa8fdd6"
      },
      "source": [
        "#FINETUNED\n",
        "best_lr_mul_repeat = LogisticRegression(penalty = 'l2', C = 2.7825594022071245)\n",
        "run_model(best_lr_mul_repeat, X_train_mul_repeat_vec, y_mul_repeat_train, X_val_mul_repeat_vec, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5062493741464569\n",
            " ## Accuracy is - 0.5064556434818825\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[636 571]\n",
            " [614 580]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc_roNBTV3pz"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w_9x66r3qRn",
        "outputId": "1bb84019-5926-4413-9beb-8a723e1c4583"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_base = lr.predict(X_test_mul_repeat_vec)\n",
        "pred_lr_mul_prob_base = lr.predict_proba(X_test_mul_repeat_vec)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_base)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ShdwYMwV3wc",
        "outputId": "c85e70cd-0d6e-4cad-c208-358a906f38ac"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul_repeat = best_lr_mul_repeat.predict(X_test_mul_repeat_vec)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5193760638968085\n",
            " ## Accuracy is - 0.519375\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1238 1152]\n",
            " [1155 1255]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP_7iMGPhCOZ"
      },
      "source": [
        "#### With Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsRGoa-KhIJU",
        "outputId": "02cf9e29-6c77-48c3-a8c2-a92256bc409b"
      },
      "source": [
        "run_model(lr, X_train_mul_repeat_vec_concat, y_mul_repeat_train, X_val_mul_repeat_vec_concat, y_mul_repeat_val)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5187493899908503\n",
            " ## Accuracy is - 0.5189504373177842\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[651 556]\n",
            " [599 595]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmKiUyslhZJS",
        "outputId": "0ecae6c8-8603-43a9-c28a-856ad7ac5edf"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_repeat_vec_concat, y_mul_repeat_train, X_val_mul_repeat_vec_concat, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2'}\n",
            "score : 0.5222718993614576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj23kEHHhZOw",
        "outputId": "564150ae-876b-4025-dd15-aa3784b78989"
      },
      "source": [
        "best_lr_mul_repeat_concat = LogisticRegression(penalty = 'l2', C = 1.0)\n",
        "run_model(best_lr_mul_repeat_concat, X_train_mul_repeat_vec_concat, y_mul_repeat_train, X_val_mul_repeat_vec_concat, y_mul_repeat_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5187493899908503\n",
            " ## Accuracy is - 0.5189504373177842\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[651 556]\n",
            " [599 595]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6WGr-Xhn8o"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cieg4jgD4DpM",
        "outputId": "9eb451be-b42d-469a-951c-ee0d5956310f"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_concat_base = lr.predict(X_test_mul_repeat_vec_concat)\n",
        "pred_lr_mul_prob_concat_base = lr.predict_proba(X_test_mul_repeat_vec_concat)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_concat_base)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxCCDCzMhoHd",
        "outputId": "9e5a1733-f903-48e5-ed5f-6e73f6dbbb9c"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul_repeat_concat = best_lr_mul_repeat_concat.predict(X_test_mul_repeat_vec_concat)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXGMZxStQx4J"
      },
      "source": [
        "###**FULL EMOJIS NO REPEATS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca1ihGKXh_ax"
      },
      "source": [
        "#### With Averaged Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69EaKC7MQyCE",
        "outputId": "cb6950d7-ac55-4fbc-c20d-fcab2c44ec15"
      },
      "source": [
        "run_model(lr, X_train_mul_vec, y_mul_train, X_val_mul_vec, y_mul_val)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.519122216228706\n",
            " ## Accuracy is - 0.5190668461193361\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[572 514]\n",
            " [558 585]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWTMqs9nQyGg",
        "outputId": "d3dbe1de-99d2-4ba3-f347-cc6bedc42de3"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_vec, y_mul_train, X_val_mul_vec, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 7.742636826811269, 'penalty': 'l2'}\n",
            "score : 0.5058041572685422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUkKQyYQS5t1",
        "outputId": "c4d2b810-5ed5-4ba9-dfbd-4aa5e4630079"
      },
      "source": [
        "best_lr_mul = LogisticRegression(penalty = 'l2', C = 7.742636826811269)\n",
        "run_model(best_lr_mul, X_train_mul_vec, y_mul_train, X_val_mul_vec, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.506974828951965\n",
            " ## Accuracy is - 0.5069537909376401\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[563 523]\n",
            " [576 567]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_R8WgYFTQKo"
      },
      "source": [
        "**PREDICTION ON TEST (w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKRVrP9c4q7s",
        "outputId": "8afa1ec7-b4db-4012-ce75-71d8191f7c07"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_base = lr.predict(X_test_mul_vec)\n",
        "pred_lr_mul_prob__base = lr.predict_proba(X_test_mul_vec)\n",
        "scores(y_mul_test, pred_lr_mul_base)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5158905918420099\n",
            " ## Accuracy is - 0.5159034513873224\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1158 1064]\n",
            " [1082 1129]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_rVW2-8T0Yn",
        "outputId": "1dd5fb35-2b6d-43e3-b06e-801b19a6f31b"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul = best_lr_mul.predict(X_test_mul_vec)\n",
        "scores(y_mul_test, pred_lr_mul)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5097595798975241\n",
            " ## Accuracy is - 0.509812767877284\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1156 1066]\n",
            " [1107 1104]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBNDCCERiEuQ"
      },
      "source": [
        "#### With Concantenated Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-TiQSVtiFAx",
        "outputId": "bf88cf79-add0-477d-eca3-60b4633473fb"
      },
      "source": [
        "run_model(lr, X_train_mul_vec_concat, y_mul_train, X_val_mul_vec_concat, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.519122216228706\n",
            " ## Accuracy is - 0.5190668461193361\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[572 514]\n",
            " [558 585]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev3DaCkLiNHj",
        "outputId": "a8f2e0df-3d91-41d2-9714-9fb45c7cd0a5"
      },
      "source": [
        "run_model_gridsearch_lr(lr, X_train_mul_vec_concat, y_mul_train, X_val_mul_vec_concat, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## Fitting GridSearch\n",
            "tuned hpyerparameters :(best parameters)  {'C': 166.81005372000593, 'penalty': 'l2'}\n",
            "score : 0.5102422337754854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaGr28EpiNM8",
        "outputId": "b2942e3d-5dd2-4b74-fd4d-0279db3bd354"
      },
      "source": [
        "best_lr_mul_concat = LogisticRegression(penalty = 'l2', C = 166.81005372000593)\n",
        "run_model(best_lr_mul_concat, X_train_mul_vec_concat, y_mul_train, X_val_mul_vec_concat, y_mul_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     ## Fitting\n",
            "     ## Predicting\n",
            " ## F1 Score (weighted) is - 0.5164243110024794\n",
            " ## Accuracy is - 0.5163750560789592\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[570 516]\n",
            " [562 581]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCgZpqr4idFE"
      },
      "source": [
        "**PREDICTION ON TEST (w Concat Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAZaIfk45AaQ",
        "outputId": "6e6c319e-e97c-4ddb-c24d-22b8f777ebdf"
      },
      "source": [
        "#BASELINE RESULT\n",
        "pred_lr_mul_concat_base = lr.predict(X_test_mul_vec_concat)\n",
        "pred_lr_mul_prob_concat_base = lr.predict_proba(X_test_mul_vec_concat)\n",
        "scores(y_mul_test, pred_lr_mul_concat_base)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5158905918420099\n",
            " ## Accuracy is - 0.5159034513873224\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1158 1064]\n",
            " [1082 1129]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEeC_eu_idtO",
        "outputId": "a06cd0af-a4a2-4d19-cd57-b7aa84ad45f9"
      },
      "source": [
        "#FINETUNED RESULT\n",
        "pred_lr_mul_concat = best_lr_mul_concat.predict(X_test_mul_vec_concat)\n",
        "scores(y_mul_test, pred_lr_mul_concat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ## F1 Score (weighted) is - 0.5153876281750626\n",
            " ## Accuracy is - 0.515452289645838\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1171 1051]\n",
            " [1097 1114]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DClgnHseTWpy"
      },
      "source": [
        "##**SUMMARY PREDICTION ON TEST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF4Rk3zgivJw"
      },
      "source": [
        "###**w Avg Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvuDRIhVSNOS",
        "outputId": "a9ba8f80-14df-4914-e35b-cbae9d3c9faa"
      },
      "source": [
        "#FULL DATA\n",
        "print(\"FULL DATA\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_full = best_lr_full.predict(X_test_vec)\n",
        "scores(y_test, pred_lr_full)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#FULL EMOJIS WITH NO REPEATS\n",
        "print(\" \")\n",
        "print(\"FULL NO REPEATS\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_mul = best_lr_mul.predict(X_test_mul_vec)\n",
        "scores(y_mul_test, pred_lr_mul)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#SINGLE EMOJI\n",
        "print(\" \")\n",
        "print(\"SINGLE EMOJI ONLY\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_sing = best_lr_sing.predict(X_test_sing_vec)\n",
        "scores(y_sing_test, pred_lr_sing)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#MULTI EMOJIS WITH REPEATS\n",
        "print(\" \")\n",
        "print(\"MULTI EMOJIS ONLY WITH REPEATS\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_mul_repeat = best_lr_mul_repeat.predict(X_test_mul_repeat_vec)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL DATA\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5245992385409034\n",
            " ## Accuracy is - 0.5245606128886886\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1184 1075]\n",
            " [1035 1144]]\n",
            "==========================================\n",
            " \n",
            "FULL NO REPEATS\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5097595798975241\n",
            " ## Accuracy is - 0.509812767877284\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1156 1066]\n",
            " [1107 1104]]\n",
            "==========================================\n",
            " \n",
            "SINGLE EMOJI ONLY\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.4878466603498624\n",
            " ## Accuracy is - 0.4879060124395301\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1047 1157]\n",
            " [1066 1071]]\n",
            "==========================================\n",
            " \n",
            "MULTI EMOJIS ONLY WITH REPEATS\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5193760638968085\n",
            " ## Accuracy is - 0.519375\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1238 1152]\n",
            " [1155 1255]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUmp6-rIi3ly"
      },
      "source": [
        "###**w Concat Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtmqBLZzi3z4",
        "outputId": "ccc60f85-b402-42a4-edfd-26eada5dfe9e"
      },
      "source": [
        "#FULL DATA\n",
        "print(\"FULL DATA CONCAT\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_full_concat = best_lr_full_concat.predict(X_test_vec_concat)\n",
        "scores(y_test, pred_lr_full_concat)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#FULL EMOJIS WITH NO REPEATS\n",
        "print(\" \")\n",
        "print(\"FULL NO REPEATS CONCAT\")\n",
        "print(\"-------------------\")\n",
        "# pred_lr_mul = best_lr_mul.predict(X_test_mul_vec)\n",
        "# scores(y_mul_test, pred_lr_mul)\n",
        "pred_lr_mul_concat = best_lr_mul_concat.predict(X_test_mul_vec_concat)\n",
        "scores(y_mul_test, pred_lr_mul_concat)\n",
        "\n",
        "print(\"==========================================\")\n",
        "\n",
        "#SINGLE EMOJI\n",
        "print(\" \")\n",
        "print(\"SINGLE EMOJI ONLY CONCAT\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_sing_concat = best_lr_sing_concat.predict(X_test_sing_vec_concat)\n",
        "scores(y_sing_test, pred_lr_sing_concat)\n",
        "print(\"==========================================\")\n",
        "\n",
        "#MULTI EMOJIS WITH REPEATS\n",
        "print(\" \")\n",
        "print(\"MULTI EMOJIS ONLY WITH REPEATS CONCAT\")\n",
        "print(\"-------------------\")\n",
        "pred_lr_mul_repeat_concat = best_lr_mul_repeat_concat.predict(X_test_mul_repeat_vec_concat)\n",
        "scores(y_mul_repeat_test, pred_lr_mul_repeat_concat)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL DATA CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5200812782739727\n",
            " ## Accuracy is - 0.5200540784136999\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1185 1074]\n",
            " [1056 1123]]\n",
            "==========================================\n",
            " \n",
            "FULL NO REPEATS CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5153876281750626\n",
            " ## Accuracy is - 0.515452289645838\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1171 1051]\n",
            " [1097 1114]]\n",
            "==========================================\n",
            " \n",
            "SINGLE EMOJI ONLY CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.49732795452647843\n",
            " ## Accuracy is - 0.4973508408200875\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1074 1130]\n",
            " [1052 1085]]\n",
            "==========================================\n",
            " \n",
            "MULTI EMOJIS ONLY WITH REPEATS CONCAT\n",
            "-------------------\n",
            " ## F1 Score (weighted) is - 0.5220614269787021\n",
            " ## Accuracy is - 0.5220833333333333\n",
            "      \n",
            "               Confusion Matrix\n",
            "[[1231 1159]\n",
            " [1135 1275]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJgMSkMCSNR4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oNXjcrakG3g"
      },
      "source": [
        "##**ERROR ANALYSIS FOR BEST RESULTS (FULL DATA w Avg Vectors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAnP2Ac8kPsz"
      },
      "source": [
        "def evaluate_incorrect(y_test, preds, input_df, preds_prob):\n",
        "  df_test = input_df.copy()\n",
        "  df_test['prob_zero'] = preds_prob[:, 0]\n",
        "  print(df_test.shape)\n",
        "  eval_incorrect = df_test.index[y_test != preds]\n",
        "\n",
        "  output_incorrect = df_test[df_test.index.isin(eval_incorrect)]\n",
        "  # print(eval)\n",
        "  # print(eval.shape)\n",
        "  # print(y_test != preds)\n",
        "  # print(y_test == preds)\n",
        "\n",
        "  return output_incorrect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM2Nl5jjkPv4"
      },
      "source": [
        "def evaluate_correct(y_test, preds, input_df, preds_prob):\n",
        "  df_test = input_df.copy()\n",
        "  df_test['prob_zero'] = preds_prob[:, 0]\n",
        "  print(df_test.shape)\n",
        "\n",
        "  eval_correct = df_test.index[y_test == preds]\n",
        "  output_correct = df_test[df_test.index.isin(eval_correct)]\n",
        "  # print(eval)\n",
        "  # print(eval.shape)\n",
        "  # print(y_test != preds)\n",
        "  # print(y_test == preds)\n",
        "\n",
        "  return output_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gngE_j3dOK38"
      },
      "source": [
        "best_lr_full = LogisticRegression(penalty = 'l2', C = 3593.813663804626)\n",
        "run_model(best_lr_full, X_train_vec, y_train, X_val_vec, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0hU2HXRNglB",
        "outputId": "58287bee-dff2-4e1f-a0b1-eb72554bcd26"
      },
      "source": [
        "best_lr_full.predict_proba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method LogisticRegression.predict_proba of LogisticRegression(C=3593.813663804626, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ru6C2e-NyRz"
      },
      "source": [
        "pred_lr_full_prob = best_lr_full.predict_proba(X_test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF812jzVkPzS",
        "outputId": "60a88b72-3a36-4b0f-d329-11b263f90c71"
      },
      "source": [
        "pred_lr_full_prob[:, 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45513382, 0.4308906 , 0.37023349, ..., 0.50978928, 0.5311429 ,\n",
              "       0.40109193])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "cXxG2aCUNxcR",
        "outputId": "8b58dc89-1b3c-4b19-8547-5cbf64f2d104"
      },
      "source": [
        "output_incorrect = evaluate_incorrect(y_test, pred_lr_full, df_test, pred_lr_full_prob)\n",
        "output_incorrect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4438, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77593</td>\n",
              "      <td>You’re just so beautiful</td>\n",
              "      <td>💀</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40054</td>\n",
              "      <td>Want to tease someone until they cry</td>\n",
              "      <td>😢</td>\n",
              "      <td>1</td>\n",
              "      <td>0.553649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32019</td>\n",
              "      <td>I’ll figure this out. I always do and I always...</td>\n",
              "      <td>😤</td>\n",
              "      <td>1</td>\n",
              "      <td>0.569586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3979</td>\n",
              "      <td>[USER] [USER] Underrated tweet.</td>\n",
              "      <td>👍🏼</td>\n",
              "      <td>1</td>\n",
              "      <td>0.519481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35360</td>\n",
              "      <td>[USER] Can you do body rolls too?</td>\n",
              "      <td>🧐</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>23112</td>\n",
              "      <td>[USER] Hitting the Plymouth tomorrow.  If you ...</td>\n",
              "      <td>😁</td>\n",
              "      <td>1</td>\n",
              "      <td>0.568806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>81505</td>\n",
              "      <td>[USER] [USER] I'm sorry for your loss!</td>\n",
              "      <td>😊</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4432</th>\n",
              "      <td>11677</td>\n",
              "      <td>tmap ep. 38 gave us so much happiness. Today's...</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "      <td>0.571603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4433</th>\n",
              "      <td>14708</td>\n",
              "      <td>Learning to LOVE yourself the RIGHT away it th...</td>\n",
              "      <td>🥰</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4436</th>\n",
              "      <td>33923</td>\n",
              "      <td>[USER] We downgraded our CSP to the Flex last ...</td>\n",
              "      <td>😬</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2110 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... prob_zero\n",
              "0     77593  ...  0.455134\n",
              "3     40054  ...  0.553649\n",
              "4     32019  ...  0.569586\n",
              "6      3979  ...  0.519481\n",
              "7     35360  ...  0.521023\n",
              "...     ...  ...       ...\n",
              "4429  23112  ...  0.568806\n",
              "4431  81505  ...  0.455440\n",
              "4432  11677  ...  0.571603\n",
              "4433  14708  ...  0.583106\n",
              "4436  33923  ...  0.531143\n",
              "\n",
              "[2110 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77U5VcDyT3_L"
      },
      "source": [
        "output_incorrect.to_csv(\"/content/drive/MyDrive/2021_NLU/data/full_data/output_incorrect.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLXh-LuRT4ZO"
      },
      "source": [
        "incorrect = pd.read_csv(\"/content/drive/MyDrive/2021_NLU/data/full_data/output_incorrect.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw6GzVCUUCXZ",
        "outputId": "2816eaf1-c064-4684-e87d-2a44a3894f8c"
      },
      "source": [
        "print(incorrect.columns)\n",
        "print(incorrect.shape)\n",
        "print(len(x_test_tokenized))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['index', 'tweets', 'emoji_sentence', 'follows?', 'prob_zero'], dtype='object')\n",
            "(2110, 5)\n",
            "4438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "iXMm9OZHUCcV",
        "outputId": "c4256b23-2aca-4019-c2df-aa76f1c035a8"
      },
      "source": [
        "# below df is original + model predicting prob of zero\n",
        "# original says 'follows=0', which means it doesn't follow \n",
        "# but the below shows 'incorrect' prediction\n",
        "# and model predicted it doesn't follow with a 0.139464 prob \n",
        "# which means the model predicted it \"follows\" with a 0.860536 (1-0.139464) prob  \n",
        "incorrect[incorrect['follows?'] == 0].sort_values(by='prob_zero').head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>65383</td>\n",
              "      <td>[USER] Amin amin amin</td>\n",
              "      <td>🙃</td>\n",
              "      <td>0</td>\n",
              "      <td>0.139464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>96456</td>\n",
              "      <td>Gud morning</td>\n",
              "      <td>🗿</td>\n",
              "      <td>0</td>\n",
              "      <td>0.144617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1674</th>\n",
              "      <td>104591</td>\n",
              "      <td>[USER] Confessional?</td>\n",
              "      <td>🤧</td>\n",
              "      <td>0</td>\n",
              "      <td>0.166362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>61741</td>\n",
              "      <td>my chakra bracelet broke</td>\n",
              "      <td>🇮🇹🇪🇸🐶</td>\n",
              "      <td>0</td>\n",
              "      <td>0.174965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>63123</td>\n",
              "      <td>bloodhound apexlegends</td>\n",
              "      <td>♋🔮</td>\n",
              "      <td>0</td>\n",
              "      <td>0.190229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>71190</td>\n",
              "      <td>A fashion designer</td>\n",
              "      <td>👏🏼🤷♂</td>\n",
              "      <td>0</td>\n",
              "      <td>0.211639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>95632</td>\n",
              "      <td>GROSS people post GROSS tweets.</td>\n",
              "      <td>🤣</td>\n",
              "      <td>0</td>\n",
              "      <td>0.221515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1427</th>\n",
              "      <td>87870</td>\n",
              "      <td>Sensible administration.</td>\n",
              "      <td>🦵🏿👏🏿👏🏿😂🤣😂</td>\n",
              "      <td>0</td>\n",
              "      <td>0.238544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>69482</td>\n",
              "      <td>.           a correlated savior            And...</td>\n",
              "      <td>🙌</td>\n",
              "      <td>0</td>\n",
              "      <td>0.245230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>64260</td>\n",
              "      <td>Petit prince</td>\n",
              "      <td>🤣</td>\n",
              "      <td>0</td>\n",
              "      <td>0.246465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... prob_zero\n",
              "561    65383  ...  0.139464\n",
              "1068   96456  ...  0.144617\n",
              "1674  104591  ...  0.166362\n",
              "214    61741  ...  0.174965\n",
              "1307   63123  ...  0.190229\n",
              "526    71190  ...  0.211639\n",
              "311    95632  ...  0.221515\n",
              "1427   87870  ...  0.238544\n",
              "1864   69482  ...  0.245230\n",
              "1619   64260  ...  0.246465\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "radSb2XarcZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c12a0d-9511-4b6e-caf6-66afd144f11a"
      },
      "source": [
        "(5+3+3+5+4+6+6+8+5+3)/10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "i4QEeAoEUiM5",
        "outputId": "7b50eca9-03d8-40f9-ba2f-7cd09301399f"
      },
      "source": [
        "incorrect[incorrect['follows?'] == 1].sort_values(by='prob_zero', ascending = False).head(11)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>29079</td>\n",
              "      <td>[USER] comfort moot</td>\n",
              "      <td>🥺</td>\n",
              "      <td>1</td>\n",
              "      <td>0.877194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>52521</td>\n",
              "      <td>[USER] Noted</td>\n",
              "      <td>📝</td>\n",
              "      <td>1</td>\n",
              "      <td>0.808980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1763</th>\n",
              "      <td>44533</td>\n",
              "      <td>the quotes</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "      <td>0.806977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>11453</td>\n",
              "      <td>BOT  BOT     BOT  BOT    BOT  BOT     BOT  BO...</td>\n",
              "      <td>💀🐔💥🔪😡👎💩👙💡💀🔪💩🌵</td>\n",
              "      <td>1</td>\n",
              "      <td>0.740729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>37314</td>\n",
              "      <td>Don’t challenge the</td>\n",
              "      <td>🐐</td>\n",
              "      <td>1</td>\n",
              "      <td>0.732235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>51905</td>\n",
              "      <td>WTF, Amazon!? This is horrible!</td>\n",
              "      <td>😡</td>\n",
              "      <td>1</td>\n",
              "      <td>0.730434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1925</th>\n",
              "      <td>41707</td>\n",
              "      <td>considering tossing the unopened box of cinnam...</td>\n",
              "      <td>😬</td>\n",
              "      <td>1</td>\n",
              "      <td>0.728836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>4868</td>\n",
              "      <td>[USER] Library</td>\n",
              "      <td>😲</td>\n",
              "      <td>1</td>\n",
              "      <td>0.722231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>3466</td>\n",
              "      <td>me to 300?</td>\n",
              "      <td>⛽</td>\n",
              "      <td>1</td>\n",
              "      <td>0.712570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>49692</td>\n",
              "      <td>Wow wow wow</td>\n",
              "      <td>😍😍😍</td>\n",
              "      <td>1</td>\n",
              "      <td>0.710795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>7599</td>\n",
              "      <td>[USER] Rinse. Repeat.</td>\n",
              "      <td>😂</td>\n",
              "      <td>1</td>\n",
              "      <td>0.704552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... prob_zero\n",
              "1171  29079  ...  0.877194\n",
              "1177  52521  ...  0.808980\n",
              "1763  44533  ...  0.806977\n",
              "120   11453  ...  0.740729\n",
              "1309  37314  ...  0.732235\n",
              "281   51905  ...  0.730434\n",
              "1925  41707  ...  0.728836\n",
              "1115   4868  ...  0.722231\n",
              "449    3466  ...  0.712570\n",
              "1989  49692  ...  0.710795\n",
              "884    7599  ...  0.704552\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDKw-CVsUChk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92227686-0a04-41cb-f87c-f2b79cdfa517"
      },
      "source": [
        "(5+3+3+5+4+6+6+8+5+3+3+3+3+4+6+8+3+4+6+4)/20"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JfhIReUsDm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQSKPfW8UsH9",
        "outputId": "f158668b-c547-454d-a68c-1d2256ef1ced"
      },
      "source": [
        "output_correct = evaluate_correct(y_test, pred_lr_full, df_test, pred_lr_full_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4438, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9-yb4isUsN2"
      },
      "source": [
        "output_correct.to_csv(\"/content/drive/MyDrive/2021_NLU/data/full_data/output_correct.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2pAq_H57UsSq",
        "outputId": "42d938a0-0090-4401-d91d-4bfa440ffd80"
      },
      "source": [
        "output_correct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42801</td>\n",
              "      <td>Watch your PH balance not my page</td>\n",
              "      <td>🙂</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45798</td>\n",
              "      <td>fast gcash  • follow me &amp;amp; [USER] • rt end...</td>\n",
              "      <td>💸💸⏳</td>\n",
              "      <td>1</td>\n",
              "      <td>0.370233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44976</td>\n",
              "      <td>15 gcash • like and rt [USER]'s pinned • retwe...</td>\n",
              "      <td>📌</td>\n",
              "      <td>1</td>\n",
              "      <td>0.274290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>75250</td>\n",
              "      <td>Hennessy and dangerous. And I can’t front like...</td>\n",
              "      <td>🙂</td>\n",
              "      <td>0</td>\n",
              "      <td>0.502358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>59363</td>\n",
              "      <td>Standing at the bus stop today, with my mask o...</td>\n",
              "      <td>😭</td>\n",
              "      <td>0</td>\n",
              "      <td>0.521341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>37450</td>\n",
              "      <td>[USER] alright then we move  just hmu whenever</td>\n",
              "      <td>🤝</td>\n",
              "      <td>1</td>\n",
              "      <td>0.465126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4430</th>\n",
              "      <td>18250</td>\n",
              "      <td>self sabotaged at work again and got Mac and c...</td>\n",
              "      <td>😔</td>\n",
              "      <td>1</td>\n",
              "      <td>0.487529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4434</th>\n",
              "      <td>53064</td>\n",
              "      <td>[USER] Follow me to gainFollowersDaily.</td>\n",
              "      <td>👻🐰🌹</td>\n",
              "      <td>1</td>\n",
              "      <td>0.387965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4435</th>\n",
              "      <td>75342</td>\n",
              "      <td>I would never let a female use a strap because...</td>\n",
              "      <td>😍</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4437</th>\n",
              "      <td>22679</td>\n",
              "      <td>[USER] happiest birthday aya!!  have a blast</td>\n",
              "      <td>💗🥳</td>\n",
              "      <td>1</td>\n",
              "      <td>0.401092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2328 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... prob_zero\n",
              "1     42801  ...  0.430891\n",
              "2     45798  ...  0.370233\n",
              "5     44976  ...  0.274290\n",
              "9     75250  ...  0.502358\n",
              "12    59363  ...  0.521341\n",
              "...     ...  ...       ...\n",
              "4428  37450  ...  0.465126\n",
              "4430  18250  ...  0.487529\n",
              "4434  53064  ...  0.387965\n",
              "4435  75342  ...  0.509789\n",
              "4437  22679  ...  0.401092\n",
              "\n",
              "[2328 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "KLpHqxchXiA7",
        "outputId": "34bf6831-da7d-4f9b-cb06-211889058643"
      },
      "source": [
        "output_correct[output_correct['prob_zero']  > 0.7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "      <th>emoji_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>61362</td>\n",
              "      <td>Actives today?</td>\n",
              "      <td>😭</td>\n",
              "      <td>0</td>\n",
              "      <td>0.800815</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>79490</td>\n",
              "      <td>Found a spider in my room  throwing away my room</td>\n",
              "      <td>😊</td>\n",
              "      <td>0</td>\n",
              "      <td>0.743156</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>58636</td>\n",
              "      <td>Urgent action! Please read.</td>\n",
              "      <td>🤍</td>\n",
              "      <td>0</td>\n",
              "      <td>0.732539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>62258</td>\n",
              "      <td>A blessing</td>\n",
              "      <td>🥳</td>\n",
              "      <td>0</td>\n",
              "      <td>0.728554</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>103314</td>\n",
              "      <td>I want to move on and never look back</td>\n",
              "      <td>🐘</td>\n",
              "      <td>0</td>\n",
              "      <td>0.738640</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1170</th>\n",
              "      <td>74023</td>\n",
              "      <td>Shea Butter Baby</td>\n",
              "      <td>😂</td>\n",
              "      <td>0</td>\n",
              "      <td>0.791787</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>90596</td>\n",
              "      <td>Need some nasty hotel  drunk sex</td>\n",
              "      <td>🤨</td>\n",
              "      <td>0</td>\n",
              "      <td>0.711217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>62976</td>\n",
              "      <td>Dr. Rachel Levine makes history.</td>\n",
              "      <td>😭😭</td>\n",
              "      <td>0</td>\n",
              "      <td>0.713636</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>71108</td>\n",
              "      <td>The bros</td>\n",
              "      <td>😭</td>\n",
              "      <td>0</td>\n",
              "      <td>0.706372</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>97014</td>\n",
              "      <td>Please text me</td>\n",
              "      <td>♾💔</td>\n",
              "      <td>0</td>\n",
              "      <td>0.757426</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>105309</td>\n",
              "      <td>[USER] manual labour</td>\n",
              "      <td>😂</td>\n",
              "      <td>0</td>\n",
              "      <td>0.746659</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2784</th>\n",
              "      <td>64365</td>\n",
              "      <td>Sexy af</td>\n",
              "      <td>💢</td>\n",
              "      <td>0</td>\n",
              "      <td>0.896276</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3028</th>\n",
              "      <td>84767</td>\n",
              "      <td>and i overslept again.</td>\n",
              "      <td>🤧</td>\n",
              "      <td>0</td>\n",
              "      <td>0.715209</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>87539</td>\n",
              "      <td>[USER] confort moot</td>\n",
              "      <td>😊</td>\n",
              "      <td>0</td>\n",
              "      <td>0.736160</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3870</th>\n",
              "      <td>103649</td>\n",
              "      <td>Grandmas should live forever</td>\n",
              "      <td>😭</td>\n",
              "      <td>0</td>\n",
              "      <td>0.740893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4114</th>\n",
              "      <td>62196</td>\n",
              "      <td>Vibin w/ someone who got the same goofy energy...</td>\n",
              "      <td>☹</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... emoji_sentence_len\n",
              "80     61362  ...                  1\n",
              "467    79490  ...                  1\n",
              "600    58636  ...                  1\n",
              "896    62258  ...                  1\n",
              "951   103314  ...                  1\n",
              "1170   74023  ...                  1\n",
              "1208   90596  ...                  1\n",
              "1482   62976  ...                  2\n",
              "2034   71108  ...                  1\n",
              "2261   97014  ...                  2\n",
              "2500  105309  ...                  1\n",
              "2784   64365  ...                  1\n",
              "3028   84767  ...                  1\n",
              "3453   87539  ...                  1\n",
              "3870  103649  ...                  1\n",
              "4114   62196  ...                  1\n",
              "\n",
              "[16 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3oelJIiVMpg"
      },
      "source": [
        "correct_prob = output_correct[output_correct['follows?'] == 0].prob_zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "pG3CN4-SVSsg",
        "outputId": "f5536819-2bab-4e05-bce9-8933a1a3c504"
      },
      "source": [
        "plt.hist(correct_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([555., 356., 167.,  59.,  29.,  10.,   5.,   2.,   0.,   1.]),\n",
              " array([0.50005471, 0.5396768 , 0.57929889, 0.61892097, 0.65854306,\n",
              "        0.69816515, 0.73778723, 0.77740932, 0.81703141, 0.85665349,\n",
              "        0.89627558]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-hBXOEuVSx3"
      },
      "source": [
        "incorrect_prob = 1-output_correct[output_correct['follows?'] == 1].prob_zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "xbB6wuw3VS22",
        "outputId": "84c0c6f3-8f7a-4536-eab4-f78740903f8f"
      },
      "source": [
        "plt.hist(incorrect_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([446., 302., 149., 100.,  69.,  37.,  24.,   8.,   6.,   3.]),\n",
              " array([0.50006746, 0.53385972, 0.56765199, 0.60144425, 0.63523651,\n",
              "        0.66902878, 0.70282104, 0.7366133 , 0.77040557, 0.80419783,\n",
              "        0.83799009]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w3ErQorWbA1"
      },
      "source": [
        "output_correct['emoji_sentence_len'] = output_correct['emoji_sentence'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "KIDQISuBWbGA",
        "outputId": "db8716e4-936a-4c3a-a0da-b7c35ba3343f"
      },
      "source": [
        "output_correct[output_correct['emoji_sentence_len'] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "      <th>emoji_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42801</td>\n",
              "      <td>Watch your PH balance not my page</td>\n",
              "      <td>🙂</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430891</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44976</td>\n",
              "      <td>15 gcash • like and rt [USER]'s pinned • retwe...</td>\n",
              "      <td>📌</td>\n",
              "      <td>1</td>\n",
              "      <td>0.274290</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>75250</td>\n",
              "      <td>Hennessy and dangerous. And I can’t front like...</td>\n",
              "      <td>🙂</td>\n",
              "      <td>0</td>\n",
              "      <td>0.502358</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>59363</td>\n",
              "      <td>Standing at the bus stop today, with my mask o...</td>\n",
              "      <td>😭</td>\n",
              "      <td>0</td>\n",
              "      <td>0.521341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>104893</td>\n",
              "      <td>Man everything be so funny to me I can’t take ...</td>\n",
              "      <td>😔</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4424</th>\n",
              "      <td>15421</td>\n",
              "      <td>[USER] Ndimi munozonzi my Ex is back in thd pi...</td>\n",
              "      <td>😉</td>\n",
              "      <td>1</td>\n",
              "      <td>0.493969</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4427</th>\n",
              "      <td>104774</td>\n",
              "      <td>[USER] YES   we have a lot of different styles...</td>\n",
              "      <td>😏</td>\n",
              "      <td>0</td>\n",
              "      <td>0.516527</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>37450</td>\n",
              "      <td>[USER] alright then we move  just hmu whenever</td>\n",
              "      <td>🤝</td>\n",
              "      <td>1</td>\n",
              "      <td>0.465126</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4430</th>\n",
              "      <td>18250</td>\n",
              "      <td>self sabotaged at work again and got Mac and c...</td>\n",
              "      <td>😔</td>\n",
              "      <td>1</td>\n",
              "      <td>0.487529</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4435</th>\n",
              "      <td>75342</td>\n",
              "      <td>I would never let a female use a strap because...</td>\n",
              "      <td>😍</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509789</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1743 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ... emoji_sentence_len\n",
              "1      42801  ...                  1\n",
              "5      44976  ...                  1\n",
              "9      75250  ...                  1\n",
              "12     59363  ...                  1\n",
              "13    104893  ...                  1\n",
              "...      ...  ...                ...\n",
              "4424   15421  ...                  1\n",
              "4427  104774  ...                  1\n",
              "4428   37450  ...                  1\n",
              "4430   18250  ...                  1\n",
              "4435   75342  ...                  1\n",
              "\n",
              "[1743 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtU4ZQE4WbK7"
      },
      "source": [
        "output_incorrect['emoji_sentence_len'] = output_incorrect['emoji_sentence'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "1f30Ze5jWbPg",
        "outputId": "3e201d57-2b6a-42c1-fa3d-3b4ca1719b54"
      },
      "source": [
        "output_incorrect[output_incorrect['emoji_sentence_len'] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweets</th>\n",
              "      <th>emoji_sentence</th>\n",
              "      <th>follows?</th>\n",
              "      <th>prob_zero</th>\n",
              "      <th>emoji_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77593</td>\n",
              "      <td>You’re just so beautiful</td>\n",
              "      <td>💀</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40054</td>\n",
              "      <td>Want to tease someone until they cry</td>\n",
              "      <td>😢</td>\n",
              "      <td>1</td>\n",
              "      <td>0.553649</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32019</td>\n",
              "      <td>I’ll figure this out. I always do and I always...</td>\n",
              "      <td>😤</td>\n",
              "      <td>1</td>\n",
              "      <td>0.569586</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35360</td>\n",
              "      <td>[USER] Can you do body rolls too?</td>\n",
              "      <td>🧐</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521023</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>76988</td>\n",
              "      <td>good morning</td>\n",
              "      <td>🙄</td>\n",
              "      <td>0</td>\n",
              "      <td>0.249820</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4429</th>\n",
              "      <td>23112</td>\n",
              "      <td>[USER] Hitting the Plymouth tomorrow.  If you ...</td>\n",
              "      <td>😁</td>\n",
              "      <td>1</td>\n",
              "      <td>0.568806</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4431</th>\n",
              "      <td>81505</td>\n",
              "      <td>[USER] [USER] I'm sorry for your loss!</td>\n",
              "      <td>😊</td>\n",
              "      <td>0</td>\n",
              "      <td>0.455440</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4432</th>\n",
              "      <td>11677</td>\n",
              "      <td>tmap ep. 38 gave us so much happiness. Today's...</td>\n",
              "      <td>😭</td>\n",
              "      <td>1</td>\n",
              "      <td>0.571603</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4433</th>\n",
              "      <td>14708</td>\n",
              "      <td>Learning to LOVE yourself the RIGHT away it th...</td>\n",
              "      <td>🥰</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583106</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4436</th>\n",
              "      <td>33923</td>\n",
              "      <td>[USER] We downgraded our CSP to the Flex last ...</td>\n",
              "      <td>😬</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531143</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1608 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... emoji_sentence_len\n",
              "0     77593  ...                  1\n",
              "3     40054  ...                  1\n",
              "4     32019  ...                  1\n",
              "7     35360  ...                  1\n",
              "8     76988  ...                  1\n",
              "...     ...  ...                ...\n",
              "4429  23112  ...                  1\n",
              "4431  81505  ...                  1\n",
              "4432  11677  ...                  1\n",
              "4433  14708  ...                  1\n",
              "4436  33923  ...                  1\n",
              "\n",
              "[1608 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvR7lyRfX31T",
        "outputId": "0ff94643-4a4e-4107-a725-4eff8e748922"
      },
      "source": [
        "df_test['follows?'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2259\n",
              "1    2179\n",
              "Name: follows?, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}